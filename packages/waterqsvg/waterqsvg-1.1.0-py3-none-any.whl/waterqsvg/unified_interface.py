#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
SVG Water Quality Generator ç»Ÿä¸€æ¥å£

è¿™æ˜¯æ°´è´¨æ•°æ®å¤„ç†å’ŒSVGç”Ÿæˆçš„ç»Ÿä¸€å…¥å£ç‚¹ï¼Œæä¾›å‘½ä»¤è¡Œå’Œç¼–ç¨‹æ¥å£ã€‚
"""

import argparse
import json
import logging
import shutil
import sys
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

# å°è¯•ç›¸å¯¹å¯¼å…¥ï¼Œå¤±è´¥åˆ™ä½¿ç”¨ç»å¯¹å¯¼å…¥
try:
    from .config.indicators import WATER_QUALITY_INDICATORS, get_indicator_info
    from .core.downloader import ResourceDownloader
    from .core.extractor import ZipExtractor
    from .data.parser import DataParser
    from .data.standardizer import DataStandardizer
    from .data.validator import DataValidator
    from .interpolation.enhanced_interpolation import (
        enhanced_interpolation_with_boundary,
    )
    from .utils.logger import setup_logging
    from .visualization.svg_generator import create_clean_interpolation_svg
except ImportError:
    # å¼€å‘æ¨¡å¼ä¸‹çš„ç»å¯¹å¯¼å…¥
    from config.indicators import get_indicator_info
    from core.downloader import ResourceDownloader
    from core.extractor import ZipExtractor
    from data.parser import DataParser
    from data.standardizer import DataStandardizer
    from data.validator import DataValidator
    from interpolation.enhanced_interpolation import (
        enhanced_interpolation_with_boundary,
    )
    from utils.logger import setup_logging
    from visualization.svg_generator import create_clean_interpolation_svg

logger = logging.getLogger(__name__)


class WaterQualityProcessor:
    """æ°´è´¨æ•°æ®å¤„ç†å™¨"""

    def __init__(
        self,
        output_dir: str = "./outputs",
        temp_dir: Optional[str] = None,
        grid_resolution: int = 300,
        log_level: str = "INFO",
    ):
        """
        åˆå§‹åŒ–æ°´è´¨æ•°æ®å¤„ç†å™¨

        Args:
            output_dir: è¾“å‡ºç›®å½•
            temp_dir: ä¸´æ—¶ç›®å½•
            grid_resolution: ç½‘æ ¼åˆ†è¾¨ç‡
            log_level: æ—¥å¿—çº§åˆ«
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        if temp_dir is None:
            self.temp_dir = Path(tempfile.mkdtemp(prefix="water_quality_"))
        else:
            self.temp_dir = Path(temp_dir)
            self.temp_dir.mkdir(parents=True, exist_ok=True)

        self.grid_resolution = grid_resolution

        # åˆå§‹åŒ–ç»„ä»¶
        self.downloader = ResourceDownloader(str(self.temp_dir))
        self.extractor = ZipExtractor(str(self.temp_dir))
        self.parser = DataParser()
        self.standardizer = DataStandardizer()
        self.validator = DataValidator()

        # è®¾ç½®æ—¥å¿—
        setup_logging(log_level)
        logger.info(f"æ°´è´¨æ•°æ®å¤„ç†å™¨å·²åˆå§‹åŒ–ï¼Œè¾“å‡ºç›®å½•: {self.output_dir}")

    def process_from_oss_zip(
        self,
        zip_url: str,
        colormap: str = "jet",
        boundary_method: str = "alpha_shape",
        interpolation_method: str = "universal_kriging",
        transparent_bg: bool = True,
        figsize: Tuple[float, float] = (10, 8),
    ) -> Dict[str, Any]:
        """
        ä»OSS ZIPæ–‡ä»¶å¤„ç†æ°´è´¨æ•°æ®å¹¶ç”ŸæˆSVG

        Args:
            zip_url: OSS ZIPæ–‡ä»¶URL
            colormap: é¢œè‰²æ˜ å°„æ–¹æ¡ˆ
            boundary_method: è¾¹ç•Œæ£€æµ‹æ–¹æ³•
            interpolation_method: æ’å€¼æ–¹æ³•
            transparent_bg: æ˜¯å¦ä½¿ç”¨é€æ˜èƒŒæ™¯
            figsize: å›¾å½¢å°ºå¯¸

        Returns:
            å¤„ç†ç»“æœå­—å…¸ï¼ŒåŒ…å«SVGæ–‡ä»¶è·¯å¾„å’Œç»çº¬åº¦è¾¹ç•Œä¿¡æ¯
        """
        try:
            logger.info(f"å¼€å§‹å¤„ç†OSS ZIPæ–‡ä»¶: {zip_url}")

            # 1. ä¸‹è½½ZIPæ–‡ä»¶
            zip_path = self.downloader.download(zip_url)
            if not zip_path:
                raise ValueError("ZIPæ–‡ä»¶ä¸‹è½½å¤±è´¥")

            # 2. è§£å‹æ–‡ä»¶
            extract_dir = self.extractor.extract(zip_path)
            if not extract_dir:
                raise ValueError("ZIPæ–‡ä»¶è§£å‹å¤±è´¥")

            # 3. è§£ææ•°æ®
            df = self.parser.parse_uav_data(extract_dir)
            if df is None:
                raise ValueError("æ•°æ®è§£æå¤±è´¥")

            # 4. æ ‡å‡†åŒ–æ•°æ®
            df, mapping_info = self.standardizer.standardize_dataframe(df)

            # 5. éªŒè¯æ•°æ®
            validation_result = self.validator.validate_dataframe(df)
            if not validation_result["is_valid"]:
                logger.warning(f"æ•°æ®éªŒè¯è­¦å‘Š: {validation_result['warnings']}")

            # 6. è·å–æ‰€æœ‰å¯ç”¨æŒ‡æ ‡
            available_indicators = self._get_available_indicators(df)
            logger.info(f"å¯ç”¨æŒ‡æ ‡: {available_indicators}")

            # 7. ä¸ºæ¯ä¸ªæŒ‡æ ‡ç”ŸæˆSVG
            results = {}
            for indicator in available_indicators:
                svg_result = self._generate_svg_for_indicator(
                    df,
                    indicator,
                    colormap,
                    boundary_method,
                    interpolation_method,
                    transparent_bg,
                    figsize,
                )
                results[indicator] = svg_result

            logger.info(f"å®Œæˆå¤„ç†ï¼Œå…±ç”Ÿæˆ{len(results)}ä¸ªSVGæ–‡ä»¶")
            return results

        except Exception as e:
            logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if self.temp_dir.exists():
                shutil.rmtree(self.temp_dir)

    def _get_available_indicators(self, df: pd.DataFrame) -> List[str]:
        """è·å–æ•°æ®ä¸­å¯ç”¨çš„æ°´è´¨æŒ‡æ ‡"""
        available = []

        # æ’é™¤åæ ‡åˆ—
        coord_columns = ["index", "longitude", "latitude"]
        indicator_columns = [col for col in df.columns if col not in coord_columns]

        # æ£€æŸ¥æ¯ä¸ªæŒ‡æ ‡åˆ—æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®
        for indicator in indicator_columns:
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®
            has_valid_data = not df[indicator].isna().all()
            if has_valid_data:
                # æ£€æŸ¥æ•°æ®ç±»å‹æ˜¯å¦ä¸ºæ•°å€¼å‹
                try:
                    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼å‹ä»¥éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
                    numeric_data = pd.to_numeric(df[indicator], errors="coerce")
                    if not numeric_data.isna().all():
                        available.append(indicator)
                        logger.info(f"å‘ç°å¯ç”¨æŒ‡æ ‡: {indicator}")
                    else:
                        logger.warning(f"æŒ‡æ ‡ {indicator} æ— æ³•è½¬æ¢ä¸ºæ•°å€¼å‹ï¼Œè·³è¿‡")
                except Exception as e:
                    logger.warning(f"æŒ‡æ ‡ {indicator} æ•°æ®éªŒè¯å¤±è´¥: {str(e)}")

        logger.info(f"æ€»å…±å‘ç° {len(available)} ä¸ªå¯ç”¨æŒ‡æ ‡: {available}")
        return available

    def _generate_svg_for_indicator(
        self,
        df: pd.DataFrame,
        indicator: str,
        colormap: str,
        boundary_method: str,
        interpolation_method: str,
        transparent_bg: bool,
        figsize: Tuple[float, float],
    ) -> Dict[str, Any]:
        """ä¸ºå•ä¸ªæŒ‡æ ‡ç”ŸæˆSVG"""
        try:
            logger.info(f"å¼€å§‹ä¸ºæŒ‡æ ‡ {indicator} ç”ŸæˆSVG")

            # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
            valid_data = df[["longitude", "latitude", indicator]].dropna()
            if len(valid_data) < 3:
                logger.warning(f"æŒ‡æ ‡ {indicator} çš„æœ‰æ•ˆæ•°æ®ç‚¹ä¸è¶³3ä¸ªï¼Œè·³è¿‡")
                return None

            # å¢å¼ºæ’å€¼
            interpolated_data, grid_x, grid_y, mask, boundary_points = (
                enhanced_interpolation_with_boundary(
                    data=valid_data,
                    indicator_col=indicator,
                    grid_resolution=self.grid_resolution,
                    method=interpolation_method,
                    boundary_method=boundary_method,
                )
            )

            # è®¡ç®—ç»çº¬åº¦è¾¹ç•Œä¿¡æ¯
            bounds_info = self._calculate_bounds_info(grid_x, grid_y, mask)

            # ğŸ¯ è®¡ç®—åŸå§‹æ•°æ®èŒƒå›´ï¼Œç¡®ä¿ä¸AutoReportV3ä¸€è‡´
            original_min = float(valid_data[indicator].min())
            original_max = float(valid_data[indicator].max())
            value_range = (original_min, original_max)
            
            # ğŸ” å¯¹æ¯”æ’å€¼æ•°æ®ä¸åŸå§‹æ•°æ®èŒƒå›´å·®å¼‚
            valid_interpolated = interpolated_data[~np.isnan(interpolated_data)]
            if len(valid_interpolated) > 0:
                interp_min = float(valid_interpolated.min())
                interp_max = float(valid_interpolated.max())
                logger.info(f"åŸå§‹æ•°æ®èŒƒå›´: [{original_min:.3f}, {original_max:.3f}]")
                logger.info(f"æ’å€¼æ•°æ®èŒƒå›´: [{interp_min:.3f}, {interp_max:.3f}]")
                if abs(interp_min - original_min) > 0.1 or abs(interp_max - original_max) > 0.1:
                    logger.warning(f"æ’å€¼æ‰©å±•äº†æ•°æ®èŒƒå›´ï¼åŸå§‹vsæ’å€¼: [{original_min:.3f}, {original_max:.3f}] vs [{interp_min:.3f}, {interp_max:.3f}]")
            else:
                logger.warning("æ’å€¼æ•°æ®å…¨ä¸ºNaN")
            
            logger.info(f"âœ… ä½¿ç”¨åŸå§‹æ•°æ®èŒƒå›´ä½œä¸ºSVG colorbarï¼ˆä¸AutoReportV3ä¸€è‡´ï¼‰")

            # ç”ŸæˆSVGæ–‡ä»¶
            svg_filename = f"{indicator}_heatmap.svg"
            svg_path = self.output_dir / svg_filename

            success = create_clean_interpolation_svg(
                grid_values=interpolated_data,
                grid_x=grid_x,
                grid_y=grid_y,
                save_path=str(svg_path),
                title=None,  # çº¯å‡€SVGä¸åŒ…å«æ ‡é¢˜
                colormap=colormap,
                figsize=figsize,
                transparent_bg=transparent_bg,
                value_range=value_range,  # ğŸ¯ ä¼ é€’åŸå§‹æ•°æ®èŒƒå›´
            )

            if not success:
                logger.error(f"SVGç”Ÿæˆå¤±è´¥: {indicator}")
                return None

            # ç”Ÿæˆè¾¹ç•Œä¿¡æ¯æ–‡ä»¶
            bounds_filename = f"{indicator}_bounds.json"
            bounds_path = self.output_dir / bounds_filename
            with open(bounds_path, "w", encoding="utf-8") as f:
                json.dump(bounds_info, f, indent=2, ensure_ascii=False)

            # è·å–æŒ‡æ ‡ä¿¡æ¯ï¼ˆæ”¯æŒæœªçŸ¥æŒ‡æ ‡ï¼‰
            indicator_info = get_indicator_info(indicator)

            result = {
                "svg_path": str(svg_path),
                "bounds_path": str(bounds_path),
                "bounds_info": bounds_info,
                "indicator_name": indicator_info["name"],
                "unit": indicator_info["unit"],
                "data_points": len(valid_data),
                "min_value": float(valid_data[indicator].min()),
                "max_value": float(valid_data[indicator].max()),
                "mean_value": float(valid_data[indicator].mean()),
            }

            logger.info(f"æŒ‡æ ‡ {indicator} çš„SVGç”Ÿæˆå®Œæˆ: {svg_path}")
            return result

        except Exception as e:
            logger.error(f"ç”ŸæˆæŒ‡æ ‡ {indicator} çš„SVGæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return None

    def _calculate_bounds_info(
        self, grid_x: np.ndarray, grid_y: np.ndarray, mask: np.ndarray
    ) -> Dict[str, Any]:
        """è®¡ç®—ç»çº¬åº¦è¾¹ç•Œä¿¡æ¯ç”¨äºåœ°å›¾å åŠ """
        # æ‰¾åˆ°æœ‰æ•ˆåŒºåŸŸçš„è¾¹ç•Œ
        valid_indices = np.where(mask)

        if len(valid_indices[0]) == 0:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆåŒºåŸŸï¼Œä½¿ç”¨æ•´ä¸ªç½‘æ ¼
            min_lat, max_lat = grid_y.min(), grid_y.max()
            min_lon, max_lon = grid_x.min(), grid_x.max()
        else:
            # ä½¿ç”¨æœ‰æ•ˆåŒºåŸŸè®¡ç®—è¾¹ç•Œ
            valid_y_coords = grid_y[valid_indices]
            valid_x_coords = grid_x[valid_indices]

            min_lat = float(valid_y_coords.min())
            max_lat = float(valid_y_coords.max())
            min_lon = float(valid_x_coords.min())
            max_lon = float(valid_x_coords.max())

        # è®¡ç®—ä¸­å¿ƒç‚¹
        center_lat = (min_lat + max_lat) / 2
        center_lon = (min_lon + max_lon) / 2

        # è®¡ç®—èŒƒå›´
        lat_range = max_lat - min_lat
        lon_range = max_lon - min_lon

        bounds_info = {
            "geographic_bounds": {
                "min_longitude": min_lon,
                "max_longitude": max_lon,
                "min_latitude": min_lat,
                "max_latitude": max_lat,
                "center_longitude": center_lon,
                "center_latitude": center_lat,
                "longitude_range": lon_range,
                "latitude_range": lat_range,
            },
            "grid_info": {
                "grid_resolution": self.grid_resolution,
                "grid_width": grid_x.shape[1],
                "grid_height": grid_y.shape[0],
                "valid_pixels": int(np.sum(mask)),
            },
            "projection_info": {
                "coordinate_system": "WGS84",
                "units": "degrees",
                "note": "ç»çº¬åº¦åæ ‡ï¼Œé€‚ç”¨äºWebåœ°å›¾å åŠ ",
            },
        }

        return bounds_info

    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£ï¼Œæ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        if hasattr(self, "temp_dir") and self.temp_dir.exists():
            shutil.rmtree(self.temp_dir)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="SVG Water Quality Generator - æ°´è´¨æ•°æ®SVGçƒ­åŠ›å›¾ç”Ÿæˆå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
                ä½¿ç”¨ç¤ºä¾‹:
                python interface.py --zip-url "https://example.com/data.zip" --output-dir "./outputs"
                python interface.py --zip-url "/path/to/config.json" --colormap "water_quality" --resolution 600
                echo "https://example.com/data.zip" | python interface.py --output-dir "./outputs"
                echo "/path/to/config.json" | python interface.py --output-dir "./outputs"
                
                JSONé…ç½®æ–‡ä»¶æ ¼å¼:
                {
                    "file_url": "https://example.com/data.zip",
                    "description": "æ•°æ®æè¿°ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰"
                }
                
                Windowsç”¨æˆ·æ³¨æ„ï¼š
                å¦‚æœURLåŒ…å«&ç¬¦å·ï¼Œè¯·ä½¿ç”¨æ ‡å‡†è¾“å…¥æ–¹å¼ï¼Œæˆ–ç”¨åŒå¼•å·åŒ…å›´URLï¼š
                echo https://example.com/data.zip?param1=value1^&param2=value2 | python interface.py
                python interface.py --zip-url "https://example.com/data.zip?param1=value1&param2=value2"
        """,
    )

    # ZIP URLå‚æ•°ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä»æ ‡å‡†è¾“å…¥è¯»å–ï¼‰
    parser.add_argument(
        "--zip-url",
        required=False,
        help="OSS ZIPæ–‡ä»¶ä¸‹è½½URLæˆ–JSONé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸æä¾›åˆ™ä»æ ‡å‡†è¾“å…¥è¯»å–ï¼‰",
    )

    # å¯é€‰å‚æ•°
    parser.add_argument(
        "--output-dir", default="./outputs", help="è¾“å‡ºç›®å½• (é»˜è®¤: ./outputs)"
    )

    parser.add_argument(
        "--resolution", type=int, default=300, help="ç½‘æ ¼åˆ†è¾¨ç‡ (é»˜è®¤: 300, ä¸AutoReportV3ä¸€è‡´)"
    )

    parser.add_argument(
        "--colormap",
        default="jet",
        choices=["jet", "water_quality", "viridis", "RdYlBu_r"],
        help="é¢œè‰²æ˜ å°„æ–¹æ¡ˆ (é»˜è®¤: jet)",
    )

    parser.add_argument(
        "--boundary-method",
        default="alpha_shape",
        choices=["alpha_shape", "convex_hull", "density_based"],
        help="è¾¹ç•Œæ£€æµ‹æ–¹æ³• (é»˜è®¤: alpha_shape)",
    )

    parser.add_argument(
        "--interpolation-method",
        default="universal_kriging",
        choices=["universal_kriging", "ordinary_kriging_spherical", "ordinary_kriging_exponential"],
        help="æ’å€¼æ–¹æ³• (é»˜è®¤: universal_krigingé«˜ç²¾åº¦æ³›å…‹é‡Œé‡‘æ’å€¼)",
    )

    parser.add_argument(
        "--figsize",
        nargs=2,
        type=float,
        default=[12, 10],
        help="å›¾å½¢å°ºå¯¸ width height (é»˜è®¤: 12 10)",
    )

    parser.add_argument(
        "--log-level",
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        help="æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)",
    )

    parser.add_argument("--no-transparent", action="store_true", help="ç¦ç”¨é€æ˜èƒŒæ™¯")

    return parser.parse_args()


def read_zip_url_from_stdin():
    """ä»æ ‡å‡†è¾“å…¥è¯»å–ZIPæ–‡ä»¶URLæˆ–JSONæ–‡ä»¶è·¯å¾„"""
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡å‡†è¾“å…¥æ•°æ®
        if sys.stdin.isatty():
            return None

        # è¯»å–ç¬¬ä¸€è¡Œä½œä¸ºURLæˆ–æ–‡ä»¶è·¯å¾„
        input_data = sys.stdin.readline().strip()
        if not input_data:
            return None
        return resolve_zip_url(input_data)
    except Exception as e:
        logger.error(f"ä»æ ‡å‡†è¾“å…¥è¯»å–ZIP URLå¤±è´¥: {str(e)}")
        return None


def resolve_zip_url(input_data: str) -> Optional[str]:
    """è§£æè¾“å…¥æ•°æ®ï¼Œè·å–ZIPæ–‡ä»¶ä¸‹è½½URL

    Args:
        input_data: è¾“å…¥æ•°æ®ï¼Œå¯èƒ½æ˜¯URLæˆ–JSONæ–‡ä»¶è·¯å¾„

    Returns:
        è§£æåçš„ZIPæ–‡ä»¶ä¸‹è½½URL
    """
    try:
        # æ£€æŸ¥æ˜¯å¦ä¸ºHTTP/HTTPS URL
        if input_data.startswith(("http://", "https://")):
            logger.info(f"æ£€æµ‹åˆ°ç›´æ¥ä¸‹è½½é“¾æ¥: {input_data}")
            return input_data

        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶è·¯å¾„
        input_path = Path(input_data)

        if input_path.exists() and input_path.is_file():
            logger.info(f"æ£€æµ‹åˆ°æ–‡ä»¶è·¯å¾„: {input_data}")

            # å°è¯•è¯»å–JSONæ–‡ä»¶
            try:
                with open(input_path, "r", encoding="utf-8") as f:
                    json_data = json.load(f)

                # æ£€æŸ¥æ˜¯å¦åŒ…å« file_url é”®
                if "file_url" in json_data:
                    file_url = json_data["file_url"]
                    logger.info(f"ä»JSONæ–‡ä»¶è¯»å–åˆ°ä¸‹è½½é“¾æ¥: {file_url}")
                    return file_url
                else:
                    logger.error(
                        f"JSONæ–‡ä»¶ä¸­ç¼ºå°‘ 'file_url' é”®: {list(json_data.keys())}"
                    )
                    return None

            except json.JSONDecodeError as e:
                logger.error(f"JSONæ–‡ä»¶æ ¼å¼é”™è¯¯: {str(e)}")
                return None
            except Exception as e:
                logger.error(f"è¯»å–JSONæ–‡ä»¶å¤±è´¥: {str(e)}")
                return None

        # å¦‚æœä¸æ˜¯URLä¹Ÿä¸æ˜¯æœ‰æ•ˆæ–‡ä»¶è·¯å¾„ï¼Œå°è¯•å½“ä½œURLå¤„ç†
        logger.warning(f"è¾“å…¥æ•°æ®æ ¼å¼ä¸æ˜ç¡®ï¼Œå°è¯•å½“ä½œURLå¤„ç†: {input_data}")
        return input_data

    except Exception as e:
        logger.error(f"è§£æè¾“å…¥æ•°æ®å¤±è´¥: {str(e)}")
        return None


def log_results(results: Dict[str, Any]):
    """è®°å½•å¤„ç†ç»“æœåˆ°æ—¥å¿—"""
    logger.info("=== å¤„ç†ç»“æœ ===")

    if not results:
        logger.warning("æ²¡æœ‰ç”Ÿæˆä»»ä½•ç»“æœ")
        return

    for indicator, result in results.items():
        if result:
            logger.info(f"æŒ‡æ ‡: {result['indicator_name']} ({indicator})")
            logger.info(f"   SVGæ–‡ä»¶: {result['svg_path']}")
            logger.info(f"   è¾¹ç•Œæ–‡ä»¶: {result['bounds_path']}")
            logger.info(f"   æ•°æ®ç‚¹æ•°: {result['data_points']}")
            logger.info(
                f"   æ•°å€¼èŒƒå›´: {result['min_value']:.2f} - {result['max_value']:.2f} {result['unit']}"
            )
            logger.info(f"   å¹³å‡å€¼: {result['mean_value']:.2f} {result['unit']}")

            bounds = result["bounds_info"]["geographic_bounds"]
            logger.info(
                f"   ç»åº¦èŒƒå›´: {bounds['min_longitude']:.6f} - {bounds['max_longitude']:.6f}"
            )
            logger.info(
                f"   çº¬åº¦èŒƒå›´: {bounds['min_latitude']:.6f} - {bounds['max_latitude']:.6f}"
            )
            logger.info(
                f"   ä¸­å¿ƒç‚¹: ({bounds['center_longitude']:.6f}, {bounds['center_latitude']:.6f})"
            )
        else:
            logger.error(f"æŒ‡æ ‡ {indicator} å¤„ç†å¤±è´¥")


def format_output_dict(results: Dict[str, Any]) -> Dict[str, Dict[str, str]]:
    """æ ¼å¼åŒ–è¾“å‡ºå­—å…¸"""
    output = {}
    for indicator, result in results.items():
        if result and result.get("svg_path") and result.get("bounds_path"):
            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            svg_abs_path = str(Path(result["svg_path"]).resolve())
            coords = result.get("bounds_info")['geographic_bounds']
            min_long = coords["min_longitude"]
            max_long = coords["max_longitude"]
            min_lat = coords["min_latitude"]
            max_lat = coords["max_latitude"]

            # ä¿®æ­£ï¼šè¥¿åŒ—(w_n)ã€ä¸œåŒ—(e_n)ã€è¥¿å—(w_s)ã€ä¸œå—(e_s)çš„ç»çº¬åº¦é¡ºåº
            w_n = f"{min_long},{max_lat}"  # è¥¿åŒ—è§’
            e_n = f"{max_long},{max_lat}"  # ä¸œåŒ—è§’
            w_s = f"{min_long},{min_lat}"  # è¥¿å—è§’
            e_s = f"{max_long},{min_lat}"  # ä¸œå—è§’
            output[indicator] = [svg_abs_path, w_n, e_n, w_s, e_s]
    return output


def main():
    """ä¸»å…¥å£å‡½æ•°"""
    try:
        # è§£æå‘½ä»¤è¡Œå‚æ•°
        args = parse_arguments()

        # åˆ›å»ºæ—¶é—´æˆ³æ–‡ä»¶å¤¹ï¼ˆæå‰åˆ›å»ºä»¥ä¾¿ä¿å­˜æ—¥å¿—ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        timestamped_output_dir = Path(args.output_dir) / timestamp
        timestamped_output_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"åˆ›å»ºè¾“å‡ºç›®å½•: {timestamped_output_dir}")

        # é…ç½®æ—¥å¿—æ–‡ä»¶ä¿å­˜åˆ°æ—¶é—´æˆ³æ–‡ä»¶å¤¹
        log_file_path = timestamped_output_dir / "processing.log"

        # æ·»åŠ æ–‡ä»¶æ—¥å¿—å¤„ç†å™¨
        try:
            from .utils.logger import add_file_handler
        except ImportError:
            from utils.logger import add_file_handler
        add_file_handler(log_file_path, level=args.log_level)
        logger.info(f"æ—¥å¿—æ–‡ä»¶ä¿å­˜è‡³: {log_file_path}")

        # è·å–ZIP URLï¼šä¼˜å…ˆä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼Œå¦åˆ™ä»æ ‡å‡†è¾“å…¥è¯»å–
        zip_url = None
        if args.zip_url:
            zip_url = resolve_zip_url(args.zip_url)
        else:
            zip_url = read_zip_url_from_stdin()

        if not zip_url:
            logger.error(
                "å¿…é¡»æä¾›ZIPæ–‡ä»¶URLæˆ–JSONæ–‡ä»¶è·¯å¾„ï¼Œå¯ä»¥é€šè¿‡--zip-urlå‚æ•°æˆ–æ ‡å‡†è¾“å…¥æä¾›"
            )
            logger.error("ä½¿ç”¨ç¤ºä¾‹:")
            logger.error(
                "  python interface.py --zip-url 'https://example.com/data.zip'"
            )
            logger.error("  python interface.py --zip-url '/path/to/config.json'")
            logger.error("  echo 'https://example.com/data.zip' | python interface.py")
            logger.error("  echo '/path/to/config.json' | python interface.py")
            return 1

        # éªŒè¯URLæ ¼å¼
        if not zip_url.startswith(("http://", "https://")):
            logger.error(f"æ— æ•ˆçš„URLæ ¼å¼: {zip_url}")
            return 1

        logger.info(f"æ­£åœ¨å¤„ç†ZIPæ–‡ä»¶: {zip_url}")

        # ä½¿ç”¨æ°´è´¨æ•°æ®å¤„ç†å™¨ï¼ˆä¸è¦é‡å¤è®¾ç½®æ—¥å¿—ï¼‰
        # ä¸´æ—¶ä¿å­˜å½“å‰æ—¥å¿—å¤„ç†å™¨
        current_handlers = logging.getLogger().handlers[:]

        with WaterQualityProcessor(
            output_dir=str(timestamped_output_dir),
            grid_resolution=args.resolution,
            log_level=args.log_level,
        ) as processor:
            # æ¢å¤æ–‡ä»¶æ—¥å¿—å¤„ç†å™¨
            for handler in current_handlers:
                if handler not in logging.getLogger().handlers:
                    logging.getLogger().addHandler(handler)

            # å¤„ç†æ•°æ®
            results = processor.process_from_oss_zip(
                zip_url=zip_url,
                colormap=args.colormap,
                boundary_method=args.boundary_method,
                interpolation_method=args.interpolation_method,
                transparent_bg=not args.no_transparent,
                figsize=tuple(args.figsize),
            )

            # è®°å½•è¯¦ç»†ç»“æœåˆ°æ—¥å¿—
            log_results(results)

            # è¾“å‡ºPythonå­—å…¸æ ¼å¼ç»“æœ
            output_dict = format_output_dict(results)
            import json

            print(json.dumps(output_dict, indent=2, ensure_ascii=False))

            # è¿”å›æˆåŠŸçŠ¶æ€
            return 0

    except KeyboardInterrupt:
        error_msg = "ç”¨æˆ·ä¸­æ–­å¤„ç†"
        logger.error(error_msg)
        if "log_file_path" in locals():
            print(f"ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ã€‚è¯¦ç»†æ—¥å¿—è¯·æŸ¥çœ‹: {log_file_path}")
        return 1
    except Exception as e:
        import traceback

        error_msg = f"ç¨‹åºå´©æºƒ: {str(e)}"
        traceback_str = traceback.format_exc()

        # è®°å½•è¯¦ç»†çš„å´©æºƒä¿¡æ¯åˆ°æ—¥å¿—
        logger.error("=" * 50)
        logger.error("ç¨‹åºå‘ç”Ÿè‡´å‘½é”™è¯¯ï¼Œå³å°†é€€å‡º")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        logger.error("å®Œæ•´é”™è¯¯å †æ ˆ:")
        logger.error(traceback_str)
        logger.error("=" * 50)

        # ç¡®ä¿æ—¥å¿—å†™å…¥æ–‡ä»¶
        for handler in logging.getLogger().handlers:
            if hasattr(handler, "flush"):
                handler.flush()

        # å‘ç”¨æˆ·æä¾›æ—¥å¿—æŸ¥çœ‹æŒ‡å¼•
        if "log_file_path" in locals():
            print(f"ç¨‹åºè¿è¡Œå¤±è´¥: {str(e)}")
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯å’Œå †æ ˆè·Ÿè¸ªå·²ä¿å­˜åˆ°æ—¥å¿—æ–‡ä»¶: {log_file_path}")
            print("è¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ä»¥è·å–å®Œæ•´çš„é”™è¯¯è¯Šæ–­ä¿¡æ¯ã€‚")
        else:
            print(f"ç¨‹åºè¿è¡Œå¤±è´¥: {str(e)}")
            print("æ— æ³•è®¿é—®æ—¥å¿—æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è¾“å‡ºç›®å½•æƒé™ã€‚")

        return 1


if __name__ == "__main__":
    sys.exit(main())
