# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

import typing
import typing_extensions

from . import stream_types, types
from .runtime import DoNotUseDirectlyCallManager, BamlCallOptions

class LlmResponseParser:
    __options: DoNotUseDirectlyCallManager

    def __init__(self, options: DoNotUseDirectlyCallManager):
        self.__options = options

    def GenerateChatResponseGemeni(
        self, llm_response: str, baml_options: BamlCallOptions = {},
    ) -> types.ChatResponse:
        result = self.__options.merge_options(baml_options).parse_response(function_name="GenerateChatResponseGemeni", llm_response=llm_response, mode="request")
        return typing.cast(types.ChatResponse, result)

    def GenerateChatResponseOpenAI(
        self, llm_response: str, baml_options: BamlCallOptions = {},
    ) -> types.ChatResponse:
        result = self.__options.merge_options(baml_options).parse_response(function_name="GenerateChatResponseOpenAI", llm_response=llm_response, mode="request")
        return typing.cast(types.ChatResponse, result)

    def GenerateCommandGemeni(
        self, llm_response: str, baml_options: BamlCallOptions = {},
    ) -> types.Command:
        result = self.__options.merge_options(baml_options).parse_response(function_name="GenerateCommandGemeni", llm_response=llm_response, mode="request")
        return typing.cast(types.Command, result)

    def GenerateCommandOpenAI(
        self, llm_response: str, baml_options: BamlCallOptions = {},
    ) -> types.Command:
        result = self.__options.merge_options(baml_options).parse_response(function_name="GenerateCommandOpenAI", llm_response=llm_response, mode="request")
        return typing.cast(types.Command, result)

    

class LlmStreamParser:
    __options: DoNotUseDirectlyCallManager

    def __init__(self, options: DoNotUseDirectlyCallManager):
        self.__options = options

    def GenerateChatResponseGemeni(
        self, llm_response: str, baml_options: BamlCallOptions = {},
    ) -> stream_types.ChatResponse:
        result = self.__options.merge_options(baml_options).parse_response(function_name="GenerateChatResponseGemeni", llm_response=llm_response, mode="stream")
        return typing.cast(stream_types.ChatResponse, result)

    def GenerateChatResponseOpenAI(
        self, llm_response: str, baml_options: BamlCallOptions = {},
    ) -> stream_types.ChatResponse:
        result = self.__options.merge_options(baml_options).parse_response(function_name="GenerateChatResponseOpenAI", llm_response=llm_response, mode="stream")
        return typing.cast(stream_types.ChatResponse, result)

    def GenerateCommandGemeni(
        self, llm_response: str, baml_options: BamlCallOptions = {},
    ) -> stream_types.Command:
        result = self.__options.merge_options(baml_options).parse_response(function_name="GenerateCommandGemeni", llm_response=llm_response, mode="stream")
        return typing.cast(stream_types.Command, result)

    def GenerateCommandOpenAI(
        self, llm_response: str, baml_options: BamlCallOptions = {},
    ) -> stream_types.Command:
        result = self.__options.merge_options(baml_options).parse_response(function_name="GenerateCommandOpenAI", llm_response=llm_response, mode="stream")
        return typing.cast(stream_types.Command, result)

    