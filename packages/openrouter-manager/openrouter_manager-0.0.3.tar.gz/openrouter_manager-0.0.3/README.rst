|Project generated with PyScaffold|

\|
==

openrouter-manager
==================

**openrouter-manager** is a wrapper library for using **DeepSeek** with
**openrouter.ai**, facilitating integration with language models through
a simple and efficient API.

Main Features
-------------

- Wrapper for **DeepSeek** using **openrouter.ai**.
- Easy-to-use singleton class ``AiAgent``.
- Allows defining dynamic prompts with variables.
- Configuration via environment variables.

Installation
------------

It is recommended to install ``openrouter-manager`` in a virtual
environment to avoid dependency conflicts:

.. code:: bash

   pip install openrouter-manager

Requirements
------------

To use this library, the following environment
variables must be set:

- ``AIAGENT_API_KEY``: API Key for **openrouter.ai**.
- ``AIAGENT_API_URL``: URL for the **openrouter.ai** API
- ``AIAGENT_LLM_MODEL``: The model to use, e.g.,
  ``deepseek/deepseek-chat-v3-0324:free``.
- ``AIAGENT_PROMPT_FILE``: (Optional) Path to the text file containing the prompt
  to send to the LLM.
- ``AIAGENT_PROMPT_FOLDER``: (Optional) Path to the folder containing
  prompt files. If not set, the default is the current working directory.


At least one of the optional variables must be set. If the variable is the prompt folder, it must contain at least one .prompt file.

Example configuration in a ``.env`` file:

.. code:: ini

   AIAGENT_API_KEY="your_api_key_here"
   AIAGENT_PROMPT_FILE="path/to/prompt_file.txt"
   AIAGENT_PROMPT_FOLDER="path/to/"
   AIAGENT_API_URL="https://openrouter.ai/api/v1/chat/completions"
   AIAGENT_LLM_MODEL="deepseek/deepseek-chat-v3-0324:free"


Model Reference
---------------

To explore available models and their corresponding URLs, visit  
[https://openrouter.ai/deepseek](https://openrouter.ai/deepseek).

Usage 
-----

To use ``openrouter-manager``, first instantiate ``AiAgent``
and then call the ``resolve`` method, providing the necessary variables
to populate the prompt:

.. code:: python

   from openrouter_manager import AiAgent

   # Get the singleton instance of the agent
   agent = AiAgent()

   # Resolve the prompt with dynamic variables
   response = agent.resolve({"name": "John", "age": 30})

   print(response)  # Response generated by the LLM

If you have a prompt folder with multiple prompt files, you can change the
active prompt with the change_prompt method and know the name of the available prompt files with get_available_prompts method:

.. code:: python

   from openrouter_manager import AiAgent

   # Get the singleton instance of the agent
   agent = AiAgent()

   # Get available prompts in the folder
   available_prompts = agent.get_available_prompts()
   print(available_prompts)  # List of available prompt files ["example.prompt", "another_example.prompt"]

   # Change the active prompt to a specific file
   agent.change_prompt("example.prompt")

   # Resolve the prompt with dynamic variables
   response = agent.resolve({"name": "Alice", "age": 25})

   print(response)  # Response generated by the LLM

Contributing 
------------

If you would like to contribute to this project,
you can clone the repository and make modifications:

.. code:: bash

   git clone https://github.com/your_username/openrouter-manager.git
   cd openrouter-manager

Contributions are welcome. Make sure to follow best coding practices and
document your changes.

License
-------

This project is **open-source**, owned by **Koral Advanced Technology**,
and developed by **Lenin David Lozano**. It is freely available for use
and modification under the **MIT License**. See the ``LICENSE`` file for
more details. .. pyscaffold-notes:

Note
====

This project has been set up using PyScaffold 4.6. For details and usage
information on PyScaffold see https://pyscaffold.org/.

.. |Project generated with PyScaffold| image:: https://img.shields.io/badge/-PyScaffold-005CA0?logo=pyscaffold
   :target: https://pyscaffold.org/