Metadata-Version: 2.3
Name: oasis-sdk
Version: 0.1.0
Summary: Oasis LLM Proxy Client
Author: ì‹ ê°•ì‹ / AIì†”ë£¨ì…˜íŒ€
Author-email: kangsik.shin@hanwha.com
Requires-Python: >=3.11,<4.0
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Dist: langchain-openai (>=0.3.28,<0.4.0)
Requires-Dist: openai (>=1.97.0,<2.0.0)
Description-Content-Type: text/markdown

# OASIS-SDK

## 1. Concept

OASIS-LLM-PROXY-CLIENTëŠ” OpenAI, Azure OpenAI ë“± ë‹¤ì–‘í•œ LLM Providerì˜ ê³µì‹ SDK ë° LangChainì„ ì–‡ê²Œ wrappingí•˜ì—¬, ì‚¬ë‚´ ê·œì¹™ì— ë§žëŠ” í•„ë“œ ìž…ë ¥ê³¼ í”„ë¡ì‹œ ì„œë²„ë¥¼ í†µí•œ í‚¤ ì£¼ìž…ì„ ì§€ì›í•˜ëŠ” Python ë¼ì´ë¸ŒëŸ¬ë¦¬ìž…ë‹ˆë‹¤. ì›ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ìˆ˜ ìžˆë„ë¡ ì„¤ê³„ë˜ì–´, ê¸°ì¡´ SDKì™€ LangChainì˜ í™•ìž¥ì„±ê³¼ í˜¸í™˜ì„±ì„ ìµœëŒ€í•œ ë³´ìž¥í•©ë‹ˆë‹¤.

## 2. Usage

### 2.1 install

```
pip install oasis-sdk
```

### 2.2 example

**0. parameters**

[required]

- user_id: ì‚¬ìš©ìžì˜ id
- workspace_id: ì‚¬ìš©ìžì˜ workspace id
- tenant_id: ì‚¬ìš©ìžì˜ tenant id
- proxy_url: Llm Proxy Server

[optional]

- user_ip: ì‚¬ìš©ìžì˜ ip (defualt=127.0.0.1)
- plugin_name: í˜¸ì¶œí•œ ì‹œìŠ¤í…œ ëª… (ex, chatbot, mcp1, rag-mcp, ..., default=default-plugin)

[auto]

- root_id: í´ë¼ì´ì–¸íŠ¸ ìƒì„±ì‹œ ë°œê¸‰
- req_id: ìš”ì²­ì‹œë§ˆë‹¤ ë°œê¸‰

ðŸ“ **ì£¼ì˜**

- 1ë²ˆì˜ ì—°ì†ì ì¸ ìˆ˜í–‰ì—ì„œ root_idëŠ” ê³ ì •ë˜ì–´ì•¼ í•¨
- ì—°ê³„ë˜ëŠ” ì‹œìŠ¤í…œì—ì„œëŠ” í´ë¼ì´ì–¸íŠ¸ ìƒì„±ì‹œ ì´ˆê¸° ë°œê¸‰ëœ root_idë¥¼ ì£¼ìž…í•˜ì—¬ ì‚¬ìš©

#### 2.2.1 SDK

**1. openai**

```python
# ë™ê¸° í´ë¼ì´ì–¸íŠ¸
client = OasisOpenAI(
    user_id="user_id",
    workspace_id="workspace_id",
    tenant_id="tenant_id",
    proxy_url="llm_proxy_server",
    user_ip="user_ip",
    plugin_name="your_system"
)

# ë™ê¸° í˜¸ì¶œ
resp = client.chat.completions.create(
    model="model",
    messages=[{"role": "user", "content": "ì•ˆë…•?"}],
)

# ë™ê¸° ìŠ¤íŠ¸ë¦¼
stream = client.chat.completions.create(
    model="model",
    messages=[{"role": "user", "content": "ì•ˆë…•?"}],
    stream=True,
)

# ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸
aync_client = OasisAsyncOpenAI(
    user_id="user_id",
    workspace_id="workspace_id",
    tenant_id="tenant_id",
    proxy_url="llm_proxy_server",
    user_ip="user_ip",
    plugin_name="your_system"
)

# ë¹„ë™ê¸° í˜¸ì¶œ
resp = await aync_client.chat.completions.create(
    model="model",
    messages=[{"role": "user", "content": "ì•ˆë…•?"}],
)

# ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¼
stream = await aync_client.chat.completions.create(
    model="model",
    messages=[{"role": "user", "content": "ì•ˆë…•?"}],
    stream=True,
)
```

**2. azure openai**

```python
# ë™ê¸° í´ë¼ì´ì–¸íŠ¸
client = OasisAzureOpenAI(
    user_id="user_id",
    workspace_id="workspace_id",
    tenant_id="tenant_id",
    proxy_url="llm_proxy_server",
    user_ip="user_ip",
    plugin_name="your_system"
)

# ë™ê¸° í˜¸ì¶œ
resp = client.chat.completions.create(
    model="deployment",
    messages=[{"role": "user", "content": "ì•ˆë…•?"}],
)

# ë™ê¸° ìŠ¤íŠ¸ë¦¼
stream = client.chat.completions.create(
    model="model",
    messages=[{"role": "user", "content": "ì•ˆë…•?"}],
    stream=True,
)

# ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸
aync_client = OasisAsyncAzureOpenAI(
    user_id="user_id",
    workspace_id="workspace_id",
    tenant_id="tenant_id",
    proxy_url="llm_proxy_server",
    user_ip="user_ip",
    plugin_name="your_system"
)

# ë¹„ë™ê¸° í˜¸ì¶œ
resp = await aync_client.chat.completions.create(
    model="model",
    messages=[{"role": "user", "content": "ì•ˆë…•?"}],
)

# ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¼
stream = await aync_client.chat.completions.create(
    model="model",
    messages=[{"role": "user", "content": "ì•ˆë…•?"}],
    stream=True,
)
```

#### 2.2.2 Langchain

**1. openai**

```python
llm = OasisChatOpenAI(
    user_id="user_id",
    workspace_id="workspace_id",
    tenant_id="tenant_id",
    proxy_url="llm_proxy_server",
    user_ip="user_ip",
    plugin_name="your_system"
)

# ë™ê¸° í˜¸ì¶œ
resp = llm.invoke("ì•ˆë…• Azure LangChain!")

# ë¹„ë™ê¸° í˜¸ì¶œ
resp = await llm.ainvoke("ì•ˆë…• Azure LangChain!")

# ë™ê¸° ìŠ¤íŠ¸ë¦¼
resp = llm.stream("ì•ˆë…• Azure LangChain!")

# ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¼
resp = await llm.astream("ì•ˆë…• Azure LangChain!")
```

**2. azure openai**

```python
llm = OasisAzureChatOpenAI(
    user_id="user_id",
    workspace_id="workspace_id",
    tenant_id="tenant_id",
    proxy_url="llm_proxy_server",
    user_ip="user_ip",
    plugin_name="your_system"
)

# ë™ê¸° í˜¸ì¶œ
resp = llm.invoke("ì•ˆë…• Azure LangChain!")

# ë¹„ë™ê¸° í˜¸ì¶œ
resp = await llm.ainvoke("ì•ˆë…• Azure LangChain!")

# ë™ê¸° ìŠ¤íŠ¸ë¦¼
resp = llm.stream("ì•ˆë…• Azure LangChain!")

# ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¼
resp = await llm.astream("ì•ˆë…• Azure LangChain!")
```

## 3. Dependency

- python 3.11.x
- openai 1.97.0
- langchain-openai 0.3.28

