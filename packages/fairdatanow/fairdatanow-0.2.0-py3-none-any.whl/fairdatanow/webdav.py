"""Instantly find and access all your Nextcloud data files"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../notebooks/10_exploring-your-remote-data.ipynb.

# %% auto 0
__all__ = ['RemoteData']

# %% ../notebooks/10_exploring-your-remote-data.ipynb 19
import nc_py_api 
from nc_py_api import Nextcloud 

import polars as pl 
import itables
from itables.widget import ITable
import os 
from pathlib import Path 
import time 
import re 
from IPython.display import HTML, display 

# %% ../notebooks/10_exploring-your-remote-data.ipynb 20
def _node_to_dataframe(fsnode): 
    '''Convert `fsnode` object to polars a single row polars dataframe.'''

    df = pl.DataFrame({'path': fsnode.user_path, 'size': fsnode.info.size, 'mimetype': fsnode.info.mimetype, 'modified': fsnode.info.last_modified, 
                   'isdir': fsnode.is_dir, 'ext': os.path.splitext(fsnode.user_path)[1]})

    return df 


class RemoteData(object): 
    
    # See: https://help.nextcloud.com/t/using-nc-py-api-i-cant-download-any-file-due-to-ssl-certificte-verify-failed/194019 
    nc_py_api.options.NPA_NC_CERT = False 
    
    # keep full dataframe 
    itables.options.maxBytes = 0
    itables.init_notebook_mode()

    def __init__(self, configuration, searchBuilder={}): 
        '''Recursively scan the contents of a remote webdav server as specified by `configuration`. 
        '''

        # parse configuration 
        m = re.match('(^https://[^/]+/)(.*)', configuration['url'])
        nextcloud_url, self.cache_dir = m.groups()
        nc_auth_user = configuration['user']
        nc_auth_pass = configuration['password'] 

        print(f'Please wait while scanning all file paths in remote folder...')
        
        # Instantiate Nextcloud client 
        self.nc = Nextcloud(nextcloud_url=nextcloud_url, nc_auth_user=nc_auth_user, nc_auth_pass=nc_auth_pass)

        # query webdav server to obtain file listing 
        fs_nodes_list = self.nc.files.listdir(self.cache_dir, depth=-1, exclude_self=False) 
        
        n_paths = len(fs_nodes_list)

        # initialize polars dataframe with first row to fix schema 
        self.df = _node_to_dataframe(fs_nodes_list[0])

        for fsnode in fs_nodes_list[1:]: 
            self.df.extend(_node_to_dataframe(fsnode))

        # create interactive table 
        self.itable = ITable(
                    self.df,
                    layout={"top1": "searchBuilder"},
                    select=True,
                    searchBuilder=searchBuilder, 
                    scrollY="500px", scrollCollapse=True, paging=False, 
                ) 

        print(f"Ready building file table for '{self.cache_dir}', Total number of files and directories: {n_paths}   ")

    
    def download_selected(self, cache_dir=None): 
        '''Download selected files (blue rows) from `table` to default local cache directory. 
        
        A custom `cache_dir` can be specified. '''
        
        # create cache path 
        if cache_dir is None: 
            cache_path = Path.home().joinpath('.cache', 'fairdatanow')
        else: 
            cache_path = Path.home().joinpath('.cache', cache_dir)
    
        os.makedirs(cache_path, exist_ok=True)
    
        # obtain remote paths and remote timestamps 
        remote_path_list = [self.itable.df['path'][n] for n in self.itable.selected_rows]
        remote_modified_list = [self.itable.df['modified'][n] for n in self.itable.selected_rows]
        remote_isdir_list = [self.itable.df['isdir'][n] for n in self.itable.selected_rows]
        
        n_files = len(remote_path_list)
       
        for i, [remote_path, remote_modified, remote_isdir] in enumerate(zip(remote_path_list, remote_modified_list, remote_isdir_list)): 
    
            # only download actual files 
            if not remote_isdir:   
                remote_directory = os.path.dirname(remote_path)
                local_directory = cache_path.joinpath(remote_directory) # I guess this will not yet work for Windows
                
                # create directory structure inside cache 
                os.makedirs(local_directory, exist_ok=True) 
            
                # get remote epoch time  
                remote_modified_epoch_time = remote_modified.timestamp()
            
                # construct corresponding local path 
                local_path = cache_path.joinpath(remote_path) 
            
                # check if local file exists and if modification times are similar 
                is_local = local_path.exists()  
            
                is_similar = False 
                local_modified_epoch_time = None 
                if is_local: 
                    local_modified_epoch_time = os.stat(local_path).st_mtime
                    if local_modified_epoch_time == remote_modified_epoch_time: 
                        is_similar = True 
                        
                # download from nextcloud 
                if not is_similar: 
                    print(f'[{i}/{n_files - 1}] Timestamps do no match: {remote_modified_epoch_time} vs {local_modified_epoch_time}', end='\r')
                    print(f'[{i}/{n_files - 1}] Downloading to: {local_path}                                                       ' , end='\r')
                      
                    # write to cache 
                    with open(local_path, 'bw') as fh: 
                        self.nc.files.download2stream(remote_path, fh) 
                        
                    # adjust last modified timestamp 
                    now = int(time.time())
                    os.utime(local_path, (now, remote_modified_epoch_time)) 
                    
        print(f"Ready with downloading {n_files} selected remote files to local cache: {cache_path}                                                                      ")


