Metadata-Version: 2.4
Name: loadimg
Version: 0.5.0
Summary: a python package for loading images
Home-page: https://github.com/not-lain/loadimg
Author-email: hhichri60@gmail.com
License: Apache 2.0 License
Classifier: Topic :: Utilities
Classifier: Programming Language :: Python :: 3.9
Requires: setuptools
Requires: wheel
Requires: typing
Requires: pillow
Requires: numpy
Requires: requests
Requires: tqdm
Description-Content-Type: text/markdown
License-File: LICENSE
Provides-Extra: testing
Requires-Dist: setuptools; extra == "testing"
Requires-Dist: wheel; extra == "testing"
Requires-Dist: typing; extra == "testing"
Requires-Dist: pillow; extra == "testing"
Requires-Dist: numpy; extra == "testing"
Requires-Dist: requests; extra == "testing"
Requires-Dist: ruff; extra == "testing"
Requires-Dist: pytest; extra == "testing"
Requires-Dist: tqdm; extra == "testing"
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license
Dynamic: license-file
Dynamic: provides-extra
Dynamic: requires
Dynamic: summary

# loadimg

[![Downloads](https://static.pepy.tech/badge/loadimg)](https://pepy.tech/project/loadimg)

A python package for loading and converting images

## How to use
Installation
```
pip install loadimg
```
Usage
```python
from loadimg import load_img
load_img(any_img_type_here,output_type="pil",input_type="auto") 
```
Supported types
- Currently supported **input types** :
	- numpy
	- pillow 
	- str(both path and url)
	- base64
	- **auto**

- Currently supported **output types** :
	- numpy
	- pillow
	- str
	- base64


<p align="center">
  <img src="https://github.com/not-lain/loadimg/blob/main/loadimg.png?raw=true">
</p>


The base64 is now compatible with most APIs, now supporting Hugging Face, OpenAI and FAL

```python
from loadimg import load_img
from huggingface_hub import InferenceClient

# or load a local image
my_b64_img = load_img("https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg", output_type="base64" ) 

client = InferenceClient(api_key="hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx")

messages = [
	{
		"role": "user",
		"content": [
			{
				"type": "text",
				"text": "Describe this image in one sentence."
			},
			{
				"type": "image_url",
				"image_url": {
					"url": my_b64_img # base64 allows using images without uploading them to the web
				}
			}
		]
	}
]

stream = client.chat.completions.create(
    model="meta-llama/Llama-3.2-11B-Vision-Instruct", 
	messages=messages, 
	max_tokens=500,
	stream=True
)

for chunk in stream:
    print(chunk.choices[0].delta.content, end="")
```


## Contributions

- [x] - thanks to [@KingNish24](https://github.com/KingNish24) for improving base64 support and adding the `input_type` parameter and adding the `url` output type
- [x] thanks to [@Saptarshi-Bandopadhyay](https://github.com/Saptarshi-Bandopadhyay) for supporting base64 and improving the docstrings
- [x] thanks to [@Abbhiishek](https://github.com/Abbhiishek) for improving image naming
- [x] thanks to [@BouajilaHamza](https://github.com/BouajilaHamza) for adding multiple image support
<a href="https://github.com/not-lain/loadimg/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=not-lain/loadimg" />
</a>
