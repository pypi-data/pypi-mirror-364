# Example DeepTeam Configuration
# This demonstrates the new YAML structure with improved organization

# Red teaming models (use standard models)
models:
  simulator: gpt-3.5-turbo-0125
  evaluation: gpt-4o
  
  # Alternative: With provider specification
  # simulator:
  #   provider: anthropic
  #   model: claude-3-5-sonnet-20241022
  #   temperature: 0.7
  # evaluation:
  #   provider: openai
  #   model: gpt-4o
  #   temperature: 0.1

# Target system configuration (uses custom model)
target:
  purpose: "A helpful AI assistant"
  
  # Option 1: Simple model specification (for testing foundational models directly)
  # model: gpt-3.5-turbo
  
  # Option 1b: With provider specification
  # model:
  #   provider: anthropic
  #   model: claude-3-haiku-20240307
  #   temperature: 0.5
  
  # Option 2: Custom DeepEval model
  model:
    provider: custom
    file: "tests/test_callback.py"
    class: "CustomFireworksLLM"

# System configuration (renamed from options/simulation)
system_config:
  max_concurrent: 10                    # Maximum concurrent operations
  attacks_per_vulnerability_type: 3     # Number of attacks per vulnerability type
  run_async: true                       # Whether to run operations asynchronously
  ignore_errors: false                  # Whether to continue on errors
  output_folder: "results"              # Folder to save results

# Vulnerabilities to test
default_vulnerabilities:
  - name: "Bias"
    types: ["race", "gender"]
  
  - name: "Toxicity"
    types: ["profanity", "insults"]

# Custom vulnerability types
custom_vulnerabilities:
  - name: "CustomVulnerability"
    custom_name: "Business Logic"
    types: ["access_control", "privilege_escalation"]

# Attack methods
attacks:
  - name: "Prompt Injection"
    weight: 1.0
  
  - name: "Leetspeak"
    weight: 0.8
  
  - name: "ROT-13"
    weight: 0.6
  
  - name: "Base64"
    weight: 0.7
  
  - name: "Roleplay"
    weight: 0.9
    