# ğŸ§ª Revenium Driver Testing Suite

This folder contains comprehensive test scripts for all Revenium Griptape drivers. Each driver has its own dedicated test script that validates functionality, integration, and error handling.

## ğŸ“ Test Scripts

| Script | Driver | Description |
|--------|--------|-------------|
| `test_openai_driver.py` | ReveniumOpenAiDriver | Tests OpenAI integration with Tier 1 middleware |
| `test_anthropic_driver.py` | ReveniumAnthropicDriver | Tests Anthropic integration with Tier 1 middleware |
| `test_ollama_driver.py` | ReveniumOllamaDriver | Tests local Ollama integration with Tier 1 middleware |
| `test_litellm_driver.py` | ReveniumLiteLLMDriver | Tests LiteLLM integration for 100+ providers |
| `test_universal_driver.py` | ReveniumDriver | Tests universal auto-detection and factory functionality |
| `run_all_tests.py` | Test Runner | Runs all test scripts and provides summary |

## ğŸš€ Quick Start

### Run All Tests
```bash
cd testing
python run_all_tests.py
```

### Run Specific Tests
```bash
# Run only OpenAI and Universal tests
python run_all_tests.py --tests openai,universal

# Skip tests that require special setup
python run_all_tests.py --skip ollama,litellm
```

### Run Individual Tests
```bash
# Test specific driver
python test_openai_driver.py
python test_anthropic_driver.py
python test_universal_driver.py
```

## âš™ï¸ Environment Setup

Create a `.env` file in the project root (not in testing folder):

```bash
# Required for usage metering (optional for testing)
REVENIUM_METERING_API_KEY=your_revenium_api_key_here
REVENIUM_METERING_BASE_URL=https://api.revenium.io/meter

# Tier 1 Provider API Keys
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
OLLAMA_HOST=http://localhost:11434  # Default for local Ollama

# Tier 2 Provider API Keys (via LiteLLM)
GEMINI_API_KEY=your_google_gemini_api_key_here
COHERE_API_KEY=your_cohere_api_key_here
AZURE_API_KEY=your_azure_openai_api_key_here
AWS_ACCESS_KEY_ID=your_aws_access_key_here        # For Bedrock
AWS_SECRET_ACCESS_KEY=your_aws_secret_key_here    # For Bedrock

# Add other provider keys as needed - see LiteLLM docs
```

## ğŸ“‹ Prerequisites

### Base Requirements
```bash
pip install revenium-griptape
pip install python-dotenv
pip install requests  # For Ollama connectivity tests
```

### Middleware Packages (Install as needed)
```bash
# Tier 1 middleware (provider-specific)
pip install revenium-middleware-openai
pip install revenium-middleware-anthropic  
pip install revenium-middleware-ollama

# Tier 2 middleware (universal LiteLLM)
pip install revenium-middleware-litellm
pip install litellm
```

### Special Setup Requirements

#### Ollama (Local Models)
1. Install Ollama: https://ollama.ai
2. Start the service: `ollama serve`
3. Pull a model: `ollama pull llama2`

#### LiteLLM (100+ Providers)
- Install LiteLLM: `pip install litellm`
- Set appropriate API keys for providers you want to test
- See [LiteLLM providers](https://docs.litellm.ai/docs/providers) for complete list

## ğŸ§ª What Each Test Does

### OpenAI Driver Tests (`test_openai_driver.py`)
- âœ… Import verification
- âœ… Driver creation with various parameters
- âœ… Griptape Agent integration
- âœ… Middleware detection
- âœ… Real API calls (if API key available)
- âœ… Metadata injection and filtering
- âœ… Inheritance chain validation

### Anthropic Driver Tests (`test_anthropic_driver.py`)
- âœ… Import verification
- âœ… Driver creation with Claude models
- âœ… Model variant testing (haiku, sonnet, opus)
- âœ… Middleware detection
- âœ… Real API calls (if API key available)
- âœ… Metadata injection and filtering
- âœ… Inheritance chain validation

### Ollama Driver Tests (`test_ollama_driver.py`)
- âœ… Ollama service availability check
- âœ… Driver creation with local models
- âœ… Model discovery from running Ollama instance
- âœ… Middleware detection
- âœ… Real API calls to local Ollama (if running)
- âœ… Metadata injection (no API key filtering needed)
- âœ… Inheritance chain validation

### LiteLLM Driver Tests (`test_litellm_driver.py`)
- âœ… Dependency checking (LiteLLM + middleware)
- âœ… Driver creation for multiple providers
- âœ… Message conversion testing
- âœ… Parameter building validation
- âœ… Real API calls (if provider keys available)
- âœ… Metadata injection and filtering
- âœ… BasePromptDriver inheritance validation

### Universal Driver Tests (`test_universal_driver.py`)
- âœ… Provider auto-detection from model names
- âœ… Tier 1 and Tier 2 driver creation
- âœ… Existing driver wrapping
- âœ… Metadata propagation to wrapped drivers
- âœ… Provider forcing for testing
- âœ… Error handling for invalid inputs
- âœ… Real API integration across providers

## ğŸ“Š Understanding Test Results

### Success Indicators
- âœ… **Green checkmarks**: Test passed successfully
- ğŸ¯ **Summary sections**: Overall test completion
- ğŸš€ **Ready messages**: Component is production-ready

### Warning Indicators
- âš ï¸ **Yellow warnings**: Non-critical issues (missing optional dependencies)
- ğŸ’¡ **Blue info**: Helpful tips or next steps

### Error Indicators
- âŒ **Red X marks**: Test failures that need attention
- ğŸ’¥ **Explosions**: Unexpected errors
- â° **Clock**: Timeout issues

## ğŸ”§ Troubleshooting

### Common Issues

#### Import Errors
```
âŒ Failed to import: No module named 'revenium_griptape'
```
**Solution**: Make sure you're running from the testing folder and the package is installed.

#### Missing Middleware
```
âš ï¸ revenium-middleware-openai not available
```
**Solution**: Install the middleware: `pip install revenium-middleware-openai`

#### API Key Issues
```
âŒ API call failed: Invalid API key
```
**Solution**: Check your `.env` file and API key validity.

#### Ollama Connection Issues
```
âŒ Cannot connect to Ollama
```
**Solution**: Start Ollama service: `ollama serve`

#### LiteLLM Missing
```
âŒ LiteLLM package required but not found
```
**Solution**: Install LiteLLM: `pip install litellm`

### Debug Mode
For more detailed output, check the individual test scripts which include debug logging.

## ğŸ’¡ Testing Strategy

### Development Testing
Run tests frequently during development:
```bash
# Quick smoke test (universal driver only)
python test_universal_driver.py

# Full validation
python run_all_tests.py
```

### CI/CD Testing
For automated testing environments:
```bash
# Skip tests requiring special setup
python run_all_tests.py --skip ollama

# Test only core functionality
python run_all_tests.py --tests openai,universal
```

### Production Validation
Before deploying:
```bash
# Full test suite with real API keys
python run_all_tests.py
```

## ğŸ¯ Next Steps

After successful testing:

1. **Install middleware** for providers you plan to use
2. **Set up environment variables** for your production environment
3. **Use `ReveniumDriver(model="your-model")`** in your applications
4. **Monitor usage** in your Revenium dashboard

The testing suite validates that the universal driver system is ready for production use with any LLM provider! ğŸš€ 