{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `model_checker` Python API Jupyter notebook\n",
    "This jupyter notebook will go through the basics of how to use the `model_checker` package from scratch in python. It will also go over how to use some of the built-in features that make exploring semantics already in `theory_lib` much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the basic imports. If you want to make a theory from scratch, see the `semantic.py` and `operator.py` files for the theories in `theory_lib`. This notebook will use the default bilateral truthmaker semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_checker\n",
    "from model_checker.theory_lib import default\n",
    "# from model_checker import default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need operators. We can define these, or, since we are using the default semantics as an example, we can import them from a theory in theory_lib. Even with that, we have two options. We can import a group of default operators for that theory, or we can import specific operators from the operator file. In either case, operators are imported through a Syntactic.OperatorCollection object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the default operators of the theory:\n",
    "operators = default.default_operators\n",
    "assert isinstance(operators, model_checker.syntactic.OperatorCollection)\n",
    "\n",
    "# import specific operators manually:\n",
    "operators = model_checker.syntactic.OperatorCollection(default.operators.NegationOperator, # Negation\n",
    "                                            default.operators.AndOperator, # And\n",
    "                                            default.operators.OrOperator, # Or\n",
    "                                            default.operators.IdentityOperator # Propositional Identity\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the default `OperatorCollection` object for the default semantics contains more operators than those seen in the manual import, the two `operators` objects above are not equivalent. \n",
    "\n",
    "We now need to pick a theorem to test. The operators have names associated to them, and it is these that you type in the string that represents the theorem. You can see the names of these operators by printing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for operator in operators:\n",
    "    print(operator) # hopefully it's clear which operators correspond to which! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to import the syntax. To do this, we need a theorem to get a model for. A `Syntax` object will represent the theorems inputted as strings in a way that `model_checker` can understand. It doesn't really have any attributes useful to the user. For more details, see the `syntactic.py` module of `model_checker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premises = [\"\\neg (P \\wedge Q)\"]\n",
    "conclusions = [\"(\\neg P \\vee \\neg Q)\"]\n",
    "syntax = model_checker.syntactic.Syntax(premises, conclusions, operators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make the semantics. We will just use the one in the `theory_lib` for default semantics. A `Semantics` object, of which `Semantics` is an instance, has limited user-useful attributes, which are shown below. For more details, see the `SemanticDefaults` class of the `model.py` module of `model_checker` and the `[X]Semantics` object found in the `semantic.py` module of the theory you are interested in. To initialize as a `Semantics` object, feed it the settings you want the semantics to have. We will just use the theory's default settings for ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_settings = default.Semantics.DEFAULT_EXAMPLE_SETTINGS\n",
    "print(default_settings)\n",
    "semantics = default.Semantics(default_settings)\n",
    "print(str(semantics))\n",
    "print(semantics.N) # number of atomic states in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last ingredient we need before we get the ball rolling is a `Proposition` class. As with the semantics there is a default for the default semantics in its module; for details on how to make one from the ground up, see the `PropositionDefaults` class in the `model.py` module of `model_checker` and the `[X]Proposition` object in the `semantic.py` modules of the theories in `theory_lib`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposition_class = default.Proposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a syntax with a specific example, a semantics, and a definition of a proposition, we can in principle find all the constraints that would be needed to see if a countermodel exists. And indeed this is what we do next, by defining a `ModelConstraints` object. Since we can impose additional constraints on the model (e.g., only contingent sentences, only non-empty verifiers, only non-null falsifiers), we also pass a `settings` dictionary into the `ModelConstraints` object. The `Semantics` has a default setting dictionary, which was printed in the cell above; we will use this for now. \n",
    "\n",
    "A `Model_Constraints` object has many user-useful attributes, mainly in the form of Z3 constraints. Z3's constraints are in prefix notation; also for more details see the specific implementations of constraints in the `Semantics` object and `Proposition` object you have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = semantics.DEFAULT_EXAMPLE_SETTINGS\n",
    "model_constraints = model_checker.model.ModelConstraints(settings, syntax, semantics, proposition_class)\n",
    "\n",
    "# print(model_constraints.frame_constraints)\n",
    "# print(model_constraints.model_constraints)\n",
    "# print(model_constraints.premise_constraints)\n",
    "# print(model_constraints.conclusion_constraints)\n",
    "print(model_constraints.all_constraints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These may seem initially opaque, so it is recommended to see the specific implementations of constraints in the `Semantics` object and `Proposition` object you have. Additionally note that any quantifiers in definitions are finite—i.e. we do not use the default quantifiers from 'z3'. This is because this is much faster for small state spaces. \n",
    "\n",
    "Now we define the model structure. This will be user-defined (?), but mostly just for printing; the bulk of it is defined in the `ModelDefaults` class of the `model.py` module of `model_checker`. We also need to feed in some settings; we can use the settings from above as default in case we don't want anything interesting. \n",
    "\n",
    "Defining this object automatically solves the constraints and finds a model. (i.e. this is where the Z3 magic happens) We can print the `z3` model—which is sometimes useful for debugging—if a model was found or the `z3` `unsat_core` (see here for more details: https://z3prover.github.io/api/html/ml/Z3.Solver.html) if no model was found. We can also print the model in a user-friendly way, which is what the last step does. \n",
    "\n",
    "There are many user-useful print methods defined in the model structure, both in the theory-specific object (entire point of defining this object) and the default (in the position mentioned in the second paragraph). It is recommended to look at those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_structure = default.ModelStructure(model_constraints, settings)\n",
    "\n",
    "# This is where the fix is - interpret sentences before printing\n",
    "sentences = model_structure.premises + model_structure.conclusions\n",
    "model_structure.interpret(sentences)\n",
    "\n",
    "# Now print the results\n",
    "model_structure.print_all(settings, \"DeMorgan's\", \"Default Semantics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No countermodels found, as expected for DeMorgan's Law! Now we will try a different theorem, for which we might expect countermodels in a non-classical semantics. The good thing is, we only need to redefined the `Syntax` object, `ModelConstraints` object, and the `ModelStructure` object—the semantics and proposition class are reusable from before, highlighting the convenient modularity of the `model_checker`! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premises2 = [\"P \\vee Q\"]\n",
    "conclusions2 = [\"(P) \\vee (Q)\"]\n",
    "\n",
    "DEFAULT_GENERAL_SETTINGS = {\n",
    "        \"print_impossible\": False,\n",
    "        \"print_constraints\": False,\n",
    "        \"print_z3\": False,\n",
    "        \"save_output\": False,\n",
    "        \"maximize\": False,\n",
    "    }\n",
    "\n",
    "for key in DEFAULT_GENERAL_SETTINGS:\n",
    "    settings[key] = DEFAULT_GENERAL_SETTINGS[key]\n",
    "\n",
    "syntax2 = model_checker.syntactic.Syntax(premises2, conclusions2, operators)\n",
    "model_constraints2 = model_checker.model.ModelConstraints(settings, syntax2, semantics, proposition_class)\n",
    "model_structure2 = default.ModelStructure(model_constraints2, settings)\n",
    "\n",
    "# Interpret sentences before printing\n",
    "sentences = model_structure2.premises + model_structure2.conclusions\n",
    "model_structure2.interpret(sentences)\n",
    "\n",
    "# Now print the results\n",
    "model_structure2.print_all(settings, \"Distribution\", \"Default Semantics\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
