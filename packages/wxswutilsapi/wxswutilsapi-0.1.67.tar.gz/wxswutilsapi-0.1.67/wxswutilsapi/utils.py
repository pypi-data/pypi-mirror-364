import ast
import base64
import json
import re
import zlib
import os
import numpy as np

def predict_to_chartdata(data):
    try:
        labels = []
        xs = []
        ys = {}

        # è§£ææ•°æ®
        for entry in data:
            if entry['used'] == '1':
                predict_data = entry['predict']
                if isinstance(predict_data, str):
                    predict_list =  ast.literal_eval(predict_data)
                else:
                    predict_list = predict_data 
                xs.append(entry['time'])  # è®°å½•æ—¶é—´æˆ³
                for predict in predict_list:
                    component = predict['component']
                    value = predict['value']

                    # æ·»åŠ åˆ°labels
                    if component not in labels:
                        labels.append(component)
                        ys[component] = []

                    # æŒ‰ç»„ä»¶å­˜å‚¨æ•°å€¼
                    ys[component].append(value)

        # æ„å»ºysä¸ºåµŒå¥—æ•°ç»„
        ys_list = [ys[label] for label in labels]

        # ç”Ÿæˆæœ€ç»ˆçš„ç»“æ„
        result = {
            'labels': labels,
            'xs': xs,
            'ys': ys_list
        }

        return result
    except Exception as e:
        raise ValueError(f"Unexpected error in predict_to_chartdata:{str(e)}") from e
        
def predict_average(data,resultIsObject = False):
    try:
        # åˆå§‹åŒ–ç”¨äºå­˜å‚¨æ¯ä¸ªç‰©è´¨çš„å€¼
        values = {}

        # è§£ææ•°æ®
        for entry in data:
            if entry['used'] == '1':
                predict_data = entry['predict']
                # æ£€æŸ¥ predict_data æ˜¯å¦ä¸ºå­—ç¬¦ä¸²ï¼Œå¦‚æœæ˜¯åˆ™è½¬æ¢
                if isinstance(predict_data, str):
                    predict_list = ast.literal_eval(predict_data)
                else:
                    predict_list = predict_data 
                for predict in predict_list:
                    component = predict['component']
                    value = predict['value']

                    # å¦‚æœç‰©è´¨è¿˜æ²¡æœ‰å‡ºç°åœ¨valuesä¸­ï¼Œåˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨
                    if component not in values:
                        values[component] = []

                    # å°†è¯¥ç‰©è´¨çš„å€¼æ·»åŠ åˆ°åˆ—è¡¨ä¸­
                    values[component].append(value)

        average_result = None
        # è®¡ç®—å»æ‰ä¸¤ä¸ªæœ€å¤§å’Œä¸¤ä¸ªæœ€å°å€¼åçš„å¹³å‡å€¼
        if resultIsObject is False:
            average_result = []
        else:
            average_result = {}

        for component, component_values in values.items():
            # å¯¹è¯¥ç‰©è´¨çš„å€¼è¿›è¡Œæ’åº
            sorted_values = sorted(component_values)

            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å€¼å»æ‰ä¸¤ä¸ªæœ€å¤§å’Œä¸¤ä¸ªæœ€å°
            if len(sorted_values) > 4:
                trimmed_values = sorted_values[2:-2]  # å»æ‰ä¸¤ä¸ªæœ€å¤§å’Œä¸¤ä¸ªæœ€å°
            else:
                trimmed_values = sorted_values  # å¦‚æœå€¼ä¸è¶³ 4 ä¸ªï¼Œä¸åšè£å‰ª

            # è®¡ç®—å¹³å‡å€¼
            avg_value = np.mean(trimmed_values)
            if resultIsObject is False:
                average_result.append({'component': component, 'value': avg_value})
            else:
                average_result[component] = avg_value

        return average_result
    except Exception as e:
        raise ValueError(f"Unexpected error in predict_average:{str(e)}") from e
    
def is_number(value):
    try:
        if isinstance(value, (int, float)):
            return True
        if isinstance(value, str):
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ£€æŸ¥æ˜¯å¦ä¸ºæ•°å­—
            return bool(re.match(r'^-?\d+(\.\d+)?$', value))
        return False
    except Exception as e:
        raise ValueError(f"Unexpected error in is_number:{str(e)}") from e
    
def spectrum_sum(data, group_size):
    try:
        grouped_data = []  # ç”¨æ¥å­˜æ”¾åˆ†ç»„åçš„æ•°æ®
        group = []  # å½“å‰æ­£åœ¨å¤„ç†çš„åˆ†ç»„
        ids = []  # ç”¨æ¥è®°å½•å½“å‰åˆ†ç»„çš„ id
        merged_spectrum = []  # ç”¨æ¥åˆå¹¶å½“å‰åˆ†ç»„çš„ Spectrum_Array
    
        for item in data:
            if len(group) < group_size:
                # æ·»åŠ å½“å‰é¡¹åˆ°å½“å‰åˆ†ç»„
                group.append(item)
                ids.append(item['id'])
                spectrum_array = eval(item['Spectrum_Array'])  # å°†å­—ç¬¦ä¸²è½¬ä¸ºåˆ—è¡¨
                
                # åˆå¹¶å½“å‰ Spectrum_Array
                if not merged_spectrum:
                    merged_spectrum = spectrum_array
                else:
                    merged_spectrum = [x + y for x, y in zip(merged_spectrum, spectrum_array)]
            
            # å½“åˆ†ç»„æ»¡äº†æ—¶ï¼Œä¿å­˜åˆ†ç»„ç»“æœï¼Œå¹¶é‡ç½®ç”¨äºä¸‹ä¸€ç»„çš„å˜é‡
            if len(group) == group_size:
                grouped_data.append({
                    'Spectrum_Array': merged_spectrum,
                    'time': group[0]['time'],  # å‡è®¾åŒä¸€ç»„çš„æ—¶é—´ç›¸åŒ
                    'ids': ids,
                    'filter_time': group[0]['filter_time'],
                    'plate_id':group[0]['plate_id'] if "plate_id" in group[0] else ""
                })
                # æ¸…ç©ºå½“å‰åˆ†ç»„ï¼Œç”¨äºå¤„ç†ä¸‹ä¸€ä¸ªåˆ†ç»„
                group = []
                ids = []
                merged_spectrum = []
    
        # å¤„ç†æœ€åå‰©ä½™çš„ä¸è¶³ group_size çš„æ•°æ®ï¼Œå¦‚æœæœ‰å°±åˆ é™¤
        if group:
            # å¦‚æœæœ€åä¸€ç»„çš„é•¿åº¦ä¸è¶³ group_sizeï¼Œåˆ™åˆ é™¤å®ƒ
            if len(group) < group_size:
                return grouped_data  # ç›´æ¥è¿”å›ï¼Œæœ€åä¸€ç»„å°†è¢«å¿½ç•¥
    
        return grouped_data
    except Exception as e:
        raise ValueError(f"Unexpected error in spectrum_sum:{str(e)}") from e
    
def spectrum_sum_mydb(data, group_size,time):
    try:
        grouped_data = []  # ç”¨æ¥å­˜æ”¾åˆ†ç»„åçš„æ•°æ®
        group = []  # å½“å‰æ­£åœ¨å¤„ç†çš„åˆ†ç»„
        ids = []  # ç”¨æ¥è®°å½•å½“å‰åˆ†ç»„çš„ id
        merged_spectrum = []  # ç”¨æ¥åˆå¹¶å½“å‰åˆ†ç»„çš„ Spectrum_Array
    
        for item in data:
            if len(group) < group_size:
                # æ·»åŠ å½“å‰é¡¹åˆ°å½“å‰åˆ†ç»„
                group.append({k: v for k, v in item.items() if k != 'Spectrum_Array'})
                ids.append(item['id'])
                spectrum_array = item['Spectrum_Array']  # å°†å­—ç¬¦ä¸²è½¬ä¸ºåˆ—è¡¨
                # ğŸ’¡ è¿™é‡Œä¿®å¤
                if isinstance(spectrum_array, str):
                    spectrum_array = json.loads(spectrum_array)
                if spectrum_array and not isinstance(spectrum_array[0], (int, float)):
                    spectrum_array = [float(x) for x in spectrum_array]
                # åˆå¹¶å½“å‰ Spectrum_Array
                if not merged_spectrum:
                    merged_spectrum = spectrum_array
                else:
                    merged_spectrum = [x + y for x, y in zip(merged_spectrum, spectrum_array)]
            
            # å½“åˆ†ç»„æ»¡äº†æ—¶ï¼Œä¿å­˜åˆ†ç»„ç»“æœï¼Œå¹¶é‡ç½®ç”¨äºä¸‹ä¸€ç»„çš„å˜é‡
            if len(group) == group_size:
                grouped_data.append({
                    'Spectrum_Array': merged_spectrum,
                    'time': group[0]['time'],  # å‡è®¾åŒä¸€ç»„çš„æ—¶é—´ç›¸åŒ
                    'ids': ids,
                    'filter_time': time,
                    'plate_id':group[0]['plate_id'] if "plate_id" in group[0] else ""
                })
                # æ¸…ç©ºå½“å‰åˆ†ç»„ï¼Œç”¨äºå¤„ç†ä¸‹ä¸€ä¸ªåˆ†ç»„
                group = []
                ids = []
                merged_spectrum = []
    
        # å¤„ç†æœ€åå‰©ä½™çš„ä¸è¶³ group_size çš„æ•°æ®ï¼Œå¦‚æœæœ‰å°±åˆ é™¤
        if group:
            # å¦‚æœæœ€åä¸€ç»„çš„é•¿åº¦ä¸è¶³ group_sizeï¼Œåˆ™åˆ é™¤å®ƒ
            if len(group) < group_size:
                return grouped_data  # ç›´æ¥è¿”å›ï¼Œæœ€åä¸€ç»„å°†è¢«å¿½ç•¥
    
        return grouped_data
    except Exception as e:
        raise ValueError(f"Unexpected error in spectrum_sum:{str(e)}") from e
    
def spectrum_and_sum(data, group_size):
    try:
        """
        æŒ‰æŒ‡å®šç»„é•¿åº¦åˆ†ç»„å¹¶è®¡ç®— Spectrum_Array çš„å’Œã€‚
    
        :param data: List[Dict], åŸå§‹æ•°æ®åˆ—è¡¨ã€‚
        :param group_size: int, æ¯ç»„çš„é•¿åº¦ã€‚
        :return: List[Dict], åˆ†ç»„è®¡ç®—åçš„ç»“æœåˆ—è¡¨ã€‚
        """
        if group_size <= 0:
            raise ValueError("group_and_sum: group_size å¿…é¡»æ˜¯æ­£æ•´æ•°")

        result = []

        # æŒ‰ç»„é•¿åº¦åˆ†ç»„å¹¶è®¡ç®—
        for i in range(0, len(data) - group_size + 1, group_size):
            group = data[i:i + group_size]
            # æŒ‰ Spectrum_Array ç´¯åŠ 
            combined_spectrum = [
                sum(values) for values in zip(
                    *(ast.literal_eval(item["Spectrum_Array"]) for item in group)
                )
            ]
            result.append({
                "Spectrum_Array": combined_spectrum,
                "time": group[0]["time"],
                "ids": [item["id"] for item in group]
            })

        return result
    except Exception as e:
        raise ValueError(f"Unexpected error in spectrum_and_sum:{str(e)}") from e
    
def send_zip(data):
    try:
        return base64.b64encode(
                    zlib.compress(json.dumps(data).encode('utf-8'))).decode('utf-8')
    except Exception as e:
        raise ValueError(f"Unexpected error in send_zip:{str(e)}") from e

def send_unzip(data):
    try:
        # å°è¯•è§£ç base64æ•°æ®
        decoded_data = base64.b64decode(data)
    except base64.binascii.Error as e:
        raise ValueError(f"Base64 decoding failed: {str(e)}") from e
    
    try:
        # å°è¯•è§£å‹ç¼©æ•°æ®
        decompressed_data = zlib.decompress(decoded_data)
    except zlib.error as e:
        raise ValueError(f"Zlib decompression failed: {str(e)}") from e
    
    try:
        # å°è¯•å°†è§£å‹ç¼©åçš„æ•°æ®è§£æä¸ºJSON
        return json.loads(decompressed_data.decode('utf-8'))
    except json.JSONDecodeError as e:
        raise ValueError(f"JSON decoding failed: {str(e)}") from e
    except UnicodeDecodeError as e:
        raise ValueError(f"UTF-8 decoding failed: {str(e)}") from e
    
def create_unique_filename(folder_path, base_name, suffix):
    try:
        file_name = f"{base_name}{suffix}"
        file_path = os.path.join(folder_path, file_name)
        counter = 1

        while os.path.exists(file_path):
            file_name = f"{base_name}({counter}){suffix}"
            file_path = os.path.join(folder_path, file_name)
            counter += 1

        return file_name
    except Exception as e:
        raise ValueError(f"Error creating unique filename: {str(e)}") from e

def ensure_directory_existence(file_path):
    try:
        directory = os.path.dirname(file_path)
        if not os.path.exists(directory):
            os.makedirs(directory)
    except OSError as e:
        raise ValueError(f"Error ensuring directory existence: {str(e)}") from e
    
def writeFile(filePath, fileName, data, suffix='.wxsw'):
    try:
        fileName = create_unique_filename(filePath, fileName, suffix)
        ensure_directory_existence(os.path.join(filePath, fileName))
        data_json = json.dumps(data, ensure_ascii=False)
        
        with open(os.path.join(filePath, fileName), 'w', encoding='utf-8') as file:
            file.write(data_json)
        return fileName
    except json.JSONEncodeError as e:
        raise ValueError(f"JSON encoding failed: {str(e)}") from e
    except IOError as e:
        raise ValueError(f"File writing failed: {str(e)}") from e
    except Exception as e:
        raise ValueError(f"Unexpected error in writeFile: {str(e)}") from e