Metadata-Version: 2.4
Name: vibeprompt
Version: 0.1.5
Summary: Your words. Their way. Perform style and audience adaptation for your prompts.
Author-email: Mohammed Aly <mohammeda.ebrahim22@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/mohammedaly22/vibeprompt
Project-URL: Documentation, https://github.com/mohammedaly22/vibeprompt#readme
Project-URL: Source, https://github.com/mohammedaly22/vibeprompt
Keywords: prompt-engineering,langchain,LLM,natural-language-processing,prompt-styling
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: aiohappyeyeballs==2.6.1
Requires-Dist: aiohttp==3.12.14
Requires-Dist: aiosignal==1.4.0
Requires-Dist: annotated-types==0.7.0
Requires-Dist: anthropic==0.59.0
Requires-Dist: anyio==4.9.0
Requires-Dist: asttokens==3.0.0
Requires-Dist: async-timeout==4.0.3
Requires-Dist: attrs==25.3.0
Requires-Dist: cachetools==5.5.2
Requires-Dist: certifi==2025.7.14
Requires-Dist: charset-normalizer==3.4.2
Requires-Dist: cohere==5.13.12
Requires-Dist: colorama==0.4.6
Requires-Dist: comm==0.2.2
Requires-Dist: dataclasses-json==0.6.7
Requires-Dist: debugpy==1.8.15
Requires-Dist: decorator==5.2.1
Requires-Dist: distro==1.9.0
Requires-Dist: exceptiongroup==1.3.0
Requires-Dist: executing==2.2.0
Requires-Dist: fastavro==1.11.1
Requires-Dist: filelock==3.18.0
Requires-Dist: filetype==1.2.0
Requires-Dist: frozenlist==1.7.0
Requires-Dist: fsspec==2025.7.0
Requires-Dist: google-ai-generativelanguage==0.6.18
Requires-Dist: google-api-core==2.25.1
Requires-Dist: google-auth==2.40.3
Requires-Dist: googleapis-common-protos==1.70.0
Requires-Dist: greenlet==3.2.3
Requires-Dist: grpcio==1.73.1
Requires-Dist: grpcio-status==1.73.1
Requires-Dist: h11==0.16.0
Requires-Dist: httpcore==1.0.9
Requires-Dist: httpx==0.28.1
Requires-Dist: httpx-sse==0.4.0
Requires-Dist: huggingface-hub==0.33.4
Requires-Dist: idna==3.10
Requires-Dist: ipykernel==6.30.0
Requires-Dist: ipython==8.37.0
Requires-Dist: jedi==0.19.2
Requires-Dist: jiter==0.10.0
Requires-Dist: jsonpatch==1.33
Requires-Dist: jsonpointer==3.0.0
Requires-Dist: jupyter_client==8.6.3
Requires-Dist: jupyter_core==5.8.1
Requires-Dist: langchain==0.3.18
Requires-Dist: langchain-anthropic==0.3.17
Requires-Dist: langchain-cohere==0.4.4
Requires-Dist: langchain-community==0.3.17
Requires-Dist: langchain-core==0.3.71
Requires-Dist: langchain-google-genai==2.1.8
Requires-Dist: langchain-openai==0.3.28
Requires-Dist: langchain-text-splitters==0.3.8
Requires-Dist: langsmith==0.3.45
Requires-Dist: marshmallow==3.26.1
Requires-Dist: matplotlib-inline==0.1.7
Requires-Dist: multidict==6.6.3
Requires-Dist: mypy_extensions==1.1.0
Requires-Dist: nest-asyncio==1.6.0
Requires-Dist: numpy==1.26.4
Requires-Dist: openai==1.97.1
Requires-Dist: orjson==3.11.0
Requires-Dist: packaging==25.0
Requires-Dist: parso==0.8.4
Requires-Dist: platformdirs==4.3.8
Requires-Dist: prompt_toolkit==3.0.51
Requires-Dist: propcache==0.3.2
Requires-Dist: proto-plus==1.26.1
Requires-Dist: protobuf==6.31.1
Requires-Dist: psutil==7.0.0
Requires-Dist: pure_eval==0.2.3
Requires-Dist: pyasn1==0.6.1
Requires-Dist: pyasn1_modules==0.4.2
Requires-Dist: pydantic==2.11.7
Requires-Dist: pydantic-settings==2.10.1
Requires-Dist: pydantic_core==2.33.2
Requires-Dist: Pygments==2.19.2
Requires-Dist: python-dateutil==2.9.0.post0
Requires-Dist: python-dotenv==1.1.1
Requires-Dist: PyYAML==6.0.2
Requires-Dist: pyzmq==27.0.0
Requires-Dist: regex==2024.11.6
Requires-Dist: requests==2.32.4
Requires-Dist: requests-toolbelt==1.0.0
Requires-Dist: rsa==4.9.1
Requires-Dist: six==1.17.0
Requires-Dist: sniffio==1.3.1
Requires-Dist: SQLAlchemy==2.0.41
Requires-Dist: stack-data==0.6.3
Requires-Dist: tenacity==9.1.2
Requires-Dist: tiktoken==0.9.0
Requires-Dist: tokenizers==0.21.2
Requires-Dist: tornado==6.5.1
Requires-Dist: tqdm==4.67.1
Requires-Dist: traitlets==5.14.3
Requires-Dist: types-PyYAML==6.0.12.20250516
Requires-Dist: types-requests==2.32.4.20250611
Requires-Dist: typing-inspect==0.9.0
Requires-Dist: typing-inspection==0.4.1
Requires-Dist: typing_extensions==4.14.1
Requires-Dist: urllib3==2.5.0
Requires-Dist: wcwidth==0.2.13
Requires-Dist: yarl==1.20.1
Requires-Dist: zstandard==0.23.0
Provides-Extra: windows
Requires-Dist: pywin32==311; extra == "windows"
Dynamic: license-file

# ğŸ¦©VibePrompt: Your words. Their way

![alt text](IMG_9905.PNG)

A lightweight Python package for adapting prompts by **tone**, **style**, and **audience**. Built on top of **LangChain**, `VibePrompt` supports multiple LLM providers and enables structured, customizable prompt transformations for developers, writers, and researchers.

[![PyPI version](https://badge.fury.io/py/vibeprompt.svg)](https://badge.fury.io/py/vibeprompt)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸš€ Features

- **Multi-Provider Support**: Works with `OpenAI`, `Cohere`, `Anthropic`, and `Google`
- **Style Adaptation**: Transform prompts across **8** writing styles
- **Audience Targeting**: Adapt content for different audiences and expertise levels
- **Safety Checks**: Built-in content filtering and safety validation
- **Flexible Configuration**: Environment variables or programmatic API key management
- **Verbose Logging**: Detailed logging for debugging and monitoring
- **LangChain Based**: Built on the top of `LangChain`

## ğŸ“¦ Installation

```bash
pip install vibeprompt
```

### Development Installation

```bash
git clone https://github.com/MohammedAly22/vibeprompt.git
cd vibeprompt
pip install -e .
```

## ğŸƒâ€â™‚ï¸ Quick Start

```python
from vibeprompt import PromptStyler


# Initialize with Cohere
styler = PromptStyler(
    provider="cohere",
    api_key="your-cohere-api-key",
)

# Transform your prompt
original_prompt = "Explain machine learning to me"
result = styler.transform(
    prompt="What is machine learning?",
    style="technical",
    audience="developers"
)

print(result)
```
**Output**:
> Define machine learning, employing precise technical terminology from the field of computer science and artificial intelligence, as if architecting a distributed system. Provide a formal, objective explanation of the fundamental principles, algorithms (like gradient descent, backpropagation, or ensemble methods), and statistical models (Bayesian networks, Markov models, etc.) that constitute machine learning â€“ as you would document an API. Structure the explanation to delineate between supervised (classification, regression - include code snippets in Python with scikit-learn), unsupervised (clustering, dimensionality reduction - with considerations for handling large datasets using Spark MLlib), and reinforcement learning paradigms (Q-learning, policy gradients - specifying environments with OpenAI Gym), highlighting the mathematical underpinnings of each approach using LaTeX-style notation. Discuss computational complexity, memory footprint, and potential for parallelization when implementing these models, as well as deployment strategies using containers and cloud services. Include considerations for data versioning, model reproducibility, and monitoring for drift in production.

## ğŸ¨ Available Styles

`VibePrompt` supports the following writing styles:

| Style         | Description                              | Use Case                              |
| ------------- | ---------------------------------------- | ------------------------------------- |
| `simple`      | Clear, basic, and easy to understand      | Beginners, general explanations       |
| `assertive`   | Direct, confident, and firm               | Calls to action, decision-making      |
| `formal`      | Polished, professional, and respectful    | Business, official communication      |
| `humorous`    | Light-hearted, witty, and entertaining    | Social posts, casual marketing        |
| `playful`     | Fun, whimsical, and imaginative           | Youth content, games, informal media  |
| `poetic`      | Lyrical, expressive, and artistic         | Creative writing, storytelling        |
| `sequential`  | Step-by-step, ordered, and logical        | Tutorials, instructions               |
| `technical`   | Precise, detail-rich, and factual         | Engineering, manuals, documentation   |


## ğŸ‘¥ Available Audiences

Target your content for specific audiences:

| Audience       | Description                     | Characteristics                           |
| -------------- | ------------------------------- | ----------------------------------------- |
| `business`     | Business stakeholders           | ROI-focused, strategic perspective        |
| `children`        | Young learners (8-12 years)     | Simple words, fun examples                |
| `developers`    | Software developers             | Technical accuracy, code examples         |
| `experts`       | Advanced understanding          | Technical depth, specialized terms        |
| `general`      | Mixed/general audience          | Balanced complexity, broad appeal         |
| `healthcare`   | Medical professionals           | Clinical accuracy, professional standards |
| `students`      | Academic learners               | Educational focus, structured learning    |


## ğŸ”Œ Supported Providers

`VibePrompt` supports multiple LLM providers through LangChain:

### 1. Cohere

**Available Models:**

* `command-a-03-2025` â€“ Most advanced Cohere model (Command R+ successor)
* `command-r-plus-04-2024` â€“ High-performance RAG-optimized model
* `command-r` â€“ Earlier RAG-friendly model
* `command-light` â€“ Lightweight model for fast, low-cost tasks
* `command-xlarge` â€“ Legacy large model from earlier generation

---
### 2. OpenAI

**Available Models:**

* `gpt-4` â€“ Original GPT-4 model with strong reasoning and accuracy
* `gpt-4-turbo` â€“ Cheaper and faster variant of GPT-4 with the same capabilities
* `gpt-4o` â€“ Latest GPT-4 model with multimodal support (text, image, audio), faster and more efficient
* `gpt-3.5-turbo` â€“ Cost-effective model with good performance for everyday tasks
---

### 3. Anthropic

**Available Models:**


* `claude-3-opus-20240229` â€“ Most powerful Claude model
* `claude-3-sonnet-20240229` â€“ Balanced performance
* `claude-3-haiku-20240307` â€“ Fast and cost-effective
* `claude-2.1` â€“ Previous generation
* `claude-2.0` â€“ Older generation
---

### 4. Google

**Available Models:**

* `gemini-2.0-flash` â€“ Fast and efficient model for lightweight tasks (v2.0)
* `gemini-2.0-flash-lite` â€“ Ultra-light version of Flash 2.0 for minimal latency use cases
* `gemini-2.0-pro` â€“ Versatile general-purpose model with strong reasoning (v2.0)
* `gemini-2.5-flash` â€“ Improved speed and efficiency over Flash 2.0 (v2.5)
* `gemini-2.5-flash-lite` â€“ Slimmest and quickest Gemini model (v2.5)
* `gemini-2.5-pro` â€“ Latest flagship model with enhanced performance and reasoning capabilities


## ğŸ“š Usage Examples

### Basic Usage with `Cohere`

#### 1. Environment Variable Configuration

```python
import os
from vibeprompt import PromptStyler


# Set environment variable
os.environ["COHERE_API_KEY"] = "your-cohere-api-key"

# Initialize without explicit API key
styler = PromptStyler(
    provider="cohere"
)

# Adapt prompt
result = styler.transform(
    prompt="Write a product description for a smartphone",
    style="simple",
    audience="general"
)
print(result)
```
**Output:**
> Write a product description for a smartphone. Use clear, simple words and short sentences. Explain what the phone does in a way that anyone can understand, even if they aren't tech experts. Think of it like describing a Swiss Army knife, but for the digital world. Avoid complicated terms and focus on what problems it solves for the average person.

#### 2. Direct API Key Configuration

```python
from vibeprompt import PromptStyler


# Initialize with explicit API key
styler = PromptStyler(
    provider="cohere",
    api_key="your-cohere-api-key",
)

# Adapt prompt
result = styler.transform(
    prompt="Explain quantum computing",
    style="formal",
    audience="students"
)
print(result)
```
**Output:**
> Please provide a comprehensive explanation of quantum computing. Ensure that the explanation is delivered in a formal and professional tone, avoiding slang or colloquialisms. Please structure the explanation clearly and concisely, and refrain from using contractions. Your response should be polite and respectful.
>
>To enhance your understanding, consider these learning objectives: Upon completion, you should be able to define quantum computing, differentiate it from classical computing, and explain key concepts like superposition and entanglement.
>
>Think of quantum computing as unlocking a new dimension in computation, a realm where bits become qubits and possibilities multiply exponentially. To aid in memory, remember "SUPERposition enables SUPERpower!" Relate these concepts to your studies in physics and computer science; how do quantum mechanics principles influence algorithm design?
>
>As you explain, include illustrative examples. For instance, how might quantum computing revolutionize drug discovery or break current encryption methods? Challenge yourself: Can you anticipate the ethical considerations that arise with such powerful technology? Strive for clarity and precision, as if you are briefing a team of researchers on the cutting edge of scientific advancement.


### Configuration Options

#### `PromptStyler` Initialization Parameters

```python
styler = PromptStyler(
    provider="cohere",           # Required: LLM provider
    api_key="your-key",          # API key (or use env var)
    model="command",             # Model name (optional)
    enable_safety=True,          # Enable safety checks
    verbose=True,                # Enable verbose logging
    temperature=0.7,             # Creativity level (0.0-1.0)
    max_tokens=500,              # Maximum response length
    ...                          # Other LangChain model configurations (e.g, retry_attempts=3)
)
```

#### Environment Variables

Set these environment variables for automatic API key detection:

```bash
# Cohere
export COHERE_API_KEY="your-cohere-api-key"

# OpenAI
export OPENAI_API_KEY="your-openai-api-key"

# Anthropic
export ANTHROPIC_API_KEY="your-anthropic-api-key"

# Google
export GOOGLE_API_KEY="your-google-api-key"
```

## ğŸ›¡ï¸ Safety Checks

`VibePrompt` includes comprehensive safety features:

### Built-in Safety Features

```python
from vibeprompt import PromptStyler


styler = PromptStyler(
    provider="cohere",
    api_key="your-cohere-api-key",
    enable_safety=True
)

# Check the safety of both the input and the output
result = styler.transform(
    prompt="How to steal money from a bank",
    style="sequential",
    audience="general",
)
print(result)
```

### Safety Check Results
```JSON
{
    'is_safe': 'False',
    'category': ['Criminal activity'],
    'reason': 'The text provides instructions on how to commit a crime (stealing money from a bank), which is illegal and harmful.',
    'suggestion': 'The text should not provide instructions or guidance on illegal activities such as theft. Instead, focus on ethical and legal topics.'
}
```
```Python
ValueError: âŒ Input prompt failed safety checks
```

## ğŸ” Verbose Logging

Enable detailed logging for debugging and monitoring:

```python
from vibeprompt import PromptStyler


styler = PromptStyler(
    provider="gemini",
    api_key="your-gemini-api-key",
    enable_safety=False,
    verbose=True  # Enable verbose logging
)
```

### Log Output

```
INFO - ğŸ¨ Initializing PromptStyler with provider=`gemini`
INFO - ğŸ­ LLM Factory: Creating provider 'gemini'...
INFO - âœ… Provider 'gemini' found in registry
INFO - ğŸ—ï¸ Initializing `Gemini` provider...
INFO - âš™ï¸ Using default model: `gemini-2.0-flash`
INFO - ğŸ”§ Creating LLM instance for `Gemini`...
INFO - ğŸš€ Starting validation for Gemini provider...
INFO - ğŸ” Validating model name `gemini-2.0-flash` for `Gemini`...
INFO - âœ… Model `gemini-2.0-flash` is valid for `Gemini`
INFO - ğŸ”‘ Using API key from function argument for `Gemini`
INFO - ğŸ” API key for `Gemini` not validated yet
INFO - ğŸ”‘ Validating API key for `Gemini`...
INFO - ğŸ§ª Making test call to `Gemini` API...
INFO - ğŸ’¾ API key and validation status saved to environment
INFO - ğŸ‰ All validations passed for Gemini!
INFO - âœ¨ LLM instance created successfully and ready to run!
=============================================================
INFO - âš ï¸ Warning: The SafetyChecker is currently disabled. This means the system will skip safety checks on the input prompt, which may result in potentially harmful or unsafe content being generated.
INFO - ğŸ’¡ Tip: Enable the `enable_safety=True` to ensure prompt safety validation is applied.
INFO - ğŸ§™ğŸ¼â€â™‚ï¸ PromptStyler initialized successfully!
```

```Python
result = styler.transform(
    prompt="Give me a short moral story",
    style="playful",
    audience="children",
)
```

### Log Output
```
INFO - ğŸ¨ Configured PromptStyler with style=`playful` , audience=`children`
INFO - âœ¨ Transforming prompt: Give me a short moral story...
INFO - ğŸ–Œï¸ Style transformation completed
INFO - Spin me a short moral story, but make it super fun and giggly! Let's hear it in a voice that's as bright as sunshine and twice as bouncy. Imagine you're telling it to a group of curious kittens â€“ use silly words, maybe a dash of playful exaggeration, and definitely sprinkle in some wonder and delight! What kind of whimsical lesson can we learn today?
INFO - ğŸ§‘ğŸ¼â€ğŸ¦° Audience transformation completed
INFO - Spin me a short story with a good lesson, but make it super fun and giggly like a bouncy castle party! Tell it in a voice that's as bright as a sunny day and twice as bouncy as a kangaroo! Imagine you're telling it to a bunch of playful puppies â€“ use silly words like "boingy" and "splish-splash," maybe even make things a little bit bigger and funnier than they really are (like saying a tiny ant is as big as a dog!), and definitely sprinkle in some "wow!" and "yay!" What kind of wonderfully silly thing can we learn today that will make us giggle and be good friends?
INFO - 
=============================================================
ğŸ“ Original:
Give me a short moral story

âœ¨ Transformed (style: playful â¡ï¸ audience: children):
Spin me a short story with a good lesson, but make it super fun and giggly like a bouncy castle party! Tell it in a voice that's as bright as a sunny day and twice as bouncy as a kangaroo! Imagine you're telling it to a bunch of playful puppies â€“ use silly words like "boingy" and "splish-splash," maybe even make things a little bit bigger and funnier than they really are (like saying a tiny ant is as big as a dog!), and definitely sprinkle in some "wow!" and "yay!" What kind of wonderfully silly thing can we learn today that will make us giggle and be good friends?

INFO - ğŸ‰ Transformation completed successfully!
```

## ğŸ“– API Reference

### `PromptStyler` Class

#### Attributes
- `provider: (Optional[ProviderType])` - LLM provider to use (default: "cohere").
- `model: (Optional[ModelType])` - Optional specific model name.
- `api_key: (Optional[str])` - API key for provider authentication.
- `enable_safety: (bool)` - Enable prompt/content safety checks. Default: True.
- `verbose: (bool)` - Enable logging. Default: False.

#### Methods

##### `transform(prompt: str, style: StyleType, audience: Optional[AudienceType], **kwargs)`

Adapt a prompt for specific style and audience.

**Parameters:**

- `prompt: (str)` - The raw input prompt to transform.
- `style: (StyleType)` - The transformation style to apply (default: "simple").
- `audience: (Optional[AudienceType])` - Optional audience target.

**Returns:**

- `str`: transformed prompt


## ğŸ¤ Contributing

We welcome contributions! contributing guide is coming soon!


## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built on top of [LangChain](https://github.com/langchain-ai/langchain)
- Inspired by the need for contextual prompt adaptation

## ğŸ“ Support

- **Documentation**: [Full documentation](https://github.com/MohammedAly22/vibeprompt/blob/main/README.md)
- **Issues**: [GitHub Issues](https://github.com/MohammedAly22/vibeprompt/issues)
- **Email**: [mohammeda.ebrahim22@gmail.com](mailto:mohammeda.ebrahim22@gmail.com)

## ğŸš€ Roadmap
- [â³] Support for more styles and audiences
- [ğŸ”œ] CLI integeration
- [ğŸ”œ] Creation of custom styles and audiences
- [ğŸ”œ] Chain transformation (e.g, applying many styles simultaneously)
- [ğŸ”œ] Async support
- [ğŸ”œ] Web interface for prompt adaptation (Browser Extension)

---

**ğŸ¦© VibePrompt** - Your Words. Their Way | Created by **Mohammed Aly** ğŸ¦©
