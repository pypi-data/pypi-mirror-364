import datetime
import inspect
import logging
import traceback
from functools import wraps
from typing import Any, Callable, Iterable, Mapping, Optional, Union


def log_this(
    log_level: int = logging.INFO,
    file_path: Optional[str] = None,
    log_format: Optional[str] = None,
    param_attrs: Optional[Mapping[str, Callable[[Any], Any]]] = None,
    discard_params: Optional[Iterable[str]] = None,
    extra_data: Optional[
        Union[Mapping[str, Any], Callable[[], Mapping[str, Any]]]
    ] = None,
    error_file_path: Optional[str] = None,
    log_conditions: Optional[Mapping[str, Callable[[Any], bool]]] = None,
):
    """Flexibly log every invocation of your application's functions.

    If you want to know what option(s) your users select from a certain dropdown, or
    maybe the length of a string they entered, this is function decorator for you.

    The invocations will be logged using the options you set, and can later be parsed
    and analyzed to understand how your users are using your application.

    Parameters
    ----------
    log_level
        Logging level (``logging.INFO`` by default).
    file_path
        Path to a log file. If *None*, output goes to *stderr*.
    log_format
        ``{}``-style format string for the emitted records.
    param_attrs
        Mapping whose *keys* are parameter names and whose *values* are
        callables that receive the parameter value and return **what should be
        logged** under *Attrs*.
    discard_params
        Iterable of parameter names whose *values* **must not appear in the
        Values section** of the log line. These parameters are still
        eligible for inclusion in *Attrs* via *param_attrs*.
    extra_data
        Optional dictionary of arbitrary data to be appended to the log
        line, or a callable that returns such a dictionary. If a callable is
        provided, it will be called at runtime to get the current extra data.
        Appears as ``Extra: {key1: val1, ...}``.
    error_file_path
        Path to a log file for errors. If *None*, error output goes to *stderr*.
    log_conditions
        Optional mapping of parameter names to boolean functions. Logging only
        occurs if ALL conditions evaluate to True. Functions receive the parameter
        value and should return a boolean. If *None*, logging always occurs.
        If a key in this mapping does not correspond to a parameter of the
        decorated function or is not available at call time, a `KeyError`
        will be raised. If a condition function itself raises an exception
        during its execution, a `RuntimeError` will be raised, encapsulating
        the original exception.

    Examples
    --------
    **Basic usage**::

        @log_this()
        def add(a, b):
            return a + b


        add(1, 2)
        Calling: __main__.add [2025-05-19T17:25:21.780733+00:00  2025-05-19T17:25:21.781115+00:00] Values: {'a': 1, 'b': 2} Attrs: {} Extra: {}

    **Conditional logging**::

        @log_this(log_conditions={"value": lambda x: x > 0})
        def process_value(value):
            return value * 2

    **Redacting a secret token**::

        @log_this(discard_params={"api_token"})
        def fetch_data(url, api_token): ...

    **Summarising large inputs**::

    It's generally good to discard parameters that are large, so you don't clutter
    your logs with huge objects. You can still log their attributes like length though.

        @log_this(param_attrs={"payload": len}, discard_params={"payload"})
        def send(payload: bytes):
            ...

    See Also
    --------
    You can use advertools.logs_to_df() to parse, compress and analyze the logs
    generated by this decorator.
    """  # noqa: E501

    handler: logging.Handler
    if file_path:
        handler = logging.FileHandler(file_path)
    else:
        handler = logging.StreamHandler()

    if log_format:
        handler.setFormatter(logging.Formatter(log_format, style="{"))
    error_handler: logging.Handler
    if error_file_path:
        error_handler = logging.FileHandler(error_file_path)
    else:
        error_handler = logging.StreamHandler()

    discard_set = set(discard_params or ())

    def decorator(func):
        logger_name = f"{func.__module__}.{func.__qualname__}"
        logger = logging.getLogger(logger_name)
        logger.setLevel(log_level)

        if handler not in logger.handlers:
            logger.addHandler(handler)

        sig = inspect.signature(func)

        error_logger_name = f"{func.__module__}.{func.__qualname__}.error"
        error_logger = logging.getLogger(error_logger_name)
        error_logger.setLevel(logging.ERROR)
        error_logger.propagate = False  # Prevent propagation to parent logger
        if error_handler not in error_logger.handlers:
            error_logger.addHandler(error_handler)

        @wraps(func)
        def wrapper(*args, **kwargs):
            bound = sig.bind_partial(*args, **kwargs)
            bound.apply_defaults()

            values_dict = {}
            for name, value in bound.arguments.items():
                if name in discard_set:
                    values_dict[name] = "discarded"
                else:
                    values_dict[name] = value

            attrs_repr = {}
            if param_attrs:
                for name, transformer in param_attrs.items():
                    try:
                        attrs_repr[name] = transformer(bound.arguments[name])
                    except KeyError as e:
                        raise KeyError(
                            f"Parameter {str(e)} referenced in param_attrs "
                            f"is not a valid parameter for function '{func.__name__}' "
                            f"or not available at call time."
                        ) from e
                    except Exception as exc:
                        attrs_repr[name] = f"<transform error: {exc}>"

            try:
                utc = datetime.UTC
            except AttributeError:
                # Fallback for Python versions < 3.11 which didn't have datetime.UTC
                utc = datetime.timezone.utc

            t0 = datetime.datetime.now(utc)
            try:
                result = func(*args, **kwargs)
            except Exception as exc:
                error_logger.error(
                    f"Error in {logger_name} at {t0.isoformat()} "
                    f"Values: {repr(values_dict)} "
                    f"Attrs: {repr(attrs_repr)} Exception: {exc}\n{traceback.format_exc()}"
                )
                raise
            t1 = datetime.datetime.now(utc)

            # Initialize with empty dict, then populate if extra_data exists
            resolved_extra_data = {}
            if extra_data:
                # Handle both static extra_data (dict) and dynamic extra_data (callable)
                if callable(extra_data):
                    try:
                        extra_result = extra_data()
                        resolved_extra_data = extra_result if extra_result is not None else {}
                    except Exception as exc:
                        resolved_extra_data = {"<extra_data_error>": str(exc)}
                else:
                    resolved_extra_data = extra_data if extra_data is not None else {}
            log_conditions_met = True
            if log_conditions is not None:
                try:
                    log_conditions_met = all(
                        v(bound.arguments[k]) for k, v in log_conditions.items()
                    )
                except KeyError as e:
                    raise KeyError(
                        f"Parameter {str(e)} referenced in log_conditions "
                        f"is not a valid parameter for function '{func.__name__}' "
                        f"or not available at call time."
                    ) from e
                except Exception as e:
                    raise RuntimeError(
                        f"Error evaluating a condition function within log_conditions "
                        f"for function '{func.__name__}': {e}"
                    ) from e
            if log_conditions_met:
                logger.log(
                    log_level,
                    (
                        f"Calling: {logger_name} "
                        f"[{t0.isoformat()}  {t1.isoformat()}] "
                        f"Values: {repr(values_dict)} "
                        f"Attrs: {repr(attrs_repr)} "
                        f"Extra: {repr(resolved_extra_data)}"
                    ),
                )
            return result

        return wrapper

    return decorator
