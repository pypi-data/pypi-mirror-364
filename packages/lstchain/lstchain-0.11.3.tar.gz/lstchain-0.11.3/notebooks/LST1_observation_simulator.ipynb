{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "import gammapy\n",
    "from gammapy.modeling.models import EBLAbsorptionNormSpectralModel\n",
    "import subprocess\n",
    "from pyirf.spectral import CRAB_MAGIC_JHEAP2015, PowerLaw, LogParabola\n",
    "from pyirf.statistics import li_ma_significance\n",
    "from scipy.stats import moyal, norm, skewnorm\n",
    "from pathlib import Path\n",
    "from lstchain.io.io import get_resource_path\n",
    "from lstchain.version import version as lstchain_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Set cut efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Cut efficiency: the same for the gammaness cut and the theta cut\n",
    "# Options: 0.4, 0.7, 0.9\n",
    "#\n",
    "# Recommended: \n",
    "# 0.7: standard cuts (safer for spectral analysis)\n",
    "# 0.4: tight cuts, better for detection of weak sources\n",
    "#\n",
    "cut_efficiency = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Load files which contain the (approximate) instrument response function, and show table contents \n",
    "\n",
    "They characterize the average performance of LST1 within 1 degree off-axis (computed from diffuse gamma MC and real data for the cosmic ray rates). The Ereco/Etrue distributions in each Etrue bin is parametrized with moyal or a skewnorm function (whatever fits better) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load files for the requested efficiency:\n",
    "#\n",
    "input_gamma_filename =  get_resource_path(f'data/LST1_gamma_irf_gheffi_{cut_efficiency:.2f}_theffi_{cut_efficiency:.2f}.csv')\n",
    "gamma_data = pd.read_csv(input_gamma_filename)\n",
    "\n",
    "input_bkg_filename = get_resource_path(f'data/LST1_backg_irf_gheffi_{cut_efficiency:.2f}_theffi_{cut_efficiency:.2f}.csv')\n",
    "background_data = pd.read_csv(input_bkg_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK that we have the same pointing zenith values in both tables:\n",
    "assert np.alltrue(np.unique(gamma_data.ZD_deg) == np.unique(background_data.ZD_deg))\n",
    "\n",
    "# Available zeniths:\n",
    "zenith = np.unique(gamma_data.ZD_deg)\n",
    "print('Available zeniths:', zenith, '(degrees)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "##  Zenith distance bin selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the bins among those above. Just set the bin number (from 0)\n",
    "# Make sure you choose values which make sense for the declination of your source\n",
    "\n",
    "zd_bin = 3\n",
    "\n",
    "print('Selected ZD = ', zenith[zd_bin], 'degrees')\n",
    "\n",
    "# Cuts for tables:\n",
    "zd_selection_gamma = abs(gamma_data.ZD_deg - np.unique(gamma_data.ZD_deg)[zd_bin])<0.01\n",
    "zd_selection_backg = abs(background_data.ZD_deg - np.unique(background_data.ZD_deg)[zd_bin])<0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## ON to OFF exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of ON to OFF exposure (Li & Ma's \"alpha\")\n",
    "# For standard wobble offset (0.4 deg) reasonable values are alpha=0.333 (3 off regions) above 0.2 TeV, \n",
    "# and alpha=1 below 0.2 TeV.  For testing sensitivity with the standard definition, set alpha=0.2\n",
    "\n",
    "# Note: this setting will be overriden in pulsar mode! (see below)\n",
    "\n",
    "alpha = 0.333 # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Pulsar mode\n",
    "(overrides the setting of alpha above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar_mode = False # Set to True to activate it\n",
    "on_phase_interval = 0.043 # Crab P1: [-0.017, 0.026]  Phase range for integrating the signal\n",
    "off_phase_interval = 0.35 # [0.52 - 0.87]             Phase range for estimating the background\n",
    "\n",
    "if pulsar_mode:\n",
    "    alpha = on_phase_interval / off_phase_interval\n",
    "    print(f'alpha = {alpha:.4f}')\n",
    "\n",
    "# The spectrum is interpreted as average flux in full period (i.e. not just in the on-phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Observation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# effective_obs_time = 103 * u.h # LST1 Crab pulsar paper\n",
    "\n",
    "# effective_obs_time = 2392 * u.s # GRB190114C, 62 - 2454 s, MAGIC\n",
    "\n",
    "# effective_obs_time = 8 * u.s # BOAT, 240 - 248 s, LHAASO\n",
    "\n",
    "effective_obs_time = 34 * u.h  # Crab nebula. LST1 performance paper\n",
    "\n",
    "# effective_obs_time = 11.8 * u.h  # 1ES 1011+496, February 2014 flare, MAGIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Source extension\n",
    "For moderately extended sources, say below ~0.5 degrees radius\n",
    "Set here the radius of the source within which (in 2d-gaussian approximation) the same fraction of the source is contained as the cut efficiency set above. That is, if you use 0.7 efficiency, set as source radius the angular distance within which 70% of the emission is expected to be contained.\n",
    "We will simply increase the background by a factor (source_radius$^2$ + theta_cut$^2$) / (theta_cut$^2$), since we expect to integrate the same fraction of the signal within an angle sqrt(source_radius$^2$ + theta_cut$^2$) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_radius = 0 # 0.3 * u.deg\n",
    "theta_cut = background_data.Theta_cut_deg[zd_selection_backg].to_numpy()*u.deg\n",
    "\n",
    "if source_radius == 0:\n",
    "    print(\"Emission from a point-like source will be assumed!\")\n",
    "    background_increase_factor = np.ones_like(theta_cut.to_value())\n",
    "else:\n",
    "    print(f'Source angular radius within which {cut_efficiency:.1%} of the emission is contained: {source_radius}')\n",
    "\n",
    "    background_increase_factor = (theta_cut**2 + \n",
    "                                  (source_radius.to_value(u.deg)*np.ones_like(theta_cut))**2) / (theta_cut**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Source redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift = 0\n",
    "\n",
    "\n",
    "# redshift = 0.151 # BOAT GRB\n",
    "# redshift = 0.212 # 1ES 1011\n",
    "# redshift = 0.42 # GRB190114C\n",
    "\n",
    "# We will apply the Dominguez EBL model to simulate the absorption\n",
    "\n",
    "dominguez_ebl_file = get_resource_path(f'data/ebl_dominguez11.fits.gz')\n",
    "ebl_model = EBLAbsorptionNormSpectralModel.read(dominguez_ebl_file, redshift=redshift)\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "#\n",
    "# In case you want to use other EBL models available in gammapy (e.g. Franceschini) you can try \n",
    "# the lines below: \n",
    "#\n",
    "# Make sure we have the necessary EBL absorption data:\n",
    "# try:\n",
    "#     os.environ['GAMMAPY_DATA']\n",
    "# except:\n",
    "#     # WE SET HERE THE GAMMAPY_DATA ENV VARIABLE IN CASE IT IS NOT SET\n",
    "#     gammapy_dir = Path(gammapy.__file__).parent\n",
    "#     gammapy_dir\n",
    "\n",
    "#     ebl_file = subprocess.run(['find', str(gammapy_dir), '-name', 'ebl_dominguez11.fits.gz'], \n",
    "#                               stdout=subprocess.PIPE).stdout.decode()\n",
    "#     gammapy_data = ebl_file[:ebl_file.find('/ebl/')]\n",
    "#     os.environ['GAMMAPY_DATA'] = gammapy_data\n",
    "#     print('Set GAMMAPY_DATA to', gammapy_data)\n",
    "#\n",
    "#\n",
    "# ebl_model = EBLAbsorptionNormSpectralModel.read_builtin(\"franceschini\", redshift=redshift)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Source (intrinsic) spectrum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set here the simulated intrinsic spectrum intrinsic_dFdE\n",
    "# (it must take as argument an astropy quantity with energy units!)\n",
    "\n",
    "# Crab Nebula:\n",
    "def intrinsic_dFdE(E):\n",
    "    return CRAB_MAGIC_JHEAP2015(E)  # Crab Nebula, MAGIC log-parabola\n",
    "\n",
    "# Crab pulsar P1, from LST1 paper (smoothly broken power-law):\n",
    "# def intrinsic_dFdE(E):\n",
    "#     return PowerLaw(normalization=1.27e-4 / (u.TeV * u.cm**2 * u.s), \n",
    "#                     index=-1.811, e_ref=1*u.GeV)(E) * (1+(E/(6.8*u.GeV))**((4.09-1.811)/3))**-3\n",
    "\n",
    "# GRB 190114C T0+62 s to T0+2454 s (set redshift above to 0.42)\n",
    "# def intrinsic_dFdE(E):\n",
    "#     return PowerLaw(normalization=8.45e-9 / (u.TeV * u.cm**2 * u.s),  \n",
    "#                     index=-2.22, \n",
    "#                     e_ref=0.46*u.TeV)(E)\n",
    "\n",
    "\n",
    "# The BOAT (GRB 221009A) @ ~T0+240s: (set redshift above to 0.151)\n",
    "# def intrinsic_dFdE(E):\n",
    "#     return PowerLaw(normalization=208e-8 / (u.TeV * u.cm**2 * u.s),  \n",
    "#                     index=-2.455, \n",
    "#                     e_ref=1*u.TeV)(E)\n",
    "\n",
    "\n",
    "# 1ES1011 February 2014 flare\n",
    "# def intrinsic_dFdE(E):\n",
    "#     return PowerLaw(normalization=8.7e-10 / (u.TeV * u.cm**2 * u.s), \n",
    "#                     index=-2.03, e_ref=0.25*u.TeV)(E)\n",
    "\n",
    "# A log-parabola spectrum:\n",
    "# def intrinsic_dFdE(E):\n",
    "#     return LogParabola(normalization=5e-8 / (u.TeV * u.cm**2 * u.s), \n",
    "#                     a=-2, b =-0.05, \n",
    "#                     e_ref=0.1*u.TeV)(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After EBL absorption:\n",
    "def dFdE(E):\n",
    "    return intrinsic_dFdE(E) * ebl_model.evaluate(E, redshift, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## END of user settings\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other settings (change only for tests)\n",
    "\n",
    "backg_systematics_uncertainty = 0.005 # 0.5% (relative) will be added in quadrature to statistical uncertainty of flux points \n",
    "min_signi_in_flux_point = 2     # minimum significance to display a flux point\n",
    "\n",
    "integral_significance_threshold = 5  # \"Detection significance\"\n",
    "integral_min_signal_to_backg_ratio = 0.05 # S/B must be larger or equal than this for detection\n",
    "\n",
    "if pulsar_mode: # unbiased background can be taken from off-phase\n",
    "    backg_systematics_uncertainty = 0\n",
    "    integral_min_signal_to_backg_ratio = 0\n",
    "\n",
    "\n",
    "min_Aeff = 100 *u.m**2         # Minimum required Aeff in Etrue bins. \n",
    "                               # Just to avoid Etrue bins with little MC stats, hence noisy!\n",
    "\n",
    "# To exclude Ereco bins with too strong deviation of the true energies that fall inside them:\n",
    "max_ereco_to_etrue_deviation = 0.5 #   abs(mean(Etrue)/ereco_bin_center - 1) < max_ereco_to_etrue_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "erecobins = background_data[zd_selection_backg].Ereco_min_TeV.to_numpy()\n",
    "erecobins = np.append(erecobins, background_data[zd_selection_backg].Ereco_max_TeV.to_numpy()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "etruebins = gamma_data[zd_selection_gamma].Etrue_min_TeV.to_numpy()\n",
    "etruebins = np.append(etruebins, gamma_data[zd_selection_gamma].Etrue_max_TeV.to_numpy()[-1])\n",
    "\n",
    "effective_area = gamma_data.Aeff_m2[zd_selection_gamma].to_numpy()*u.m**2\n",
    "\n",
    "# Model to characterize the energy migration matrix (skewnorm or moyal):\n",
    "emig_model = gamma_data[zd_selection_gamma].emig_model.to_numpy()\n",
    "\n",
    "# Parameters to characterize the energy migration matrix:\n",
    "loc = gamma_data[zd_selection_gamma].emig_mu_loc.to_numpy()\n",
    "scale = gamma_data[zd_selection_gamma].emig_mu_scale.to_numpy()\n",
    "a = gamma_data[zd_selection_gamma].emig_mu_a.to_numpy()\n",
    "\n",
    "\n",
    "# Now we extrapolate Aeff to higher Etrue by using the same value of the highest available energy:\n",
    "# (it is better than having zeros!) We also assume the same E-migration\n",
    "factor = etruebins[-1]/etruebins[-2] # step in energy in each bin\n",
    "while etruebins[-1] < 80: # extend to 80 TeV at least\n",
    "    etruebins = np.append(etruebins, etruebins[-1]*factor)\n",
    "    effective_area = np.append(effective_area, effective_area[-1])\n",
    "    emig_model = np.append(emig_model, emig_model[-1])\n",
    "    loc = np.append(loc, loc[-1])\n",
    "    scale = np.append(scale, scale[-1])\n",
    "    a = np.append(a, a[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "etruebincenters = (etruebins[:-1]*etruebins[1:])**0.5\n",
    "erecobincenters = (erecobins[:-1]*erecobins[1:])**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude too low eff. areas (in general, unreliable due to low MC stats)\n",
    "\n",
    "effective_area[effective_area<min_Aeff] = 0\n",
    "\n",
    "# Exclude also Ereco bins which have Ereco values below the first Etrue value with valid Aeff:\n",
    "ereco_mask = erecobincenters >= etruebincenters[np.where(effective_area>0)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate dF/dE within a bin, assuming power-law approximation within it:\n",
    "def integrate (dfde1, dfde2, e1, e2):\n",
    "    # We cannot let numpy deal with the units, sometimes rounding leads to wrong units in result!\n",
    "    # like TeV^(1e-15) :-D\n",
    "    if (dfde1 == 0) | (dfde2 == 0): # May happen, e.g because of EBL or a strong cutoff\n",
    "        return 0\n",
    "    \n",
    "    # In power-law approximation:\n",
    "    gamma = np.log(dfde2/dfde1) / np.log(e2/e1)\n",
    "    e1tev = e1.to_value(u.TeV)\n",
    "    e2tev = e2.to_value(u.TeV)\n",
    "    \n",
    "    integral = (dfde1.to_value(1/(u.TeV * u.cm**2 * u.s)) / \n",
    "                (gamma+1) * e1tev**(-gamma) * \n",
    "                (e2tev**(gamma+1) - e1tev**(gamma+1))\n",
    "               )\n",
    "    return integral # (1/u.s/u.cm**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_flux = []\n",
    "for etruemin, etruemax in zip(etruebins[:-1], etruebins[1:]):\n",
    "    integrated_flux.append(integrate(dFdE(etruemin*u.TeV),\n",
    "                                     dFdE(etruemax*u.TeV),\n",
    "                                     etruemin*u.TeV, \n",
    "                                     etruemax*u.TeV))\n",
    "integrated_flux = np.array(integrated_flux)\n",
    "\n",
    "# Too strong EBL absorption produces NaNs in high-E bins, just replace by 0's:\n",
    "integrated_flux[np.isnan(integrated_flux)] = 0\n",
    "    \n",
    "integrated_flux = np.array(integrated_flux) * 1/(u.s * u.cm**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Effective area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(etruebincenters, effective_area)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Etrue (TeV)')\n",
    "plt.ylabel('Aeff (m2)')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Background rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "bgrate = background_data[zd_selection_backg].BckgRate_per_second.to_numpy()\n",
    "\n",
    "if pulsar_mode: # Scale background to the on-phase:\n",
    "    bgrate *= on_phase_interval\n",
    "\n",
    "bgrate *= background_increase_factor\n",
    "\n",
    "plt.plot(erecobincenters[ereco_mask], bgrate[ereco_mask])\n",
    "plt.xlabel('Ereco (TeV)')\n",
    "plt.ylabel('Background rate within theta cut\\n (events/s) in Ereco bins')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_gamma_rate = (integrated_flux*effective_area).to(1/u.s)\n",
    "print(f'Total gamma rate after cuts: {total_gamma_rate.sum().to_value(1/u.s):.3f} events/s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_realizations_a = 100\n",
    "num_realizations_b = 100\n",
    "# Number of realizations (random numbers taken from skewnorm or moyal) for E-migration simulation\n",
    "\n",
    "num_realizations = num_realizations_a * num_realizations_b\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_etrue_binning = np.logspace(-2.5, 3.5, 601) # Just for calculation of mean Etrue within an Ereco bin\n",
    "\n",
    "total_bg_counts = effective_obs_time.to_value(u.s) * bgrate\n",
    "\n",
    "total_signal_counts_2d = np.zeros(shape=[len(total_bg_counts), len(fine_etrue_binning)-1])\n",
    "\n",
    "for ietrue in range(len(etruebincenters)):\n",
    "    \n",
    "    gamma_rate = total_gamma_rate[ietrue]\n",
    "\n",
    "    \n",
    "    emin= etruebins[ietrue]\n",
    "    emax = etruebins[ietrue+1]\n",
    "\n",
    "    etrue_values = np.exp(np.log(emin) + np.log(emax/emin) * np.random.uniform(0, 1, num_realizations_a))\n",
    "    \n",
    "    for etrue in etrue_values:\n",
    "        # print(f'{ietrue}: {etrue:.4f} TeV, {gamma_rate}, {loc[ietrue]:.4f}, {scale[ietrue]:.4f}, {emig_model[ietrue]}')\n",
    "        # Possible alternative: simulate according to the (interpolated) events vs Etrue graph,\n",
    "        # instead of all energies being equal to the bin center\n",
    "\n",
    "        if emig_model[ietrue] == 'skewnorm':\n",
    "            ereco = etrue*skewnorm.rvs(a[ietrue], loc[ietrue], scale[ietrue], \n",
    "                                           num_realizations_b)                  \n",
    "        elif emig_model[ietrue] == 'moyal':\n",
    "            ereco = etrue*moyal.rvs(loc[ietrue], scale[ietrue], \n",
    "                                    num_realizations_b)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # counts, _ = np.histogram(ereco, bins=erecobins)\n",
    "        # Histogram in very fine Etrue bins, for later calculation of mean true energy of\n",
    "        # gammas within each Ereco bin:\n",
    "        counts, _, _ = np.histogram2d(ereco, etrue*np.ones_like(ereco), bins=[erecobins, fine_etrue_binning]) \n",
    "\n",
    "\n",
    "        # Integrate in Ereco bins and add to total:\n",
    "        total_signal_counts_2d += (gamma_rate * effective_obs_time * counts / num_realizations)\n",
    "\n",
    "        \n",
    "total_signal_counts = np.sum(total_signal_counts_2d, axis=1) # Integrate in Ereco bins\n",
    "# Now set to zero values below the \"reliable minimum energy\":\n",
    "total_signal_counts[~ereco_mask] = 0\n",
    "total_bg_counts[~ereco_mask] = 0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(0.5*(erecobins[:-1]+erecobins[1:]), total_signal_counts, total_signal_counts**0.5,\n",
    "             label='gammas', fmt='o')\n",
    "plt.errorbar(0.5*(erecobins[:-1]+erecobins[1:]), total_bg_counts, total_bg_counts**0.5,\n",
    "             label='Background')\n",
    "\n",
    "# PLOT GAMMAS VS. ETRUE FOR COMPARISON, correcting for the different bin width:\n",
    "plt.plot(etruebincenters, total_gamma_rate*effective_obs_time.to_value(u.s)*\n",
    "         len(etruebincenters)/len(erecobincenters), '--', alpha=0.5, label='gammas vs. Etrue')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('Ereco (TeV)')\n",
    "plt.ylabel('Number of events after cuts in Ereco bins')\n",
    "plt.grid()\n",
    "plt.ylim(0.1, 2*max(np.max(total_bg_counts), np.max(total_signal_counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bg_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_etrue_vs_ereco = np.zeros_like(erecobincenters)\n",
    "finebincenters = 0.5 * (fine_etrue_binning[1:]+fine_etrue_binning[:-1])\n",
    "\n",
    "for iereco in range(len(erecobincenters)):\n",
    "    if np.nansum(total_signal_counts_2d[iereco]) == 0:\n",
    "        continue\n",
    "    mean_etrue_vs_ereco[iereco] = (np.nansum(finebincenters * total_signal_counts_2d[iereco]) / \n",
    "                                   np.nansum(total_signal_counts_2d[iereco]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.scatter(erecobincenters, mean_etrue_vs_ereco)\n",
    "plt.xlabel('Ereco bin center (TeV)')\n",
    "plt.ylabel('Mean Etrue in bin (TeV)')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.scatter(erecobincenters, mean_etrue_vs_ereco / erecobincenters)\n",
    "plt.xlabel('Ereco bin center (TeV)')\n",
    "plt.ylabel('Mean Etrue in bin / Ereco bin center')\n",
    "plt.ylim(0, 1.1*np.nanmax(mean_etrue_vs_ereco/erecobincenters))\n",
    "plt.xscale('log')\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's not use bins with too high bias in the spectrum:\n",
    "not_too_high_bias = abs(mean_etrue_vs_ereco / erecobincenters - 1) < max_ereco_to_etrue_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "significance = li_ma_significance(total_signal_counts+total_bg_counts,\n",
    "                                  total_bg_counts/alpha, alpha)\n",
    "\n",
    "# integrating from each Ereco to max Ereco\n",
    "integral_signal_counts = np.cumsum(total_signal_counts[::-1])[::-1]\n",
    "integral_bg_counts = np.cumsum(total_bg_counts[::-1])[::-1]\n",
    "\n",
    "integral_significance = li_ma_significance(integral_signal_counts+integral_bg_counts,\n",
    "                                           integral_bg_counts/alpha, alpha)\n",
    "integral_signal_to_background_ratio = integral_signal_counts / integral_bg_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## Signal to background ratio and significance in Ereco bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_to_background_ratio = total_signal_counts / total_bg_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.plot(erecobincenters, signal_to_background_ratio)\n",
    "plt.scatter(erecobincenters, signal_to_background_ratio)\n",
    "plt.grid()\n",
    "plt.xlabel('Ereco (TeV)')\n",
    "plt.ylabel('Signal / background ratio')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.ylim(1e-3, 2*np.nanmax(signal_to_background_ratio))\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "\n",
    "# Conditions to consider a bin reliable\n",
    "reliable_points = ((signal_to_background_ratio >= backg_systematics_uncertainty) &\n",
    "                   not_too_high_bias)\n",
    "\n",
    "plt.scatter(erecobincenters[reliable_points], significance[reliable_points], \n",
    "            label='Valid bins')\n",
    "\n",
    "plt.scatter(erecobincenters[~reliable_points], significance[~reliable_points], label='Unreliable bins', color='orange')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('Ereco (TeV)')\n",
    "plt.ylabel('Li & Ma significance per Ereco bin')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "## Integral significance (for Ereco>xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "mask = (integral_significance >= integral_significance_threshold)\n",
    "\n",
    "plt.scatter(erecobins[:-1][mask & reliable_points], integral_significance[mask & reliable_points], \n",
    "            label=f'Significance $\\geq$ {integral_significance_threshold} sigma')\n",
    "\n",
    "if (mask & ~reliable_points).sum() > 0:\n",
    "    plt.scatter(erecobins[:-1][mask & ~reliable_points], integral_significance[mask & ~reliable_points], \n",
    "                label=f'Significance >= {integral_significance_threshold}, \\nUNRELIABLE points!')\n",
    "\n",
    "plt.scatter(erecobins[:-1][~mask], integral_significance[~mask],\n",
    "            label=f'Significance < {integral_significance_threshold} sigma')\n",
    "plt.grid()\n",
    "plt.xlabel('Minimum Ereco (TeV)')\n",
    "plt.ylabel('Li & Ma integral significance')\n",
    "plt.xscale('log')\n",
    "\n",
    "if (mask & reliable_points).sum() > 0:\n",
    "    print('*************************')\n",
    "    print('Detection successful! :-D')\n",
    "else:\n",
    "    print('****************')\n",
    "    print('No detection :-C')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "## Simulated SED from observation (Asimov dataset)\n",
    "The fluxes & uncertainties are computed in the Ereco bins, then placed at the mean Etrue of the gamma events falling within the bin, and at the \"expected\" flux level. \n",
    "In reality proper energy unfolding will be needed... what is shown below is just a an estimate of what the spectrum will look like - but pretty accurate for the purpose of observation planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "noff = total_bg_counts / alpha\n",
    "non = total_signal_counts + total_bg_counts\n",
    "# excess = non - alpha * noff (= total_signal_counts in Asimov dataset)\n",
    "stat_excess_error = (non + alpha**2 * noff)**0.5\n",
    "\n",
    "np.seterr(divide='ignore')\n",
    "relative_stat_excess_error = stat_excess_error/total_signal_counts\n",
    "\n",
    "syst_excess_error = backg_systematics_uncertainty * total_bg_counts\n",
    "\n",
    "relative_syst_excess_error = syst_excess_error / total_signal_counts\n",
    "total_relative_excess_error = np.hypot(relative_stat_excess_error, relative_syst_excess_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayed_points = reliable_points & (significance > min_signi_in_flux_point)\n",
    "\n",
    "if displayed_points.sum() > 0:\n",
    "\n",
    "    SED = ((mean_etrue_vs_ereco[displayed_points]*u.TeV)**2 * \n",
    "           dFdE(mean_etrue_vs_ereco[displayed_points]*u.TeV))\n",
    "\n",
    "    SED_stat_error = SED*relative_stat_excess_error[displayed_points]\n",
    "    SED_total_error = SED*total_relative_excess_error[displayed_points]\n",
    "\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    intrinsic_SED = (finebincenters*u.TeV)**2 * intrinsic_dFdE(finebincenters*u.TeV)\n",
    "\n",
    "    if redshift > 0:\n",
    "        plt.plot(finebincenters, intrinsic_SED, '--', color='lightgrey', label='intrinsic')\n",
    "\n",
    "\n",
    "    SED_fine = (fine_etrue_binning*u.TeV)**2 * dFdE(fine_etrue_binning*u.TeV)\n",
    "    plt.plot(fine_etrue_binning, SED_fine, '--')\n",
    "\n",
    "\n",
    "    if not pulsar_mode:\n",
    "        plt.errorbar(mean_etrue_vs_ereco[displayed_points], SED, yerr=SED_total_error, \n",
    "                     fmt='o', markersize=4, \n",
    "                     label=f'Observed, stat + backg syst ({backg_systematics_uncertainty:.1%})')\n",
    "    plt.errorbar(mean_etrue_vs_ereco[displayed_points], SED, yerr=SED_stat_error, \n",
    "                 fmt='o', markersize=4, \n",
    "                 label='Observed, stat-only')\n",
    "\n",
    "    ax = fig.axes[0]\n",
    "    \n",
    "    str = 'Source-independent analysis'\n",
    "    str += f'\\nZenith angle = {zenith[zd_bin]:.1f} degrees'\n",
    "    str += f'\\nCut efficiencies: {cut_efficiency:.0%}, {cut_efficiency:.0%} ($\\\\theta$, g/h)'\n",
    "    str += f'\\nEffective observation time = {effective_obs_time.to(u.h):.1f}'\n",
    "    if pulsar_mode:\n",
    "        str += '\\nPulsar mode'\n",
    "    str += f'\\nOn/Off exposure ratio $\\\\alpha$={alpha:.3f}'\n",
    "    if source_radius == 0:\n",
    "        str += '\\nPoint-like source'\n",
    "    else:\n",
    "        str += f'\\nSource radius: {source_radius:.2f}$^\\\\circ$ ({cut_efficiency:.0%} containment)'\n",
    "    str += f'\\n\\ncta-lstchain {lstchain_version}'\n",
    "    \n",
    "    ax.text(0.05, 0.38, str, \n",
    "            transform=ax.transAxes, fontsize=12, verticalalignment='top',\n",
    "            bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "    \n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Energy (TeV)', fontsize=14)\n",
    "    plt.ylabel(f'SED ( {SED.unit} )', fontsize=14)\n",
    "    plt.ylim(np.nanmin((SED-SED_total_error)).value*0.1, \n",
    "             np.nanmax((SED+SED_total_error)).value*5)\n",
    "\n",
    "    plt.xlim(mean_etrue_vs_ereco[displayed_points][0]/3, mean_etrue_vs_ereco[displayed_points][-1]*3)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,3))\n",
    "    if not pulsar_mode:\n",
    "        plt.scatter(mean_etrue_vs_ereco[displayed_points], SED_total_error/SED, \n",
    "                    s=12, label=f'Observed, stat + backg syst ({backg_systematics_uncertainty:.1%})')\n",
    "    plt.scatter(mean_etrue_vs_ereco[displayed_points], SED_stat_error/SED, \n",
    "                s=12, label='Observed, stat-only')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Energy (TeV)', fontsize=14)\n",
    "    plt.ylabel('Relative SED \\n uncertainty', fontsize=14)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "        \n",
    "else:\n",
    "    print(\"Nothing to display. No valid flux points!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d43a4",
   "metadata": {},
   "source": [
    "### NOTE: in reality, other systematics from data-MC discrepancies (in Aeff, energy-dependent) may make the point-to point fluctuations larger than shown above. Systematic errors of around a few percent (independent in each bin) are to be expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c63cec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
