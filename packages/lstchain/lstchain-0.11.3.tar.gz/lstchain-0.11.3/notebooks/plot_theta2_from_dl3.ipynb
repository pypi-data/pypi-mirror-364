{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an example notebook to plot theta² using DL3 files in custom energy bins\n",
    "\n",
    "It customizes the Gammapy function [`make_theta_squared_table`](https://docs.gammapy.org/1.3/api/gammapy.makers.utils.make_theta_squared_table.html).\n",
    "\n",
    "Theta² plots can also be done from DL2 files, see [explore_DL2.ipynb notebook](https://github.com/cta-observatory/cta-lstchain/blob/main/notebooks/explore_DL2.ipynb).\n",
    "\n",
    "Content:\n",
    "\n",
    "#### 1. Read the given DL3 files\n",
    "\n",
    "#### 2. Data selection masks\n",
    "\n",
    "#### 3. Custom theta2 functions, to create a theta2 table and plot it\n",
    "\n",
    "#### 4. Enter the inputs for the custom theta2 functions\n",
    "\n",
    "#### 5. Plot theta2 distribution for each observation\n",
    "\n",
    "#### 6. Theta2 plot for stacked observations (On/Off distributions)\n",
    "\n",
    "#### 7. Plot just the excess counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by **Chaitanya Priyadarshi** for the previous LST Analysis School and adapted to be used with newly created DL3 files (v0.10.x). It is compatible with Gammapy versions 1.2 and 1.3.\n",
    "\n",
    "This is another example of creating theta2 plots, by using the standard function make_theta_squared_table() in Gammapy, customized to include user-defined energy bins and custom wobble positions for wobble observations. It also adds the CTA outreach approved style for the plots, and separates the counts plots and the excess plots for easy visualization.\n",
    "By default, the OFF theta2 profile is extracted from a mirror position radially symmetric in the FOV to pos_on. The ON and OFF regions are assumed to be of the same size, so the normalisation factor between both regions, alpha = 1.\n",
    "\n",
    "One can either plot theta2 for stacked observations or single observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import numpy as np\n",
    "from astropy.coordinates import Angle, SkyCoord\n",
    "from astropy.table import Table\n",
    "from gammapy.data import DataStore\n",
    "from gammapy.maps import MapAxis\n",
    "from gammapy.maps.utils import edges_from_lo_hi\n",
    "from gammapy.stats import WStatCountsStatistic\n",
    "from pyirf.statistics import li_ma_significance\n",
    "from scipy.stats import chi2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from gammapy import __version__ as gammapy_version\n",
    "\n",
    "print(f\"Using Gammapy {gammapy_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get directory of DL3 files and source information to make the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl3_path = Path('/fefs/aswg/workspace/analysis-school-2024/DL3/Crab')\n",
    "datastore = DataStore.from_dir(dl3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming there is only 1 unique source in the DL3 files in this directory\n",
    "obj_name = np.unique(datastore.obs_table[\"OBJECT\"])[0]\n",
    "\n",
    "target_position = SkyCoord.from_name(obj_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the table of observations\n",
    "datastore.obs_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data selection masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_livetime = 300 #in sec\n",
    "max_zen = 60\n",
    "\n",
    "print('Total runs:', len(datastore.obs_table))\n",
    "\n",
    "d_time = [datastore.obs_table[\"LIVETIME\"]>min_livetime]\n",
    "print(f'Number of runs with more than {min_livetime/60.:.1f} min data:', d_time[0].sum())\n",
    "\n",
    "d_zen = [datastore.obs_table[\"ZEN_PNT\"]<max_zen]\n",
    "print(f'Number of runs with zenith less than {max_zen} deg:', d_zen[0].sum())\n",
    "\n",
    "d_obj = [datastore.obs_table[\"OBJECT\"]==obj_name]\n",
    "print(f'Number of runs with source {obj_name}:', d_obj[0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only some runs based on previous filters\n",
    "obs_table = datastore.obs_table[d_zen[0]*d_obj[0]*d_time[0]]\n",
    "obs_list = datastore.obs_table[d_zen[0]*d_obj[0]*d_time[0]][\"OBS_ID\"]\n",
    "\n",
    "observations = datastore.get_observations(\n",
    "    obs_list,\n",
    "    required_irf=\"point-like\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The list of runs selected are\", obs_list.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total livetime: {datastore.obs_table[\"LIVETIME\"].sum()/3600:.1f} hrs')\n",
    "print(f'Total livetime of selected observations: {obs_table[\"LIVETIME\"].sum()/3600:.1f} hrs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Custom theta2 functions, to create a theta2 table and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_theta_squared_table(\n",
    "    observations, theta_squared_axis, e_reco_axis, position_on,\n",
    "    position_off=None, wobble_pos=None, n_wobbles=4, geometric_norm=True, theta2_norm_min=None, theta2_norm_max=None, exclusion_region=False, theta2_exclusion=None, \n",
    "):\n",
    "    \"\"\"\n",
    "    Make theta squared distribution in the same FoV for a list of wobble `Observation` objects.\n",
    "    \n",
    "    The ON theta2 profile is computed from a given distribution, on_position. By default, \n",
    "    the OFF theta2 profile is extracted from a mirror position radially symmetric in the FOV to pos_on.\n",
    "    \n",
    "    The ON and OFF regions are assumed to be of the same size, so the normalisation\n",
    "    factor between both region alpha = 1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    observations: `~gammapy.data.Observations`\n",
    "        List of observations\n",
    "    theta_squared_axis: `~gammapy.maps.geom.MapAxis`\n",
    "        Axis of edges of the theta2 bin used to compute the distribution\n",
    "    e_reco_axis: `~gammapy.maps.geom.MapAxis`\n",
    "        Axis of edges of the reco energy bin used to compute the distribution\n",
    "    position_on: `~astropy.coordinates.SkyCoord`\n",
    "        Position from which the ON theta^2 distribution is computed\n",
    "    position_off: `astropy.coordinates.SkyCoord`\n",
    "        Position from which the OFF theta^2 distribution is computed.\n",
    "        Default: reflected position w.r.t. to the pointing position\n",
    "    wobble_pos: 'array' or 'List'\n",
    "        Array or List of wobble positions to consider for OFF regions. \n",
    "        1,2,3 corresponding to 90, 180, 270 deg from the source position\n",
    "        This is in the case a specific OFF position is not provided\n",
    "        Default: [2]\n",
    "    n_wobbles: 'int'\n",
    "        Maximum number of wobbles to be considered, while making the selection of the\n",
    "        wobble indices, chosen for OFF counts.\n",
    "        Default: 4\n",
    "    geometric_norm: 'float'\n",
    "        If true the normalization of the background is computed from geometric consideration, if false for the ON and OFF value between theta2_norm_min and theta2_norm_max\n",
    "    theta2_norm_min: 'float'\n",
    "        Minimum theta2 edge for normalization\n",
    "    theta2_norm_max: 'float'\n",
    "        Maximum theta2 edge for normalization\n",
    "    exclusion_region: 'bool'\n",
    "        If true will exclude from of off events counts all events that are within the theta2_exclusion radius of the on position\n",
    "    theta2_exclusion: 'float'\n",
    "        The exclusion radius for the on region, if None will default to theta2_norm_min\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    table : `~astropy.table.Table`\n",
    "        Table containing the ON counts, the OFF counts, acceptance, off acceptance, alpha and the statistics\n",
    "        for each bin.\n",
    "    \"\"\"\n",
    "\n",
    "    if not geometric_norm and (theta2_norm_min is None or theta2_norm_max is None):\n",
    "        raise Exception('Need to provide theta2_norm_min and theta2_norm_max for background normalisation')\n",
    "\n",
    "    table = Table()\n",
    "\n",
    "    table[\"theta2_min\"] = [theta_squared_axis.edges[:-1]]\n",
    "    table[\"theta2_max\"] = [theta_squared_axis.edges[1:]]\n",
    "    table[\"ereco_min\"] = [e_reco_axis.edges[:-1]]\n",
    "    table[\"ereco_max\"] = [e_reco_axis.edges[1:]]\n",
    "    table[\"counts\"] = [np.zeros((e_reco_axis.nbin,theta_squared_axis.nbin))]\n",
    "    table[\"counts_off\"] = [np.zeros((e_reco_axis.nbin,theta_squared_axis.nbin))]\n",
    "    table[\"acceptance\"] = [np.zeros(e_reco_axis.nbin)]\n",
    "    table[\"acceptance_off\"] = [np.zeros(e_reco_axis.nbin)]\n",
    "    table[\"n_sig\"] = [np.zeros((e_reco_axis.nbin,theta_squared_axis.nbin))]\n",
    "    table[\"sqrt_ts\"] = [np.zeros((e_reco_axis.nbin,theta_squared_axis.nbin))]\n",
    "    table[\"excess_errp\"] = [np.zeros((e_reco_axis.nbin,theta_squared_axis.nbin))]\n",
    "    table[\"excess_errn\"] = [np.zeros((e_reco_axis.nbin,theta_squared_axis.nbin))]\n",
    "    table[\"p_value\"] = [np.zeros((e_reco_axis.nbin,theta_squared_axis.nbin))]\n",
    "    \n",
    "    list_obs=[]\n",
    "    \n",
    "    livetime_total = 0\n",
    "\n",
    "    ereco_edges = edges_from_lo_hi(table[\"ereco_min\"].quantity[0], table[\"ereco_max\"].quantity[0])\n",
    "    \n",
    "    # Get the indices of the normalization region in the theta2 axis, from the values provided\n",
    "    if not geometric_norm:\n",
    "        if theta2_norm_min is None or theta2_norm_max is None:\n",
    "            raise Exception('Need to provide theta2_norm_min and theta2_norm_max for background normalisation')\n",
    "        else:\n",
    "            t2_norm_min_idx = np.where(theta_squared_axis.edges.value == theta2_norm_min)[0][0]\n",
    "            t2_norm_max_idx = np.where(theta_squared_axis.edges.value == theta2_norm_max)[0][0]\n",
    "    \n",
    "    create_off = position_off is None\n",
    "\n",
    "    theta2_exclusion = theta2_norm_min if theta2_exclusion is None else theta2_exclusion\n",
    "    if theta2_exclusion is None and exclusion_region:\n",
    "        raise Exception('Need to provide an exclusion radius')\n",
    "    \n",
    "    # Iterate over all observations\n",
    "    for observation in observations:\n",
    "        list_obs.append(observation.obs_id)\n",
    "        \n",
    "        # ON counts\n",
    "        separation = position_on.separation(observation.events.radec)\n",
    "        ereco = observation.events.energy\n",
    "        counts_on, _, _ = np.histogram2d(\n",
    "            ereco, separation ** 2, \n",
    "            bins = (e_reco_axis.edges, theta_squared_axis.edges)\n",
    "        )\n",
    "        mask_exclusion_region = (separation**2).to_value(u.deg*u.deg) < theta2_norm_min\n",
    "        \n",
    "        table[\"counts\"][0] += counts_on\n",
    "        if geometric_norm:\n",
    "            table[\"acceptance\"][0] = np.ones(e_reco_axis.center.shape)\n",
    "        else:\n",
    "            table[\"acceptance\"][0] += np.sum(counts_on[:,t2_norm_min_idx:t2_norm_max_idx], axis=1)\n",
    "        \n",
    "        counts_all_off=[]\n",
    "        if create_off:\n",
    "            # Estimate the position of the mirror position\n",
    "            pos_angle = observation.get_pointing_icrs(observation.tmid).position_angle(position_on)\n",
    "            sep_angle = observation.get_pointing_icrs(observation.tmid).separation(position_on)\n",
    "            \n",
    "            # Calculate the OFF counts from the wobble positions (OFF regions) provided\n",
    "            for i in wobble_pos:\n",
    "               position_off = observation.get_pointing_icrs(observation.tmid).directional_offset_by(\n",
    "                            pos_angle + Angle(2*i*np.pi/n_wobbles, \"rad\"), sep_angle\n",
    "                )\n",
    "               # Angular distance of the events from the mirror position\n",
    "               separation_off = position_off.separation(observation.events.radec)\n",
    "\n",
    "\n",
    "               if exclusion_region:\n",
    "                   counts_off_wob, _, _ = np.histogram2d(\n",
    "                        ereco[~mask_exclusion_region], separation_off[~mask_exclusion_region] ** 2, \n",
    "                        bins = (e_reco_axis.edges, theta_squared_axis.edges)\n",
    "                    )\n",
    "               else:\n",
    "                   counts_off_wob, _, _ = np.histogram2d(\n",
    "                        ereco, separation_off ** 2, \n",
    "                        bins = (e_reco_axis.edges, theta_squared_axis.edges)\n",
    "                    )\n",
    "               counts_all_off.append(counts_off_wob)\n",
    "        else:\n",
    "            # Angular distance of the events from the mirror position\n",
    "           separation_off = position_off.separation(observation.events.radec)\n",
    "\n",
    "           if exclusion_region:\n",
    "               separation_off = separation_off[~mask_exclusion_region]\n",
    "\n",
    "           if exclusion_region:\n",
    "               counts_off_wob, _, _ = np.histogram2d(\n",
    "                    ereco[~mask_exclusion_region], separation_off[~mask_exclusion_region] ** 2, \n",
    "                    bins = (e_reco_axis.edges, theta_squared_axis.edges)\n",
    "                )\n",
    "           else:\n",
    "               counts_off_wob, _, _ = np.histogram2d(\n",
    "                    ereco, separation_off ** 2, \n",
    "                    bins = (e_reco_axis.edges, theta_squared_axis.edges)\n",
    "                )\n",
    "           counts_all_off.append(counts_off_wob)\n",
    "                \n",
    "        counts_off=np.sum(counts_all_off, axis=0)\n",
    "        \n",
    "        table[\"counts_off\"][0] += counts_off\n",
    "        \n",
    "        # Normalisation between ON and OFF is one\n",
    "        if geometric_norm:\n",
    "            table[\"acceptance_off\"][0] = np.ones(e_reco_axis.center.shape)*len(wobble_pos)\n",
    "        else:\n",
    "            table[\"acceptance_off\"][0] +=  np.sum(counts_off[:, t2_norm_min_idx:t2_norm_max_idx], axis=1)\n",
    "        \n",
    "        livetime_total += observation.observation_live_time_duration.to_value(\"s\")\n",
    "\n",
    "    table[\"obs_id\"]=[list_obs]\n",
    "    table[\"n_wobbles\"] = [wobble_pos]\n",
    "    table[\"alpha\"] = [table[\"acceptance\"][0] / table[\"acceptance_off\"][0]]\n",
    "    table[\"livetime_total\"] = [livetime_total]\n",
    "    \n",
    "    # normalized background rate\n",
    "    table[\"bkg_rate\"] = [table[\"counts_off\"][0] / table[\"livetime_total\"][0] * 60]\n",
    "    \n",
    "    for i in np.arange(e_reco_axis.nbin):\n",
    "        table[\"bkg_rate\"][0][i] *= table[\"alpha\"][0][i]\n",
    "        \n",
    "        # Calculate the Statistics\n",
    "        stat = WStatCountsStatistic(\n",
    "            table[\"counts\"][0][i], table[\"counts_off\"][0][i], \n",
    "            np.repeat(table[\"alpha\"][0][i], theta_squared_axis.nbin)\n",
    "        )\n",
    "        if np.all(np.isfinite(stat.sqrt_ts)):\n",
    "            table[\"n_sig\"][0][i] = stat.n_sig # Excess\n",
    "            table[\"sqrt_ts\"][0][i] = stat.sqrt_ts # Significance\n",
    "\n",
    "            table[\"excess_errn\"][0][i] = stat.compute_errn()\n",
    "            table[\"excess_errp\"][0][i] = stat.compute_errp()\n",
    "            table[\"p_value\"][0][i] = chi2.sf(stat.n_sig, 1)\n",
    "        else:\n",
    "            print(f'Non finite values in stats for {ereco_edges[i]}')\n",
    "            table[\"n_sig\"][0][i] = stat.n_sig\n",
    "            table[\"sqrt_ts\"][0][i] = stat.sqrt_ts\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_theta_squared_table(table, theta2_cut, custom_style=None, counts_only=None):\n",
    "    \"\"\"\n",
    "    Plot the theta2 distribution of ON, OFF counts, excess and significance in each theta2bin \n",
    "    from the provided filled Theta2 Table.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table: `~astropy.table.Table`\n",
    "        Required columns: theta2_min, theta2_max, counts, counts_off and alpha\n",
    "    theta2_cut: 'float'\n",
    "        Theta2 cut on the theta2 axis\n",
    "    custom_style: 'Bool'\n",
    "        For the plot style to be CTAO outreach-approved\n",
    "    counts_only: 'Bool'\n",
    "        True for only plotting counts distributions.\n",
    "        False for only plotting excess distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create MapAxis objects of the axes\n",
    "    theta2_edges = edges_from_lo_hi(table[\"theta2_min\"].quantity[0], table[\"theta2_max\"].quantity[0])\n",
    "    \n",
    "    theta2_axis = MapAxis.from_edges(\n",
    "        theta2_edges, interp=\"lin\", name=\"theta_squared\"\n",
    "    )\n",
    "    ereco_edges = edges_from_lo_hi(table[\"ereco_min\"].quantity[0], table[\"ereco_max\"].quantity[0])\n",
    "    \n",
    "    ereco_axis = MapAxis.from_edges(\n",
    "        ereco_edges, interp=\"lin\", name=\"reco_energy\"\n",
    "    )\n",
    "    \n",
    "    total_time = table[\"livetime_total\"][0]/3600\n",
    "    table[\"Sig_LiMa\"] = table[\"alpha\"] # to have the same shape for each energy bin\n",
    "    bin_cut = np.where(theta2_edges==theta2_cut)[0][0]\n",
    "    \n",
    "    # The Li&Ma formula for calculating the significance:\n",
    "    #alpha = table[\"alpha\"][0]\n",
    "    #N_on = np.sum(table[\"counts\"][:bin_cut])\n",
    "    #N_off = np.sum(table[\"counts_off\"][:bin_cut])\n",
    "    \n",
    "    #S = np.sqrt(2 * (N_on * np.log( ((1+alpha)/alpha)*(N_on/(N_on+N_off)) ) + N_off * np.log( (1+alpha)*(N_off/(N_on+N_off)) ) ))\n",
    "    \n",
    "    # For different number of energy bins, fixing the rows and columns of the final plot\n",
    "    if ereco_axis.nbin>16:\n",
    "        nrow=5\n",
    "        ncol=5\n",
    "    elif ereco_axis.nbin>9:\n",
    "        nrow=4\n",
    "        ncol=4\n",
    "    elif ereco_axis.nbin>4:\n",
    "        nrow=3\n",
    "        ncol=3\n",
    "    else:\n",
    "        nrow=2\n",
    "        ncol=2\n",
    "\n",
    "    if custom_style:\n",
    "        style.use('tableau-colorblind10')\n",
    "\n",
    "    fig, axs = plt.subplots(nrow,ncol, figsize=(6*ncol,5.5*nrow))\n",
    "    \n",
    "    # Main title of the plot\n",
    "    if len(table[\"obs_id\"][0])==1:\n",
    "        fig.suptitle(\n",
    "            f'Theta² distribution of Run {table[\"obs_id\"][0][0]} with {len(table[\"n_wobbles\"][0])} wobbles'\n",
    "            f' and cut at {theta2_edges[bin_cut]:.2f}, for total time {total_time:.2f} hr', y=0.95\n",
    "        )\n",
    "    else:\n",
    "        fig.suptitle(\n",
    "            f'Theta² distribution of Runs {table[\"obs_id\"][0][0]}:{table[\"obs_id\"][0][-1]} with'\n",
    "            f' {len(table[\"n_wobbles\"][0])} wobbles and cut at {theta2_edges[bin_cut]:.2f}, '\n",
    "            f'for total time {total_time:.2f} hr', y=0.95\n",
    "        )\n",
    "        \n",
    "    xerr = (theta2_axis.center - theta2_axis.edges[:-1], theta2_axis.edges[1:] - theta2_axis.center)\n",
    "    e_reco_index = 0\n",
    "    \n",
    "    for i in np.arange(nrow):\n",
    "        for j in np.arange(ncol):\n",
    "            if e_reco_index >=ereco_axis.nbin:\n",
    "                axs[i,j].remove()\n",
    "                continue\n",
    "            \n",
    "            alpha = table[\"alpha\"][0][e_reco_index]\n",
    "            N_on = np.sum(table[\"counts\"][0][e_reco_index][:bin_cut])\n",
    "            N_off = np.sum(table[\"counts_off\"][0][e_reco_index][:bin_cut])\n",
    "            N_ex = np.sum(table[\"n_sig\"][0][e_reco_index][:bin_cut])\n",
    "            \n",
    "            # Using Li&Ma's formula:\n",
    "            S_lima = li_ma_significance(N_on, N_off, alpha)\n",
    "            \n",
    "            # This pyIRF function li_ma_significance is analog to Gammapy's WStatCountsStatistic(N_on, N_off, alpha).sqrt_ts\n",
    "            # but we keep to be consistent with the way explore_DL2.ipynb notebook calculates the significance.\n",
    "                \n",
    "            # Using gammapy method, but normalizing the binned significance to get total significance in the cut region\n",
    "            table[\"Sig_LiMa\"][0][e_reco_index] = S_lima\n",
    "            \n",
    "            params_text = (\n",
    "                f'Significance (Li&Ma) = {S_lima:.1f} $\\sigma$' \n",
    "                f'\\nR_$\\gamma$ = {N_ex/total_time/60:.1f} $\\gamma$/min,'\n",
    "                f'\\nR_BG = {np.sum(table[\"bkg_rate\"][0][e_reco_index][:bin_cut]):.1f} events/min'\n",
    "                f'\\nN_on = {N_on}, N_off = {alpha*N_off:.1f}\\n$\\sigma$/sqrt(Hour) = {S_lima/np.sqrt(total_time):.1f}'\n",
    "            )\n",
    "            \n",
    "            if counts_only: # Only ON-background plot\n",
    "                if not custom_style:\n",
    "                    axs[i,j].errorbar(\n",
    "                        theta2_axis.center,\n",
    "                        table[\"counts\"][0][e_reco_index],\n",
    "                        xerr=xerr, \n",
    "                        yerr=np.sqrt(table[\"counts\"][0][e_reco_index]),\n",
    "                        linestyle='None', \n",
    "                        label=\"Counts On\",\n",
    "                        ecolor='k'\n",
    "                    )\n",
    "                    axs[i,j].errorbar(\n",
    "                        theta2_axis.center,\n",
    "                        alpha*table[\"counts_off\"][0][e_reco_index],\n",
    "                        xerr=xerr, \n",
    "                        yerr=np.sqrt(table[\"counts_off\"][0][e_reco_index])/np.sqrt(len(wobble_pos)),\n",
    "                        linestyle='None', \n",
    "                        label=\"Counts Off\",\n",
    "                        ecolor='r'\n",
    "                    )\n",
    "                    axs[i,j].grid()\n",
    "                    axs[i,j].legend()\n",
    "                    axs[i,j].axvline(theta2_edges[bin_cut], ls = ':', color='g')\n",
    "                    axs[i,j].text(theta2_edges[bin_cut] * 1.5, table[\"counts\"][0][e_reco_index].max(), params_text)\n",
    "                    axs[i,j].set_ylim(0, table[\"counts\"][0][e_reco_index].max() * 1.7)\n",
    "                else:\n",
    "                    axs[i,j].errorbar(\n",
    "                        theta2_axis.center, table[\"counts\"][0][e_reco_index],\n",
    "                        yerr=np.sqrt(table[\"counts\"][0][e_reco_index]), \n",
    "                        label=\"ON data\", fmt='o'\n",
    "                    )\n",
    "                    axs[i,j].errorbar(\n",
    "                        theta2_axis.center, alpha*table[\"counts_off\"][0][e_reco_index], \n",
    "                        yerr=alpha*np.sqrt(table[\"counts_off\"][0][e_reco_index]), \n",
    "                        label=\"Background\", fmt='s'\n",
    "                    )\n",
    "                    axs[i,j].grid(ls='dashed')\n",
    "                    axs[i,j].axvline(theta2_edges[bin_cut], ls = '--', color='black', alpha=0.75)\n",
    "                    axs[i,j].legend(title=f'Significance = {S_lima:.1f} $\\sigma$')\n",
    "\n",
    "            else: # Only excess plot\n",
    "                if not custom_style:\n",
    "                    axs[i,j].errorbar(\n",
    "                        theta2_axis.center, table[\"n_sig\"][0][e_reco_index],\n",
    "                        xerr=xerr, \n",
    "                        yerr=(table[\"excess_errn\"][0][e_reco_index], table[\"excess_errp\"][0][e_reco_index]), \n",
    "                        fmt=\"+\", linestyle='None', label=\"Excess\", ecolor='b'\n",
    "                    )\n",
    "                    axs[i,j].grid()\n",
    "                    axs[i,j].legend()\n",
    "                    axs[i,j].axvline(theta2_edges[bin_cut], ls = ':', color='g')\n",
    "                    axs[i,j].text(theta2_edges[bin_cut] * 1.5, table[\"n_sig\"][0][e_reco_index].max(), params_text)\n",
    "                    axs[i,j].set_ylim(0, table[\"n_sig\"][0][e_reco_index].max() * 1.7)\n",
    "                    \n",
    "                else:\n",
    "                    axs[i,j].errorbar(\n",
    "                        theta2_axis.center, table[\"n_sig\"][0][e_reco_index], \n",
    "                        yerr=(table[\"excess_errn\"][0][e_reco_index], table[\"excess_errp\"][0][e_reco_index]), \n",
    "                        label=\"Excess counts\", color='forestgreen', fmt=\"o\"\n",
    "                    )\n",
    "                    axs[i,j].bar(\n",
    "                        theta2_axis.center, table[\"n_sig\"][0][e_reco_index], width = theta2_axis.edges[1]-theta2_axis.edges[0],\n",
    "                        color='limegreen', alpha=0.5\n",
    "                    )\n",
    "                    axs[i,j].axhline(0, color='darkgray')\n",
    "                    axs[i,j].grid(ls='dashed')\n",
    "                    axs[i,j].axvline(theta2_edges[bin_cut], ls = '--', color='black', alpha=0.75)\n",
    "                    axs[i,j].legend(title=f'Significance = {S_lima:.1f} $\\sigma$')\n",
    "\n",
    "            axs[i,j].set_ylabel(\"Counts\")\n",
    "            axs[i,j].set_title(f'Energy {ereco_edges[e_reco_index]:.2f}:{ereco_edges[e_reco_index+1]:.2f} TeV')\n",
    "            axs[i,j].set_xlabel('$\\\\theta^2$ [deg$^2$]')\n",
    "\n",
    "            e_reco_index += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Enter the inputs for the custom theta2 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta2_axis = MapAxis.from_bounds(0, 0.4, nbin=40, interp=\"lin\", unit=\"deg2\")\n",
    "\n",
    "e_reco_axis = MapAxis.from_edges(\n",
    "    [0.01, 0.1, 1, 10] * u.TeV\n",
    ") # For custom binning\n",
    "# For linear binning\n",
    "# MapAxis.from_energy_bounds(0.05, 50, nbin=5, unit=u.TeV)\n",
    "\n",
    "n_wobbles = 4\n",
    "wobble_pos=[1, 2, 3]  # Reflected OFF positions at 90, 180 and 270 deg from the source\n",
    "#wobble_pos=[2]  # For OFF position diametrically opposite the ON position\n",
    "\n",
    "\n",
    "theta2_cut = 0.04\n",
    "theta2_norm_min = 0.2\n",
    "theta2_norm_max = 0.4\n",
    "geometric_norm = True\n",
    "LiMa_sig = {}\n",
    "\n",
    "custom_style = True\n",
    "counts_plot = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Plot theta2 distribution for each observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for i in range(len(observations)):\n",
    "    \n",
    "    theta2 = make_theta_squared_table(\n",
    "        [observations[i]], theta2_axis, e_reco_axis, target_position,\n",
    "        wobble_pos=wobble_pos, geometric_norm=geometric_norm, theta2_norm_min=theta2_norm_min, theta2_norm_max=theta2_norm_max\n",
    "    )\n",
    "    plot_theta_squared_table(theta2, theta2_cut, custom_style=custom_style, counts_only=counts_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Theta2 plot for stacked observations (On/Off distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta2_total = make_theta_squared_table(\n",
    "    observations, theta2_axis, e_reco_axis, target_position,\n",
    "    wobble_pos=wobble_pos, n_wobbles=n_wobbles, geometric_norm=geometric_norm, theta2_norm_min=theta2_norm_min, theta2_norm_max=theta2_norm_max\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_theta_squared_table(theta2_total, theta2_cut, custom_style=custom_style, counts_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 7. Plot just the excess counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_theta_squared_table(theta2_total, theta2_cut, custom_style=custom_style, counts_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
