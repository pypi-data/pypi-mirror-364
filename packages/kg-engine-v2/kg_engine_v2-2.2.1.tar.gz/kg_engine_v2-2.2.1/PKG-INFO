Metadata-Version: 2.4
Name: kg-engine-v2
Version: 2.2.1
Summary: Advanced Knowledge Graph Engine with semantic search and temporal tracking
Project-URL: Homepage, https://github.com/dasein108/kg_semantic
Project-URL: Repository, https://github.com/dasein108/kg_semantic.git
Project-URL: Issues, https://github.com/dasein108/kg_semantic/issues
Author-email: KG/Semantic Engine <acidpictures@gmail.com>
Requires-Python: >=3.8
Requires-Dist: dateparser>=1.1.0
Requires-Dist: llama-index-vector-stores-neo4jvector>=0.3.0
Requires-Dist: llama-index>=0.10.0
Requires-Dist: neo4j>=5.0.0
Requires-Dist: numpy>=1.24.0
Requires-Dist: openai>=1.0.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: sentence-transformers>=2.2.0
Provides-Extra: dev
Requires-Dist: black>=23.0.0; extra == 'dev'
Requires-Dist: flake8>=6.0.0; extra == 'dev'
Requires-Dist: mypy>=1.0.0; extra == 'dev'
Requires-Dist: pytest>=7.0.0; extra == 'dev'
Description-Content-Type: text/markdown

# Knowledge Graph Engine v2

Modern Neo4j-based knowledge graph engine with semantic search capabilities, intelligent relationship management, and performance optimizations.

## ğŸ¯ Overview

A production-ready knowledge graph system built entirely on **Neo4j** for persistent graph storage and vector search. Combines graph database operations with semantic vector search to provide intelligent information storage, retrieval, and reasoning.

## âœ¨ Key Features

- **ğŸ—ï¸ Neo4j-Native Architecture**: Complete Neo4j integration for both graph and vector operations
- **ğŸ” Enhanced Semantic Search**: Improved vector search with dynamic thresholds and contextual boosting
- **ğŸ¤– LLM Integration**: OpenAI/Ollama support for entity extraction and query processing  
- **âš”ï¸ Conflict Resolution**: Intelligent handling of contradicting information with temporal tracking
- **â° Temporal Tracking**: Complete relationship history with date ranges and conflict resolution
- **ğŸ¯ Smart Query Understanding**: Context-aware search with semantic category matching
- **ğŸ“Š Optimized Performance**: 50-74% faster queries with smart caching and lazy loading
- **ğŸš€ Production Ready**: ACID compliance, comprehensive error handling, modern architecture

## ğŸ†• New in v2.1.0

- **âš¡ Performance Optimizations**: GraphQueryOptimizer and Neo4jOptimizer for 50-74% faster queries
- **ğŸ’¾ Smart Caching**: Query result caching with 5-minute TTL for near-instant repeated queries
- **ğŸ”§ Refactored GraphEdge**: Lazy loading with safe accessors, 18% smaller codebase
- **ğŸ› ï¸ Dynamic Relationships**: WORKS_AT, LIVES_IN instead of generic RELATES_TO
- **ğŸ› Bug Fixes**: Fixed "Relationship not populated" errors, enhanced source filtering

## ğŸ“ Project Structure

```
src/                                  # Main source directory
â”œâ”€â”€ kg_engine/                        # Knowledge Graph Engine
â”‚   â”œâ”€â”€ core/                         # Core engine
â”‚   â”‚   â””â”€â”€ engine.py                 # Main KG Engine
â”‚   â”œâ”€â”€ models/                       # Data models
â”‚   â”‚   â””â”€â”€ models.py                 # Graph data structures
â”‚   â”œâ”€â”€ storage/                      # Storage components
â”‚   â”‚   â”œâ”€â”€ graph_db.py               # Neo4j graph operations
â”‚   â”‚   â”œâ”€â”€ neo4j_vector_store.py     # Vector storage
â”‚   â”‚   â”œâ”€â”€ vector_store.py           # Vector store interface
â”‚   â”‚   â””â”€â”€ ...                       # Other storage components
â”‚   â”œâ”€â”€ llm/                          # LLM integration
â”‚   â”‚   â””â”€â”€ llm_interface.py          # OpenAI/Ollama interface
â”‚   â”œâ”€â”€ config/                       # Configuration
â”‚   â”‚   â”œâ”€â”€ neo4j_config.py           # Neo4j settings
â”‚   â”‚   â””â”€â”€ neo4j_schema.py           # Schema management
â”‚   â””â”€â”€ utils/                        # Utilities
â”‚       â”œâ”€â”€ date_parser.py            # Date parsing
â”‚       â”œâ”€â”€ graph_query_optimizer.py  # Query optimization
â”‚       â”œâ”€â”€ neo4j_optimizer.py        # Neo4j optimizations
â”‚       â””â”€â”€ ...                       # Other utilities
â”œâ”€â”€ examples/                         # Usage examples
â”‚   â”œâ”€â”€ examples.py                   # Basic examples
â”‚   â”œâ”€â”€ bio_example.py                # Biographical demo
â”‚   â””â”€â”€ simple_bio_demo.py            # Simple demo
â””â”€â”€ test_neo4j_integration.py         # Test suite

docs/                                 # Comprehensive documentation
â”œâ”€â”€ architecture/                     # System design
â”œâ”€â”€ user-guide/                       # Getting started
â”œâ”€â”€ api/                              # API reference
â””â”€â”€ development/                      # Development guides
```

## ğŸš€ Quick Start

### Prerequisites
```bash
# Install Neo4j (required)
docker run --name neo4j -p7474:7474 -p7687:7687 -d \
    -e NEO4J_AUTH=neo4j/password \
    neo4j:latest
```

### Installation
```bash
pip install -e .
```

### Basic Usage
```python
from src.kg_engine import KnowledgeGraphEngineV2, InputItem
from src.kg_engine.config import Neo4jConfig

# Initialize with Neo4j
engine = KnowledgeGraphEngineV2(
    api_key="your-openai-key",  # or "ollama" for local LLM
    neo4j_config=Neo4jConfig()
)

# Add knowledge
result = engine.process_input([
    InputItem(description="Alice works as a software engineer at Google"),
    InputItem(description="Bob lives in San Francisco")
])

# Search with natural language
response = engine.search("Who works at Google?")
print(response.answer)  # "Alice works as a software engineer at Google."
```

## ğŸ¤– LLM Setup Options

### Option 1: OpenAI (Recommended for Production)
```bash
export OPENAI_API_KEY="your-api-key"
```

```python
engine = KnowledgeGraphEngineV2(
    api_key="your-openai-key",
    model="gpt-4.1-nano"  # Fast and cost-effective
)
```

### Option 2: Local Ollama (Privacy & Cost-Free)
```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Start server
ollama serve

# Pull a model
ollama pull llama3.2:3b  # Recommended: good balance of size/performance
```

```python
engine = KnowledgeGraphEngineV2(
    api_key="ollama",
    base_url="http://localhost:11434/v1",
    model="llama3.2:3b"
)
```

## ğŸ—ï¸ Optimized Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM Interface â”‚    â”‚   Graph Database â”‚    â”‚  Vector Store   â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ Entity Extractâ”‚    â”‚ â€¢ Neo4j Native   â”‚    â”‚ â€¢ Neo4j Vectors â”‚
â”‚ â€¢ Query Parse   â”‚    â”‚ â€¢ Query Cache    â”‚    â”‚ â€¢ Semantic      â”‚
â”‚ â€¢ Answer Gen.   â”‚    â”‚ â€¢ Optimizations  â”‚    â”‚ â€¢ Search        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ KG Engine v2        â”‚
                    â”‚  (Optimized)        â”‚
                    â”‚                     â”‚
                    â”‚ â€¢ Process Input     â”‚
                    â”‚ â€¢ Smart Updates     â”‚
                    â”‚ â€¢ Hybrid Search     â”‚
                    â”‚ â€¢ Query Caching     â”‚
                    â”‚ â€¢ Safe Accessors    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Advanced Features

### Intelligent Conflict Resolution
```python
# Initial information
engine.process_input([InputItem(description="Alice lives in Boston")])

# Update with conflicting information (automatically resolves)
engine.process_input([InputItem(description="Alice moved to Seattle in 2024")])

# System automatically:
# 1. Marks old relationship as obsolete
# 2. Adds new relationship as active
# 3. Maintains complete history
```

### Optimized Search Performance
```python
# Fast cached queries (< 1ms for repeated searches)
response = engine.search("Who works in technology?")  # First call: ~100ms
response = engine.search("Who works in technology?")  # Cached: < 1ms

# Enhanced semantic understanding with contextual boosting
response = engine.search("Who was born in Europe?")
# âœ… Returns all European births: Berlin, Lyon, Barcelona, Paris

# Safe relationship access (no more "Relationship not populated" errors)
for result in response.results:
    edge = result.triplet.edge
    subject = edge.get_subject_safe()  # Safe accessor
    relationship = edge.get_relationship_safe()  # Safe accessor
    obj = edge.get_object_safe()  # Safe accessor
```

### Temporal Relationship Tracking
```python
# Natural language dates
engine.process_input([
    InputItem(description="Project started", from_date="2 months ago"),
    InputItem(description="Alice joined", from_date="last week")
])
```

## ğŸ“š Documentation

- **[ğŸ“– Quick Start](docs/user-guide/quick-start.md)**: Get running in 5 minutes
- **[ğŸ—ï¸ Architecture](docs/architecture/overview.md)**: System design and components
- **[ğŸ“Š Workflows](docs/architecture/workflows.md)**: Process flows with diagrams
- **[ğŸ”§ API Reference](docs/api/README.md)**: Complete API documentation
- **[ğŸ‘©â€ğŸ’» Development](docs/development/README.md)**: Development setup and guidelines

## ğŸš¦ Running Examples

```bash
# Run basic examples
python src/examples/examples.py

# Run biographical knowledge graph demo  
python src/examples/simple_bio_demo.py

# Verify project structure
python verify_structure.py
```

Expected output:
```
âœ… Neo4j connection verified
ğŸš€ Knowledge Graph Engine v2 initialized
   - Vector store: kg_v2 (neo4j)
   - Graph database: Neo4j (persistent)
   
=== Example: Semantic Relationship Handling ===
1. Adding: John Smith teaches at MIT
   Result: 1 new edge(s) created
...
```

## ğŸ” Search Capabilities

The Knowledge Graph Engine v2 features advanced semantic search with:

- **Performance Optimizations**: Query caching, lazy loading, and optimized Cypher queries
- **Dynamic Similarity Thresholds**: Base threshold of 0.3 with context-specific adjustments
- **Semantic Category Matching**: Understands relationships between concepts (e.g., "technology" â†’ "software engineer")
- **Query-Specific Boosting**: Different query types get tailored relevance scoring
- **Geographic Intelligence**: Recognizes European cities and other geographic relationships
- **Safe Data Access**: Robust error handling with safe accessor methods

### Example Queries
```python
# Technology and profession queries
"Who works in technology?" â†’ Finds software engineers, developers, tech professionals
"Tell me about engineers" â†’ Returns all engineering-related professions

# Geographic queries  
"Who was born in Europe?" â†’ Finds Berlin, Lyon, Barcelona, Paris births
"Who lives in Paris?" â†’ Returns all Paris residents

# Activity and interest queries
"What do people do for hobbies?" â†’ Returns all "enjoys" relationships
"Tell me about photographers" â†’ Finds people who enjoy or specialize in photography

# Entity-specific queries
"Tell me about Emma Johnson" â†’ Returns all relationships for Emma
```

## ğŸ§ª Testing

Run the comprehensive test suite:

```bash
# Core integration tests
python test_neo4j_integration.py

# Performance optimization tests
python test_optimizations.py

# Relationship fix validation
python test_relationship_fix.py

# Quick validation
python test_quick_relationship_fix.py
```

## ğŸ“ˆ Performance Benchmarks

| Operation | Before Optimization | After Optimization | Improvement |
|-----------|-------------------|-------------------|-------------|
| Entity Exploration | 20-50ms | 8-15ms | ~60% faster |
| Vector Search | 100-200ms | 40-80ms | ~50% faster |
| Conflict Detection | 150-300ms | 50-100ms | ~67% faster |
| Path Finding | 80-160ms | 25-50ms | ~70% faster |
| Cached Queries | N/A | < 1ms | Near-instant |

## ğŸ”§ Development

For development setup and contributing guidelines, see [docs/development/README.md](docs/development/README.md).

### Key Implementation Details

```python
# Safe edge property access
edge = result.triplet.edge
if edge.has_graph_data():
    subject, relationship, obj = edge.get_graph_data()
else:
    subject = edge.get_subject_safe() or "Unknown"
    relationship = edge.get_relationship_safe() or "Unknown"
    obj = edge.get_object_safe() or "Unknown"

# Optimized queries with caching
cache_key = f"entity_exploration_{entity_name}"
if cached_result := self.graph_db._get_cache(cache_key):
    return cached_result
    
result = self.graph_db.get_entity_relationships_optimized(entity_name)
self.graph_db._set_cache(cache_key, result)
```

## License

MIT License