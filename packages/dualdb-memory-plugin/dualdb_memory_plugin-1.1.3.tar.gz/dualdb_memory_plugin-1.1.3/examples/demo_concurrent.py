# examples/demo_concurrent.py

import os
import csv
import time
import threading
from concurrent.futures import ThreadPoolExecutor

from dualdb_memory.store_sqlite import SQLiteStore
from dualdb_memory.memory import DualDBMemory
from dualdb_memory.summarizer_stub import StubSummarizer

# è¾“å‡ºç›®å½•
OUT_DIR = "demo_concurrent_output"
os.makedirs(OUT_DIR, exist_ok=True)

# æ•°æ®åº“æ–‡ä»¶
active_path  = os.path.join(OUT_DIR, "active.db")
archive_path = os.path.join(OUT_DIR, "archive.db")
log_path     = os.path.join(OUT_DIR, "latencies.csv")

# 1) ç”¨å¼‚æ­¥ + WAL æ¨¡å¼çš„ SQLiteStore åˆ›å»ºå­˜å‚¨
active_store  = SQLiteStore(active_path,  use_async=True)
archive_store = SQLiteStore(archive_path, use_async=True)

# 2) ç›´æ¥ç”¨ DualDBMemory ç»„åˆ
manager = DualDBMemory(
    active_store=active_store,
    archive_store=archive_store,
    summarizer=StubSummarizer(),
    threshold=10000,  # è¶³å¤Ÿå¤§ä»¥é¿å…è½®å›æ‘˜è¦æ‰“æ–­æµ‹è¯•
)

lock = threading.Lock()
log_rows = []

def write_pair(i: int):
    """ä¸€æ¬¡ user+assistant å†™å…¥ï¼Œè®°å½•è€—æ—¶"""
    start = time.time()
    manager.append("user",      f"[T{i}] Hello from user")
    manager.append("assistant", f"[T{i}] Response from assistant")
    elapsed_ms = (time.time() - start) * 1000
    with lock:
        log_rows.append((i, elapsed_ms))

def run_concurrent_demo(workers: int = 8, rounds_per_thread: int = 500):
    total = workers * rounds_per_thread
    print(f"ğŸ”¥ å¼€å§‹å¹¶å‘å†™å…¥ï¼š{workers} çº¿ç¨‹ Ã— {rounds_per_thread} è½® = {total} æ¬¡å†™å…¥")
    with ThreadPoolExecutor(max_workers=workers) as execu:
        for i in range(total):
            execu.submit(write_pair, i)
    print("âœ… å¹¶å‘å†™å…¥ç»“æŸï¼Œæ­£åœ¨å†™æ—¥å¿—â€¦")

    # ç¡®ä¿åå°é˜Ÿåˆ—éƒ½ flush å®Œæ¯•å¹¶å…³é—­è¿æ¥
    manager.close()

    # ä¿å­˜ CSV
    with open(log_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["entry_id", "append_time_ms"])
        writer.writerows(log_rows)

    print(f"å†™å…¥å»¶è¿Ÿæ—¥å¿—ä¿å­˜åœ¨: {log_path}")

if __name__ == "__main__":
    run_concurrent_demo(workers=16, rounds_per_thread=2000)
