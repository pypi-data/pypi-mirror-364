

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Vision User Guide" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://manipulapy.readthedocs.io/user_guide/vision.html" />
<meta property="og:site_name" content="ManipulaPy Documentation" />
<meta property="og:description" content="This comprehensive guide covers the Vision module in ManipulaPy, which provides advanced computer vision capabilities for robotic perception, including stereo vision, object detection, and PyBullet..." />
<meta name="description" content="This comprehensive guide covers the Vision module in ManipulaPy, which provides advanced computer vision capabilities for robotic perception, including stereo vision, object detection, and PyBullet..." />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Vision User Guide &mdash; ManipulaPy 1.1.0 Documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=b4417981" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=b4417981" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=fc837d61"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=fd10adb8"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
      <script src="../_static/design-tabs.js?v=f930bc37"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="CUDA Kernels User Guide" href="CUDA_Kernels.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >

          
          
          <a href="../index.html" class="icon icon-home">
            ManipulaPy
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">üöÄ Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/index.html">Getting Started with ManipulaPy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üõ†Ô∏è API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/index.html">üîß API Reference Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üìö User Guides</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Kinematics.html">Kinematics User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Dynamics.html">Dynamics User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Control.html">Control Module User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Trajectory_Planning.html">Trajectory Planning User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Simulation.html">Simulation Module User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="URDF_Processor.html">URDF Processor User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Singularity_Analysis.html">Singularity Analysis User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Perception.html">Perception User Guide</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Vision User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#getting-started">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#basic-camera-setup">Basic Camera Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="#custom-camera-configuration">Custom Camera Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#core-features">Core Features</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#object-detection-with-yolo">Object Detection with YOLO</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pybullet-virtual-cameras">PyBullet Virtual Cameras</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stereo-vision-pipeline">Stereo Vision Pipeline</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#advanced-usage">Advanced Usage</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#multiple-camera-systems">Multiple Camera Systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="#opencv-camera-integration">OpenCV Camera Integration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#camera-calibration-parameters">Camera Calibration Parameters</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#performance-optimization">Performance Optimization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#memory-management">Memory Management</a></li>
<li class="toctree-l3"><a class="reference internal" href="#efficient-object-detection">Efficient Object Detection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#error-handling-and-debugging">Error Handling and Debugging</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#robust-error-handling">Robust Error Handling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#debugging-tips">Debugging Tips</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#common-issues-and-solutions">Common Issues and Solutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#real-world-applications">Real-World Applications</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#robot-navigation">Robot Navigation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pick-and-place-operations">Pick and Place Operations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#best-practices">Best Practices</a></li>
<li class="toctree-l2"><a class="reference internal" href="#see-also">See Also</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Potential_Field.html">Potential Field Module User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Collision_Checker.html">Collision Checker Module User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="CUDA_Kernels.html">CUDA Kernels User Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ManipulaPy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Vision User Guide</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/user_guide/vision.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="vision-user-guide">
<h1>Vision User Guide<a class="headerlink" href="#vision-user-guide" title="Link to this heading">ÔÉÅ</a></h1>
<p id="user-guide-vision">This comprehensive guide covers the Vision module in ManipulaPy, which provides advanced computer vision capabilities for robotic perception, including stereo vision, object detection, and PyBullet integration.</p>
<nav class="contents local" id="quick-navigation">
<p class="topic-title"><strong>Quick Navigation</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="#overview" id="id1">Overview</a></p></li>
<li><p><a class="reference internal" href="#getting-started" id="id2">Getting Started</a></p>
<ul>
<li><p><a class="reference internal" href="#basic-camera-setup" id="id3">Basic Camera Setup</a></p></li>
<li><p><a class="reference internal" href="#custom-camera-configuration" id="id4">Custom Camera Configuration</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#core-features" id="id5">Core Features</a></p>
<ul>
<li><p><a class="reference internal" href="#object-detection-with-yolo" id="id6">Object Detection with YOLO</a></p></li>
<li><p><a class="reference internal" href="#pybullet-virtual-cameras" id="id7">PyBullet Virtual Cameras</a></p></li>
<li><p><a class="reference internal" href="#stereo-vision-pipeline" id="id8">Stereo Vision Pipeline</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#advanced-usage" id="id9">Advanced Usage</a></p>
<ul>
<li><p><a class="reference internal" href="#multiple-camera-systems" id="id10">Multiple Camera Systems</a></p></li>
<li><p><a class="reference internal" href="#opencv-camera-integration" id="id11">OpenCV Camera Integration</a></p></li>
<li><p><a class="reference internal" href="#camera-calibration-parameters" id="id12">Camera Calibration Parameters</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#performance-optimization" id="id13">Performance Optimization</a></p>
<ul>
<li><p><a class="reference internal" href="#memory-management" id="id14">Memory Management</a></p></li>
<li><p><a class="reference internal" href="#efficient-object-detection" id="id15">Efficient Object Detection</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#error-handling-and-debugging" id="id16">Error Handling and Debugging</a></p>
<ul>
<li><p><a class="reference internal" href="#robust-error-handling" id="id17">Robust Error Handling</a></p></li>
<li><p><a class="reference internal" href="#debugging-tips" id="id18">Debugging Tips</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#common-issues-and-solutions" id="id19">Common Issues and Solutions</a></p></li>
<li><p><a class="reference internal" href="#real-world-applications" id="id20">Real-World Applications</a></p>
<ul>
<li><p><a class="reference internal" href="#robot-navigation" id="id21">Robot Navigation</a></p></li>
<li><p><a class="reference internal" href="#pick-and-place-operations" id="id22">Pick and Place Operations</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#best-practices" id="id23">Best Practices</a></p></li>
<li><p><a class="reference internal" href="#see-also" id="id24">See Also</a></p></li>
</ul>
</nav>
<section id="overview">
<h2><a class="toc-backref" href="#id1" role="doc-backlink">Overview</a><a class="headerlink" href="#overview" title="Link to this heading">ÔÉÅ</a></h2>
<p>The Vision module is a unified computer vision system that brings together:</p>
<ul class="simple">
<li><p><strong>Monocular and stereo camera support</strong> with flexible configuration</p></li>
<li><p><strong>YOLO-based object detection</strong> for real-time obstacle identification</p></li>
<li><p><strong>PyBullet virtual cameras</strong> with interactive debugging sliders</p></li>
<li><p><strong>Stereo vision pipeline</strong> for 3D reconstruction and depth estimation</p></li>
<li><p><strong>Camera calibration utilities</strong> for precise geometric measurements</p></li>
</ul>
<div class="feature-showcase">
   <div class="feature-card">
      <span class="feature-icon">üì∑</span>
      <h4>Multi-Camera Support</h4>
      <p>Configure multiple cameras with individual intrinsics, extrinsics, and distortion parameters</p>
   </div>
   <div class="feature-card">
      <span class="feature-icon">ü§ñ</span>
      <h4>YOLO Integration</h4>
      <p>Real-time object detection with YOLOv8 for robust obstacle identification</p>
   </div>
   <div class="feature-card">
      <span class="feature-icon">üéÆ</span>
      <h4>PyBullet Debug</h4>
      <p>Interactive virtual cameras with real-time parameter adjustment</p>
   </div>
   <div class="feature-card">
      <span class="feature-icon">üëÅÔ∏è</span>
      <h4>Stereo Vision</h4>
      <p>Complete stereo pipeline from rectification to 3D point cloud generation</p>
   </div>
</div></section>
<section id="getting-started">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Getting Started</a><a class="headerlink" href="#getting-started" title="Link to this heading">ÔÉÅ</a></h2>
<section id="basic-camera-setup">
<h3><a class="toc-backref" href="#id3" role="doc-backlink">Basic Camera Setup</a><a class="headerlink" href="#basic-camera-setup" title="Link to this heading">ÔÉÅ</a></h3>
<p>The simplest way to start with the Vision module:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ManipulaPy.vision</span> <span class="kn">import</span> <span class="n">Vision</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Create a basic vision system with default settings</span>
<span class="n">vision</span> <span class="o">=</span> <span class="n">Vision</span><span class="p">()</span>

<span class="c1"># Capture an image (requires PyBullet environment)</span>
<span class="n">rgb_image</span><span class="p">,</span> <span class="n">depth_image</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">capture_image</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üì∏ Captured RGB image: </span><span class="si">{</span><span class="n">rgb_image</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üìè Captured depth image: </span><span class="si">{</span><span class="n">depth_image</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="custom-camera-configuration">
<h3><a class="toc-backref" href="#id4" role="doc-backlink">Custom Camera Configuration</a><a class="headerlink" href="#custom-camera-configuration" title="Link to this heading">ÔÉÅ</a></h3>
<p>For more control, configure your cameras explicitly:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define camera parameters</span>
<span class="n">camera_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;workspace_camera&quot;</span><span class="p">,</span>
    <span class="s2">&quot;translation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>  <span class="c1"># 1 meter above workspace</span>
    <span class="s2">&quot;rotation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>           <span class="c1"># Look down at 45 degrees</span>
    <span class="s2">&quot;fov&quot;</span><span class="p">:</span> <span class="mi">60</span><span class="p">,</span>                        <span class="c1"># Field of view in degrees</span>
    <span class="s2">&quot;near&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>                      <span class="c1"># Near clipping plane</span>
    <span class="s2">&quot;far&quot;</span><span class="p">:</span> <span class="mf">10.0</span><span class="p">,</span>                      <span class="c1"># Far clipping plane</span>
    <span class="s2">&quot;intrinsic_matrix&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">320</span><span class="p">],</span>    <span class="c1"># fx, 0, cx</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">240</span><span class="p">],</span>    <span class="c1"># 0, fy, cy</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>         <span class="c1"># 0, 0, 1</span>
    <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="s2">&quot;distortion_coeffs&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>  <span class="c1"># k1,k2,p1,p2,k3</span>
    <span class="s2">&quot;use_opencv&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>              <span class="c1"># Use PyBullet cameras</span>
    <span class="s2">&quot;device_index&quot;</span><span class="p">:</span> <span class="mi">0</span>                 <span class="c1"># Camera device index</span>
<span class="p">}</span>

<span class="c1"># Create vision system with custom configuration</span>
<span class="n">vision</span> <span class="o">=</span> <span class="n">Vision</span><span class="p">(</span><span class="n">camera_configs</span><span class="o">=</span><span class="p">[</span><span class="n">camera_config</span><span class="p">])</span>
</pre></div>
</div>
</section>
</section>
<section id="core-features">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Core Features</a><a class="headerlink" href="#core-features" title="Link to this heading">ÔÉÅ</a></h2>
<section id="object-detection-with-yolo">
<h3><a class="toc-backref" href="#id6" role="doc-backlink">Object Detection with YOLO</a><a class="headerlink" href="#object-detection-with-yolo" title="Link to this heading">ÔÉÅ</a></h3>
<p>The Vision module integrates YOLOv8 for robust object detection:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Capture images</span>
<span class="n">rgb_image</span><span class="p">,</span> <span class="n">depth_image</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">capture_image</span><span class="p">(</span><span class="n">camera_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Detect obstacles with 3D positioning</span>
<span class="n">obstacle_positions</span><span class="p">,</span> <span class="n">orientations</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">detect_obstacles</span><span class="p">(</span>
    <span class="n">depth_image</span><span class="o">=</span><span class="n">depth_image</span><span class="p">,</span>
    <span class="n">rgb_image</span><span class="o">=</span><span class="n">rgb_image</span><span class="p">,</span>
    <span class="n">depth_threshold</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span>    <span class="c1"># Only consider objects within 5 meters</span>
    <span class="n">camera_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">step</span><span class="o">=</span><span class="mi">2</span>                  <span class="c1"># Depth sampling step for efficiency</span>
<span class="p">)</span>

<span class="c1"># Process detected obstacles</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üîç Detected </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">obstacle_positions</span><span class="p">)</span><span class="si">}</span><span class="s2"> obstacles&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">orientation</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">obstacle_positions</span><span class="p">,</span> <span class="n">orientations</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Obstacle </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  üìç Position: [</span><span class="si">{</span><span class="n">pos</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">pos</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">pos</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">] meters&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  üß≠ Orientation: </span><span class="si">{</span><span class="n">orientation</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> degrees&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The object detection pipeline:</p>
<ol class="arabic simple">
<li><p><strong>YOLO Detection</strong>: Identifies objects in RGB images with bounding boxes</p></li>
<li><p><strong>Depth Analysis</strong>: Uses depth information within bounding boxes</p></li>
<li><p><strong>3D Positioning</strong>: Converts 2D detections to 3D world coordinates</p></li>
<li><p><strong>Orientation Estimation</strong>: Computes object orientation in the XY plane</p></li>
</ol>
</section>
<section id="pybullet-virtual-cameras">
<h3><a class="toc-backref" href="#id7" role="doc-backlink">PyBullet Virtual Cameras</a><a class="headerlink" href="#pybullet-virtual-cameras" title="Link to this heading">ÔÉÅ</a></h3>
<p>For simulation and debugging, use PyBullet‚Äôs virtual cameras:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create an interactive debug camera system</span>
<span class="n">debug_vision</span> <span class="o">=</span> <span class="n">Vision</span><span class="p">(</span>
    <span class="n">use_pybullet_debug</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>    <span class="c1"># Enable PyBullet debug sliders</span>
    <span class="n">show_plot</span><span class="o">=</span><span class="kc">True</span>              <span class="c1"># Display camera feed in matplotlib</span>
<span class="p">)</span>

<span class="c1"># The debug interface provides real-time sliders for:</span>
<span class="c1"># - Camera position (target_x, target_y, target_z)</span>
<span class="c1"># - Camera orientation (yaw, pitch, roll)</span>
<span class="c1"># - View parameters (distance, up axis)</span>
<span class="c1"># - Projection settings (width, height, FOV, near/far planes)</span>
</pre></div>
</div>
<p><strong>Debug Interface Features:</strong></p>
<ul class="simple">
<li><p><strong>Real-time parameter adjustment</strong> via PyBullet GUI sliders</p></li>
<li><p><strong>Live camera feed</strong> displayed in matplotlib window</p></li>
<li><p><strong>Matrix visualization</strong> for view and projection matrices</p></li>
<li><p><strong>Interactive positioning</strong> for optimal camera placement</p></li>
</ul>
</section>
<section id="stereo-vision-pipeline">
<h3><a class="toc-backref" href="#id8" role="doc-backlink">Stereo Vision Pipeline</a><a class="headerlink" href="#stereo-vision-pipeline" title="Link to this heading">ÔÉÅ</a></h3>
<p>For 3D reconstruction, configure a stereo camera pair:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Configure left camera</span>
<span class="n">left_camera_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;left_camera&quot;</span><span class="p">,</span>
    <span class="s2">&quot;translation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="s2">&quot;rotation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="s2">&quot;intrinsic_matrix&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="p">[</span><span class="mi">600</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">320</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">600</span><span class="p">,</span> <span class="mi">240</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="s2">&quot;distortion_coeffs&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Configure right camera (10cm baseline)</span>
<span class="n">right_camera_config</span> <span class="o">=</span> <span class="n">left_camera_config</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">right_camera_config</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;right_camera&quot;</span>
<span class="n">right_camera_config</span><span class="p">[</span><span class="s2">&quot;translation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>  <span class="c1"># 10cm to the right</span>

<span class="c1"># Create stereo vision system</span>
<span class="n">stereo_vision</span> <span class="o">=</span> <span class="n">Vision</span><span class="p">(</span><span class="n">stereo_configs</span><span class="o">=</span><span class="p">(</span><span class="n">left_camera_config</span><span class="p">,</span> <span class="n">right_camera_config</span><span class="p">))</span>

<span class="c1"># Compute rectification maps (do this once)</span>
<span class="n">stereo_vision</span><span class="o">.</span><span class="n">compute_stereo_rectification_maps</span><span class="p">(</span><span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">640</span><span class="p">,</span> <span class="mi">480</span><span class="p">))</span>

<span class="c1"># Capture stereo images</span>
<span class="n">left_image</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">stereo_vision</span><span class="o">.</span><span class="n">capture_image</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Left camera</span>
<span class="n">right_image</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">stereo_vision</span><span class="o">.</span><span class="n">capture_image</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Right camera</span>

<span class="c1"># Process stereo pipeline</span>
<span class="n">left_rect</span><span class="p">,</span> <span class="n">right_rect</span> <span class="o">=</span> <span class="n">stereo_vision</span><span class="o">.</span><span class="n">rectify_stereo_images</span><span class="p">(</span><span class="n">left_image</span><span class="p">,</span> <span class="n">right_image</span><span class="p">)</span>
<span class="n">disparity_map</span> <span class="o">=</span> <span class="n">stereo_vision</span><span class="o">.</span><span class="n">compute_disparity</span><span class="p">(</span><span class="n">left_rect</span><span class="p">,</span> <span class="n">right_rect</span><span class="p">)</span>
<span class="n">point_cloud</span> <span class="o">=</span> <span class="n">stereo_vision</span><span class="o">.</span><span class="n">disparity_to_pointcloud</span><span class="p">(</span><span class="n">disparity_map</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üåê Generated point cloud with </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">point_cloud</span><span class="p">)</span><span class="si">}</span><span class="s2"> 3D points&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Stereo Pipeline Steps:</strong></p>
<ol class="arabic simple">
<li><p><strong>Image Rectification</strong>: Align stereo images for disparity computation</p></li>
<li><p><strong>Disparity Calculation</strong>: Use StereoSGBM for robust disparity estimation</p></li>
<li><p><strong>3D Reconstruction</strong>: Convert disparity to 3D points using camera geometry</p></li>
<li><p><strong>Point Cloud Filtering</strong>: Remove invalid and distant points</p></li>
</ol>
</section>
</section>
<section id="advanced-usage">
<h2><a class="toc-backref" href="#id9" role="doc-backlink">Advanced Usage</a><a class="headerlink" href="#advanced-usage" title="Link to this heading">ÔÉÅ</a></h2>
<section id="multiple-camera-systems">
<h3><a class="toc-backref" href="#id10" role="doc-backlink">Multiple Camera Systems</a><a class="headerlink" href="#multiple-camera-systems" title="Link to this heading">ÔÉÅ</a></h3>
<p>Configure and manage multiple cameras simultaneously:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define multiple camera configurations</span>
<span class="n">camera_configs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>  <span class="c1"># Overview camera</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;overview_camera&quot;</span><span class="p">,</span>
        <span class="s2">&quot;translation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>
        <span class="s2">&quot;rotation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>     <span class="c1"># Look straight down</span>
        <span class="s2">&quot;fov&quot;</span><span class="p">:</span> <span class="mi">80</span><span class="p">,</span>
        <span class="s2">&quot;intrinsic_matrix&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">400</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">320</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">400</span><span class="p">,</span> <span class="mi">240</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
        <span class="s2">&quot;distortion_coeffs&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="p">},</span>
    <span class="p">{</span>  <span class="c1"># Side view camera</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;side_camera&quot;</span><span class="p">,</span>
        <span class="s2">&quot;translation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
        <span class="s2">&quot;rotation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">90</span><span class="p">],</span>     <span class="c1"># Look sideways</span>
        <span class="s2">&quot;fov&quot;</span><span class="p">:</span> <span class="mi">60</span><span class="p">,</span>
        <span class="s2">&quot;intrinsic_matrix&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">320</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">240</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
        <span class="s2">&quot;distortion_coeffs&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">]</span>

<span class="c1"># Create multi-camera vision system</span>
<span class="n">multi_vision</span> <span class="o">=</span> <span class="n">Vision</span><span class="p">(</span><span class="n">camera_configs</span><span class="o">=</span><span class="n">camera_configs</span><span class="p">)</span>

<span class="c1"># Capture from different cameras</span>
<span class="n">overview_rgb</span><span class="p">,</span> <span class="n">overview_depth</span> <span class="o">=</span> <span class="n">multi_vision</span><span class="o">.</span><span class="n">capture_image</span><span class="p">(</span><span class="n">camera_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">side_rgb</span><span class="p">,</span> <span class="n">side_depth</span> <span class="o">=</span> <span class="n">multi_vision</span><span class="o">.</span><span class="n">capture_image</span><span class="p">(</span><span class="n">camera_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Detect obstacles from multiple viewpoints</span>
<span class="n">obstacles_overview</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">multi_vision</span><span class="o">.</span><span class="n">detect_obstacles</span><span class="p">(</span><span class="n">overview_depth</span><span class="p">,</span> <span class="n">overview_rgb</span><span class="p">,</span> <span class="n">camera_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">obstacles_side</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">multi_vision</span><span class="o">.</span><span class="n">detect_obstacles</span><span class="p">(</span><span class="n">side_depth</span><span class="p">,</span> <span class="n">side_rgb</span><span class="p">,</span> <span class="n">camera_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üì∑ Overview camera detected </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">obstacles_overview</span><span class="p">)</span><span class="si">}</span><span class="s2"> obstacles&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üì∑ Side camera detected </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">obstacles_side</span><span class="p">)</span><span class="si">}</span><span class="s2"> obstacles&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="opencv-camera-integration">
<h3><a class="toc-backref" href="#id11" role="doc-backlink">OpenCV Camera Integration</a><a class="headerlink" href="#opencv-camera-integration" title="Link to this heading">ÔÉÅ</a></h3>
<p>Use real hardware cameras with OpenCV:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Configure real camera with OpenCV</span>
<span class="n">real_camera_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;usb_camera&quot;</span><span class="p">,</span>
    <span class="s2">&quot;translation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="s2">&quot;rotation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="s2">&quot;fov&quot;</span><span class="p">:</span> <span class="mi">60</span><span class="p">,</span>
    <span class="s2">&quot;intrinsic_matrix&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="p">[</span><span class="mi">800</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">320</span><span class="p">],</span>    <span class="c1"># Values from camera calibration</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">800</span><span class="p">,</span> <span class="mi">240</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="s2">&quot;distortion_coeffs&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>  <span class="c1"># From calibration</span>
    <span class="s2">&quot;use_opencv&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>        <span class="c1"># Enable OpenCV capture</span>
    <span class="s2">&quot;device_index&quot;</span><span class="p">:</span> <span class="mi">0</span>          <span class="c1"># USB camera device ID</span>
<span class="p">}</span>

<span class="c1"># Create vision system with real camera</span>
<span class="n">real_vision</span> <span class="o">=</span> <span class="n">Vision</span><span class="p">(</span><span class="n">camera_configs</span><span class="o">=</span><span class="p">[</span><span class="n">real_camera_config</span><span class="p">])</span>

<span class="c1"># Note: capture_image() will use OpenCV for image acquisition</span>
<span class="c1"># when use_opencv=True</span>
</pre></div>
</div>
</section>
<section id="camera-calibration-parameters">
<h3><a class="toc-backref" href="#id12" role="doc-backlink">Camera Calibration Parameters</a><a class="headerlink" href="#camera-calibration-parameters" title="Link to this heading">ÔÉÅ</a></h3>
<p>Understanding the camera configuration parameters:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Intrinsic matrix format:</span>
<span class="c1"># [fx  0  cx]</span>
<span class="c1"># [0  fy  cy]</span>
<span class="c1"># [0   0   1]</span>
<span class="c1">#</span>
<span class="c1"># Where:</span>
<span class="c1"># fx, fy = focal lengths in pixels</span>
<span class="c1"># cx, cy = principal point (image center) in pixels</span>

<span class="n">intrinsic_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="n">focal_x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">center_x</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">focal_y</span><span class="p">,</span> <span class="n">center_y</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Distortion coefficients: [k1, k2, p1, p2, k3]</span>
<span class="c1"># k1, k2, k3 = radial distortion coefficients</span>
<span class="c1"># p1, p2 = tangential distortion coefficients</span>
<span class="n">distortion_coeffs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">k1</span><span class="p">,</span> <span class="n">k2</span><span class="p">,</span> <span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span> <span class="n">k3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Extrinsic parameters (pose in world coordinates):</span>
<span class="c1"># translation = [x, y, z] position in meters</span>
<span class="c1"># rotation = [roll, pitch, yaw] in degrees</span>
</pre></div>
</div>
</section>
</section>
<section id="performance-optimization">
<h2><a class="toc-backref" href="#id13" role="doc-backlink">Performance Optimization</a><a class="headerlink" href="#performance-optimization" title="Link to this heading">ÔÉÅ</a></h2>
<section id="memory-management">
<h3><a class="toc-backref" href="#id14" role="doc-backlink">Memory Management</a><a class="headerlink" href="#memory-management" title="Link to this heading">ÔÉÅ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># For long-running applications, manage resources carefully</span>
<span class="n">vision</span> <span class="o">=</span> <span class="n">Vision</span><span class="p">(</span><span class="n">camera_configs</span><span class="o">=</span><span class="n">configs</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Capture and process images</span>
        <span class="n">rgb</span><span class="p">,</span> <span class="n">depth</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">capture_image</span><span class="p">()</span>
        <span class="n">obstacles</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">detect_obstacles</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">rgb</span><span class="p">)</span>

        <span class="c1"># Process obstacles...</span>

        <span class="c1"># Clean up large arrays if needed</span>
        <span class="k">del</span> <span class="n">rgb</span><span class="p">,</span> <span class="n">depth</span>

<span class="k">finally</span><span class="p">:</span>
    <span class="c1"># Always release resources</span>
    <span class="n">vision</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="efficient-object-detection">
<h3><a class="toc-backref" href="#id15" role="doc-backlink">Efficient Object Detection</a><a class="headerlink" href="#efficient-object-detection" title="Link to this heading">ÔÉÅ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Optimize detection parameters for performance</span>
<span class="n">obstacles</span><span class="p">,</span> <span class="n">orientations</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">detect_obstacles</span><span class="p">(</span>
    <span class="n">depth_image</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span>
    <span class="n">rgb_image</span><span class="o">=</span><span class="n">rgb</span><span class="p">,</span>
    <span class="n">depth_threshold</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span>     <span class="c1"># Limit detection range</span>
    <span class="n">camera_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">step</span><span class="o">=</span><span class="mi">4</span>                   <span class="c1"># Increase step size for speed (lower accuracy)</span>
<span class="p">)</span>

<span class="c1"># For real-time applications, consider:</span>
<span class="c1"># - Reducing image resolution</span>
<span class="c1"># - Increasing step size</span>
<span class="c1"># - Limiting depth threshold</span>
<span class="c1"># - Processing every nth frame</span>
</pre></div>
</div>
</section>
</section>
<section id="error-handling-and-debugging">
<h2><a class="toc-backref" href="#id16" role="doc-backlink">Error Handling and Debugging</a><a class="headerlink" href="#error-handling-and-debugging" title="Link to this heading">ÔÉÅ</a></h2>
<section id="robust-error-handling">
<h3><a class="toc-backref" href="#id17" role="doc-backlink">Robust Error Handling</a><a class="headerlink" href="#robust-error-handling" title="Link to this heading">ÔÉÅ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="c1"># Create vision system</span>
    <span class="n">vision</span> <span class="o">=</span> <span class="n">Vision</span><span class="p">(</span><span class="n">camera_configs</span><span class="o">=</span><span class="n">configs</span><span class="p">)</span>

    <span class="c1"># Attempt image capture</span>
    <span class="n">rgb</span><span class="p">,</span> <span class="n">depth</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">capture_image</span><span class="p">(</span><span class="n">camera_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">rgb</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">depth</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;‚ùå Failed to capture images&quot;</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="c1"># Attempt object detection</span>
    <span class="n">obstacles</span><span class="p">,</span> <span class="n">orientations</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">detect_obstacles</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">rgb</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">obstacles</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;‚ö†Ô∏è No obstacles detected&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;‚úÖ Detected </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">obstacles</span><span class="p">)</span><span class="si">}</span><span class="s2"> obstacles&quot;</span><span class="p">)</span>

<span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;‚ùå Vision system error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;‚ùå Unexpected error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">finally</span><span class="p">:</span>
    <span class="k">if</span> <span class="s1">&#39;vision&#39;</span> <span class="ow">in</span> <span class="nb">locals</span><span class="p">():</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="debugging-tips">
<h3><a class="toc-backref" href="#id18" role="doc-backlink">Debugging Tips</a><a class="headerlink" href="#debugging-tips" title="Link to this heading">ÔÉÅ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Enable debug logging</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>

<span class="c1"># Create vision with detailed logging</span>
<span class="n">vision</span> <span class="o">=</span> <span class="n">Vision</span><span class="p">(</span><span class="n">camera_configs</span><span class="o">=</span><span class="n">configs</span><span class="p">,</span> <span class="n">logger_name</span><span class="o">=</span><span class="s2">&quot;DebugVision&quot;</span><span class="p">)</span>

<span class="c1"># Check YOLO model status</span>
<span class="k">if</span> <span class="n">vision</span><span class="o">.</span><span class="n">yolo_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;‚ö†Ô∏è YOLO model not loaded - object detection disabled&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;‚úÖ YOLO model loaded successfully&quot;</span><span class="p">)</span>

<span class="c1"># Verify camera configuration</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">camera</span> <span class="ow">in</span> <span class="n">vision</span><span class="o">.</span><span class="n">cameras</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üì∑ Camera </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">camera</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   Position: </span><span class="si">{</span><span class="n">camera</span><span class="p">[</span><span class="s1">&#39;translation&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   Rotation: </span><span class="si">{</span><span class="n">camera</span><span class="p">[</span><span class="s1">&#39;rotation&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   FOV: </span><span class="si">{</span><span class="n">camera</span><span class="p">[</span><span class="s1">&#39;fov&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">¬∞&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="common-issues-and-solutions">
<h2><a class="toc-backref" href="#id19" role="doc-backlink">Common Issues and Solutions</a><a class="headerlink" href="#common-issues-and-solutions" title="Link to this heading">ÔÉÅ</a></h2>
<p><strong>Issue: No objects detected by YOLO</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solutions:</span>
<span class="c1"># 1. Check if YOLO model loaded properly</span>
<span class="k">if</span> <span class="n">vision</span><span class="o">.</span><span class="n">yolo_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Install ultralytics: pip install ultralytics&quot;</span><span class="p">)</span>

<span class="c1"># 2. Verify image quality</span>
<span class="n">rgb</span><span class="p">,</span> <span class="n">depth</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">capture_image</span><span class="p">()</span>
<span class="k">if</span> <span class="n">rgb</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Image is completely black - check lighting/camera&quot;</span><span class="p">)</span>

<span class="c1"># 3. Adjust detection confidence</span>
<span class="c1"># Lower confidence threshold in detect_obstacles()</span>
</pre></div>
</div>
<p><strong>Issue: Poor stereo reconstruction</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solutions:</span>
<span class="c1"># 1. Ensure proper camera calibration</span>
<span class="c1"># 2. Check baseline distance (should be 5-15% of working distance)</span>
<span class="c1"># 3. Verify image rectification quality</span>

<span class="n">left_rect</span><span class="p">,</span> <span class="n">right_rect</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">rectify_stereo_images</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span>
<span class="c1"># Rectified images should be aligned horizontally</span>
</pre></div>
</div>
<p><strong>Issue: Inaccurate 3D positions</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solutions:</span>
<span class="c1"># 1. Calibrate intrinsic matrix precisely</span>
<span class="c1"># 2. Verify depth image scaling</span>
<span class="c1"># 3. Check coordinate frame conventions</span>

<span class="c1"># Debug depth values</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Depth range: </span><span class="si">{</span><span class="n">depth</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">depth</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Near/far planes: </span><span class="si">{</span><span class="n">camera</span><span class="p">[</span><span class="s1">&#39;near&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">camera</span><span class="p">[</span><span class="s1">&#39;far&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="real-world-applications">
<h2><a class="toc-backref" href="#id20" role="doc-backlink">Real-World Applications</a><a class="headerlink" href="#real-world-applications" title="Link to this heading">ÔÉÅ</a></h2>
<section id="robot-navigation">
<h3><a class="toc-backref" href="#id21" role="doc-backlink">Robot Navigation</a><a class="headerlink" href="#robot-navigation" title="Link to this heading">ÔÉÅ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ManipulaPy.path_planning</span> <span class="kn">import</span> <span class="n">TrajectoryPlanning</span>

<span class="c1"># Integrated obstacle detection for path planning</span>
<span class="k">def</span> <span class="nf">safe_navigation</span><span class="p">():</span>
    <span class="c1"># Detect current obstacles</span>
    <span class="n">rgb</span><span class="p">,</span> <span class="n">depth</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">capture_image</span><span class="p">()</span>
    <span class="n">obstacles</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">detect_obstacles</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">rgb</span><span class="p">,</span> <span class="n">depth_threshold</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>

    <span class="c1"># Update robot&#39;s environmental model</span>
    <span class="n">planner</span> <span class="o">=</span> <span class="n">TrajectoryPlanning</span><span class="p">(</span><span class="n">robot</span><span class="p">,</span> <span class="n">urdf_file</span><span class="p">,</span> <span class="n">dynamics</span><span class="p">,</span> <span class="n">joint_limits</span><span class="p">)</span>

    <span class="c1"># Plan collision-free trajectory</span>
    <span class="n">safe_trajectory</span> <span class="o">=</span> <span class="n">planner</span><span class="o">.</span><span class="n">joint_trajectory</span><span class="p">(</span>
        <span class="n">thetastart</span><span class="o">=</span><span class="n">current_position</span><span class="p">,</span>
        <span class="n">thetaend</span><span class="o">=</span><span class="n">target_position</span><span class="p">,</span>
        <span class="n">Tf</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span>
        <span class="n">N</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="mi">5</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">safe_trajectory</span><span class="p">,</span> <span class="n">obstacles</span>
</pre></div>
</div>
</section>
<section id="pick-and-place-operations">
<h3><a class="toc-backref" href="#id22" role="doc-backlink">Pick and Place Operations</a><a class="headerlink" href="#pick-and-place-operations" title="Link to this heading">ÔÉÅ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">pick_and_place_with_vision</span><span class="p">():</span>
    <span class="c1"># Detect objects in workspace</span>
    <span class="n">rgb</span><span class="p">,</span> <span class="n">depth</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">capture_image</span><span class="p">(</span><span class="n">camera_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Overhead camera</span>
    <span class="n">objects</span><span class="p">,</span> <span class="n">orientations</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">detect_obstacles</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">rgb</span><span class="p">,</span> <span class="n">depth_threshold</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">objects</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No objects found to pick&quot;</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="c1"># Select closest object</span>
    <span class="n">closest_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">objects</span><span class="p">])</span>
    <span class="n">target_object</span> <span class="o">=</span> <span class="n">objects</span><span class="p">[</span><span class="n">closest_idx</span><span class="p">]</span>
    <span class="n">target_orientation</span> <span class="o">=</span> <span class="n">orientations</span><span class="p">[</span><span class="n">closest_idx</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üéØ Targeting object at: </span><span class="si">{</span><span class="n">target_object</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üß≠ Object orientation: </span><span class="si">{</span><span class="n">target_orientation</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">¬∞&quot;</span><span class="p">)</span>

    <span class="c1"># Plan approach trajectory</span>
    <span class="c1"># ... (integrate with kinematics and planning)</span>
</pre></div>
</div>
</section>
</section>
<section id="best-practices">
<h2><a class="toc-backref" href="#id23" role="doc-backlink">Best Practices</a><a class="headerlink" href="#best-practices" title="Link to this heading">ÔÉÅ</a></h2>
<ol class="arabic simple">
<li><p><strong>Camera Placement</strong>
- Position cameras for optimal workspace coverage
- Avoid backlighting and reflective surfaces
- Ensure sufficient lighting for object detection</p></li>
<li><p><strong>Calibration</strong>
- Use high-quality calibration patterns (checkerboards)
- Capture calibration images from multiple angles
- Verify calibration accuracy before deployment</p></li>
<li><p><strong>Performance</strong>
- Choose appropriate image resolutions for your application
- Balance detection accuracy with processing speed
- Use temporal filtering for stable object tracking</p></li>
<li><p><strong>Robustness</strong>
- Implement proper error handling for all vision operations
- Use multiple cameras for redundancy when possible
- Validate detection results before using in control loops</p></li>
<li><p><strong>Integration</strong>
- Coordinate vision frame rates with control loop timing
- Transform coordinates to robot base frame consistently
- Use vision confidence scores in decision making</p></li>
</ol>
</section>
<section id="see-also">
<h2><a class="toc-backref" href="#id24" role="doc-backlink">See Also</a><a class="headerlink" href="#see-also" title="Link to this heading">ÔÉÅ</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="../api/vision.html"><span class="doc">Vision API Reference</span></a> - Complete Vision API reference</p></li>
<li><p><a class="reference internal" href="Perception.html"><span class="doc">Perception User Guide</span></a> - Higher-level perception capabilities</p></li>
<li><p><a class="reference internal" href="../tutorials/index.html"><span class="doc">Tutorials</span></a> - Vision and perception tutorials</p></li>
<li><p><a class="reference internal" href="Simulation.html"><span class="doc">Simulation Module User Guide</span></a> - PyBullet integration guide</p></li>
</ul>
<style>
.feature-showcase {
   display: grid;
   grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
   gap: 1.5rem;
   margin: 2rem 0;
}

.feature-card {
   background: linear-gradient(135deg, #f6f9fc 0%, #ffffff 100%);
   border: 1px solid #e1e8ed;
   border-radius: 12px;
   padding: 1.5rem;
   text-align: center;
   transition: all 0.3s ease;
   box-shadow: 0 2px 4px rgba(0,0,0,0.05);
}

.feature-card:hover {
   transform: translateY(-2px);
   box-shadow: 0 8px 25px rgba(0,0,0,0.1);
   border-color: #1da1f2;
}

.feature-icon {
   font-size: 2.5rem;
   display: block;
   margin-bottom: 1rem;
}

.feature-card h4 {
   margin: 0 0 0.5rem 0;
   color: #14171a;
   font-weight: 600;
}

.feature-card p {
   margin: 0;
   color: #657786;
   font-size: 0.9rem;
   line-height: 1.4;
}
</style></section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="CUDA_Kernels.html" class="btn btn-neutral float-left" title="CUDA Kernels User Guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Mohamed Aboelnar.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>