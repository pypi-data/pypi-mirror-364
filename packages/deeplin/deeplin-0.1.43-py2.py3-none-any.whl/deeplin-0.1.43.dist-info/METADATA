Metadata-Version: 2.3
Name: deeplin
Version: 0.1.43
Summary: deep learning toolbox for LinXueyuan
License: MIT
Author: LinXueyuanStdio
Author-email: 23211526+LinXueyuanStdio@users.noreply.github.com
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 2
Classifier: Programming Language :: Python :: 2.7
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.4
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Dist: fastapi
Requires-Dist: httpx
Requires-Dist: loguru
Requires-Dist: numpy
Requires-Dist: openai
Requires-Dist: pydantic
Requires-Dist: pytest
Requires-Dist: pytest-asyncio
Requires-Dist: python-dotenv
Requires-Dist: torch
Requires-Dist: transformers
Requires-Dist: uvicorn
Requires-Dist: xlin
Description-Content-Type: text/markdown

# deeplin
Deep Learning Toolbox for LinXueyuan

## Hexin Server

详见 [docs/README_FASTAPI.md](docs/README_FASTAPI.md)

启动 FastAPI 服务器以代理 OpenAI API 并使用 hexin_engine 后端处理请求。

```sh
python -m deeplin.inference_engine.hexin_server
python -m deeplin.inference_engine.hexin_server --host 0.0.0.0 --port 8777
```

服务器使用固定的 API key 进行认证：

```python
from openai import OpenAI
OPENAI_API_KEY="sk-deeplin-fastapi-proxy-key-12345"
OPENAI_BASE_URL="http://localhost:8777/v1"
client = OpenAI(
    api_key=OPENAI_API_KEY,
    base_url=OPENAI_BASE_URL,
)
messages = [
    {"role": "user", "content": "Hello!"},
]
response = client.chat.completions.create(
    model="gpt-4o",
    messages=messages,
)
print(response.choices[0].message.content)
```

