Metadata-Version: 2.4
Name: ruleboost
Version: 0.3.0
Summary: Interpretable rule ensembles via gradient boosting
Author-email: Mario Boley <mario.boley@gmail.com>, Fan Yang <fan.yang1@monash.edu>
License-Expression: MIT
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy<2.3,>=2.2.6
Requires-Dist: scipy<1.16,>=1.15.3
Requires-Dist: numba<1.0,>=0.62.1
Requires-Dist: scikit-learn<2.0,>=1.7.0
Requires-Dist: optikon<0.3,==0.2.2
Dynamic: license-file

# ruleboost

Learn additive rule ensembles via gradient boosting.

## Usage

```python
>>> from ruleboost import RuleBoostingClassifier
>>> import numpy as np
>>> x = np.array([[0.1], [0.2], [0.3], [0.4], [0.5], [0.6], [0.7], [0.8], [0.9]])
>>> y = np.array([0, 0, 0, 1, 1, 1, 0, 0, 0])
>>> model = RuleBoostingClassifier(num_rules=1, fit_intercept=True).fit(x, y)
>>> print(model.rules_str()) # doctest: +NORMALIZE_WHITESPACE
    -0.475 if  
    +0.675 if x1 >= 0.400 & x1 <= 0.600
>>> model.predict(x)
array([0, 0, 0, 1, 1, 1, 0, 0, 0])
>>> np.round(model.predict_proba(x)[:, 1], 2)
array([0.38, 0.38, 0.38, 0.55, 0.55, 0.55, 0.38, 0.38, 0.38])
```
