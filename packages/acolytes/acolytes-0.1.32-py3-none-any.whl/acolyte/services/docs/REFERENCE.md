# üìö API Reference - M√≥dulo Services

## conversation_service.py

### Clase ConversationService

#### M√©todos Principales

##### `create_session(initial_message: str) ‚Üí str`

Crea nueva sesi√≥n con ID √∫nico y busca sesiones relacionadas autom√°ticamente.

**Par√°metros:**

- `initial_message`: Mensaje inicial del usuario

**Retorna:**

- `str`: session_id generado con formato hex32

**Caracter√≠sticas:**

- Usa IDGenerator centralizado con `generate_id()`
- Busca autom√°ticamente sesiones relacionadas por similitud sem√°ntica
- Inicializa metadata con timestamps

##### `save_conversation_turn(session_id: str, user_message: str, assistant_response: str, summary: str, tokens_used: int, task_checkpoint_id: Optional[str] = None) ‚Üí None`

Guarda resumen del turno (~90% reducci√≥n) y actualiza total_tokens acumulativo.

**Par√°metros:**

- `session_id`: ID de la sesi√≥n actual
- `user_message`: Mensaje original del usuario
- `assistant_response`: Respuesta original del asistente
- `summary`: Resumen extractivo generado por Semantic
- `tokens_used`: Tokens originales procesados
- `task_checkpoint_id`: ID de la tarea asociada (opcional)

**Caracter√≠sticas:**

- Solo guarda res√∫menes en messages (role="turn_summary")
- Concatena res√∫menes manteniendo √∫ltimos 4 turnos
- Compression ratio basado en tokens, no caracteres
- SmartTokenCounter integrado para m√©tricas precisas

##### `find_related_sessions(query: str, current_session_id: str, limit: int = 10) ‚Üí List[Dict[str, Any]]`

Busca sesiones relacionadas usando RAG h√≠brido (70% sem√°ntico, 30% l√©xico).

**Par√°metros:**

- `query`: Texto a buscar
- `current_session_id`: Sesi√≥n actual para excluir
- `limit`: M√°ximo de resultados

**Retorna:**

- Lista de sesiones con metadata y score de similitud

**Caracter√≠sticas:**

- Usa HybridSearch del m√≥dulo RAG
- Threshold de similitud: 0.7
- Fallback a SQLite si falla Weaviate

##### `get_session_context(session_id: str, include_related: bool = True) ‚Üí Dict[str, Any]`

Recupera contexto completo con res√∫menes, sesiones relacionadas, tarea y decisiones.

**Par√°metros:**

- `session_id`: ID de la sesi√≥n
- `include_related`: Si incluir sesiones relacionadas

**Retorna:**

- Diccionario con contexto completo:
  - `session`: Datos de la sesi√≥n
  - `messages`: Res√∫menes concatenados
  - `related_sessions`: Sesiones similares
  - `task`: Tarea activa si existe
  - `task_summary`: Resumen rico usando get_summary()
  - `decision_summaries`: Decisiones t√©cnicas

**Caracter√≠sticas:**

- Usa get_summary() para contexto rico
- Crea objetos TaskCheckpoint y TechnicalDecision desde BD
- Fallback robusto si falla creaci√≥n de objetos

##### `search_conversations(request: ConversationSearchRequest) ‚Üí List[ConversationSearchResult]`

B√∫squeda sem√°ntica con modelos tipados Pydantic para validaci√≥n autom√°tica.

**Par√°metros:**

- `request`: ConversationSearchRequest con validaci√≥n autom√°tica

**Retorna:**

- Lista de ConversationSearchResult tipados

**Caracter√≠sticas:**

- Type safety con Pydantic
- Validaci√≥n autom√°tica de request
- Mejor integraci√≥n con API

##### `get_last_session() ‚Üí Optional[Dict[str, Any]]`

Obtiene √∫ltima sesi√≥n para continuidad autom√°tica.

##### `complete_session(session_id: str) ‚Üí None`

Marca sesi√≥n como completada actualizando metadata.

##### `invalidate_cache_for_file(file_path: str) ‚Üí None`

Invalida cache relacionado con archivo modificado publicando eventos.

#### M√©todos Internos

##### `_execute_with_retry(operation_name: str, db_operation: Callable, *args, max_attempts: int = 3) ‚Üí Any`

Retry logic robusto para operaciones SQLite con backoff exponential.

**Caracter√≠sticas:**

- Exponential backoff: 0.5s, 1s, 2s
- Usa `is_retryable()` para locks y timeouts
- M√©tricas: `db_retries_attempted`, `db_retries_successful`

##### `_fallback_search_typed(query: str, exclude_session_id: Optional[str], limit: int, time_range: Optional[tuple], request: ConversationSearchRequest) ‚Üí List[ConversationSearchResult]`

B√∫squeda fallback en SQLite retornando modelos tipados.

### Configuraci√≥n

Lee desde `.acolyte`:

- `limits.max_related_sessions`: M√°ximo de sesiones relacionadas (default: 10)
- `limits.related_sessions_chain`: Longitud cadena de continuidad (default: 5)
- `limits.max_summary_turns`: Turnos a mantener en resumen (default: 4)

---

## task_service.py

### Clase TaskService

#### M√©todos Principales

##### `create_task(title: str, description: str, task_type: TaskType, initial_session_id: str) ‚Üí str`

Crea nueva tarea que agrupa m√∫ltiples sesiones relacionadas.

**Par√°metros:**

- `title`: T√≠tulo descriptivo
- `description`: Descripci√≥n detallada
- `task_type`: IMPLEMENTATION, DEBUGGING, REFACTORING, etc.
- `initial_session_id`: Primera sesi√≥n asociada

**Retorna:**

- `str`: task_id generado

**Caracter√≠sticas:**

- Usa `generate_id()` para IDs hex32
- Crea relaci√≥n inicial en task_sessions
- Detecta autom√°ticamente tipo si no se especifica

##### `associate_session_to_task(task_id: str, session_id: str) ‚Üí None`

Asocia sesi√≥n a tarea existente con relaci√≥n many-to-many.

##### `get_task_full_context(task_id: str) ‚Üí Dict[str, Any]`

Recupera contexto completo con sesiones, decisiones, timeline y archivos clave.

**Retorna:**

- Diccionario con:
  - `task`: Datos de la tarea
  - `sessions`: Todas las sesiones asociadas
  - `decisions`: Decisiones t√©cnicas
  - `timeline`: Cronolog√≠a de eventos
  - `key_files`: Archivos modificados frecuentemente

##### `save_technical_decision(decision: TechnicalDecision) ‚Üí None`

Guarda decisi√≥n t√©cnica detectada con validaci√≥n de IDs requeridos.

**Par√°metros:**

- `decision`: Objeto TechnicalDecision completo

**Caracter√≠sticas:**

- Valida que decision tenga task_id y session_id
- Usa `generate_id()` para el ID de la decisi√≥n
- Serializa alternatives_considered como JSON

##### `find_active_task(user_id: str = "default") ‚Üí Optional[TaskCheckpoint]`

Encuentra tarea activa del usuario (siempre "default" en mono-usuario).

##### `complete_task(task_id: str) ‚Üí None`

Marca tarea como completada actualizando status.

##### `get_recent_decisions(task_id: str, limit: int = 5) ‚Üí List[TechnicalDecision]`

Obtiene objetos TechnicalDecision recientes para usar get_summary().

**Caracter√≠sticas:**

- Convierte filas de BD a objetos TechnicalDecision
- Parsea alternatives_considered como JSON
- Manejo robusto de errores con fallback

---

## chat_service.py

### Clase ChatService

#### Constructor

```python
def __init__(self,
    conversation_service: Optional[ConversationService] = None,
    task_service: Optional[TaskService] = None,
    semantic_analyzer: Optional[Any] = None,
    rag_service: Optional[Any] = None,
    git_service: Optional[GitService] = None,
    debug: bool = False)
```

**Caracter√≠sticas:**

- Inyecci√≥n de dependencias para evitar imports circulares
- Todos los servicios son opcionales con fallback
- Debug mode configurable por instancia

#### M√©todos Principales

##### `process_message(message: str, session_id: Optional[str] = None, debug: Optional[bool] = None) ‚Üí Dict[str, Any]`

Procesa mensaje completo orquestando an√°lisis, b√∫squeda, generaci√≥n y persistencia.

**Par√°metros:**

- `message`: Mensaje del usuario
- `session_id`: ID de sesi√≥n existente o None para nueva
- `debug`: Override del debug mode de la instancia

**Retorna:**

- Diccionario con:
  - `response`: Respuesta generada
  - `session_id`: ID de la sesi√≥n
  - `tokens_used`: Tokens procesados
  - `debug_info`: Info de debug si est√° activado

**Flujo completo:**

1. An√°lisis de intenci√≥n con Semantic
2. Detecci√≥n de nueva tarea
3. B√∫squeda h√≠brida con RAG
4. Compresi√≥n contextual si query espec√≠fico
5. Construcci√≥n de System Prompt
6. Generaci√≥n con Ollama (con retry)
7. Generaci√≥n de resumen
8. Detecci√≥n de decisiones t√©cnicas
9. Persistencia en ConversationService

##### `get_active_session_info() ‚Üí Dict[str, Any]`

Obtiene informaci√≥n de sesi√≥n activa para dashboard o status checks.

#### M√©todos Helper Cr√≠ticos

##### `_handle_new_chat() ‚Üí str`

Gesti√≥n autom√°tica de contexto previo (Decisi√≥n #7).

**Caracter√≠sticas:**

- Carga tarea activa si existe
- Si no hay tarea, carga √∫ltima sesi√≥n
- No pregunta, asume continuidad

##### `_generate_with_retry(system_prompt: str, user_message: str, context_chunks: list, max_tokens: int, max_attempts: int = 3) ‚Üí str`

Retry logic robusto para Ollama con backoff exponencial.

**Caracter√≠sticas:**

- 3 intentos con backoff: 1s, 2s, 4s
- Usa `is_retryable()` de excepciones
- M√©tricas: `ollama_retries_attempted`, `ollama_retries_successful`

##### `_get_project_info() ‚Üí Dict[str, Any]`

Obtiene info del proyecto desde .acolyte + integraci√≥n GitService.

**Retorna:**

- `name`: Nombre del proyecto
- `stack`: Stack tecnol√≥gico (lista plana)
- `structure`: Estructura de directorios
- `branch`: Branch actual si GitService disponible
- `recent_files`: Archivos modificados recientemente

##### `_infer_task_type(message: str) ‚Üí TaskType`

Inferencia inteligente de TaskType usando patterns.

**Patterns:**

- IMPLEMENTATION: "implementar", "crear", "a√±adir"
- DEBUGGING: "error", "bug", "arreglar"
- REFACTORING: "refactorizar", "mejorar", "optimizar"
- RESEARCH: "investigar", "analizar", "estudiar"

### Correcciones Importantes

#### Flujo de Chunks para Res√∫menes

```python
# Semantic necesita chunks para extraer entidades
summary = await self.semantic.generate_summary(
    user_msg=message,
    assistant_msg=response,
    context_chunks=chunks  # NECESARIO para extraer entidades
)
```

#### TokenBudgetManager

```python
# Semantic retorna objeto TokenDistribution
distribution = await self.semantic.analyze_query_intent(query)

# TokenBudgetManager espera string, usar solo el tipo
self.token_manager.allocate_for_query_type(distribution.type)  # .type
```

#### Conversi√≥n DetectedDecision ‚Üí TechnicalDecision

```python
# Semantic detecta decisi√≥n pero sin IDs
detected = await self.semantic.detect_technical_decision(message)

if detected:
    # ChatService completa los IDs necesarios
    decision = TechnicalDecision(
        decision_type=detected.decision_type,
        title=detected.title,
        description=detected.description,
        rationale=detected.rationale,
        alternatives_considered=detected.alternatives_considered,
        impact_level=detected.impact_level,
        session_id=self.current_session.id,  # ChatService tiene el ID
        task_id=self.current_task.id if self.current_task else None
    )

    # Guardar v√≠a TaskService
    await self.task_service.save_technical_decision(decision)
```

---

## indexing_service.py

### Clase IndexingService

#### Estado: 95% Implementado

Pipeline completo implementado, solo falta re-indexaci√≥n autom√°tica por patr√≥n.

#### M√©todos Principales

##### `index_files(files: List[str], trigger: str = "manual", task_id: Optional[str] = None) ‚Üí Dict[str, Any]`

Orquesta chunking, enrichment, embeddings y Weaviate con task_id opcional para progreso WebSocket.

**Par√°metros:**

- `files`: Lista de archivos a indexar
- `trigger`: Origen de la indexaci√≥n
  - 'commit': Desde post-commit hook
  - 'pull': Desde post-merge hook (invalida cache)
  - 'checkout': Desde post-checkout hook
  - 'fetch': Desde post-fetch hook
  - 'manual': Solicitado por usuario
- `task_id`: ID opcional para notificaciones WebSocket

**Retorna:**

- Diccionario con estad√≠sticas:
  - `indexed`: Archivos indexados exitosamente
  - `failed`: Archivos que fallaron
  - `chunks_created`: Total de chunks generados
  - `embeddings_generated`: Total de embeddings

**Caracter√≠sticas:**

- Progress tracking via EventBus con task_id
- Batch processing: 20 archivos por batch
- 4 workers paralelos configurables
- Respeta .acolyteignore

#### Pipeline Completo

##### `_chunk_files(files: List[str]) ‚Üí List[Chunk]`

Usa AdaptiveChunker de RAG cuando est√° disponible.

**Caracter√≠sticas:**

- An√°lisis AST para Python con detecci√≥n de complejidad
- Respeto de l√≠mites naturales del c√≥digo
- Overlap inteligente que preserva contexto
- Fallback a implementaci√≥n simple si no disponible

##### `_detect_chunk_type(content: str, file_extension: str) ‚Üí ChunkType`

Usa regex patterns para detectar 18 tipos:

- FUNCTION, METHOD, CLASS, CONSTRUCTOR
- INTERFACE, TYPE_DEFINITION, ENUM
- IMPORT_BLOCK, CONFIG, CONSTANT
- DECORATOR, ASYNC_FUNCTION, GENERATOR
- PROPERTY, ABSTRACT_METHOD, STATIC_METHOD
- MIXIN, TRAIT

##### `_process_batch(files: List[str], trigger: str) ‚Üí Dict[str, Any]`

Procesa batch completo: chunking ‚Üí enrichment ‚Üí embeddings ‚Üí Weaviate.

##### `_prepare_weaviate_object(chunk: Chunk, enrichment_metadata: Dict) ‚Üí Dict[str, Any]`

Combina chunk + metadata Git + patterns para objeto Weaviate final.

**Campos generados:**

- Todos los campos del chunk original
- Metadata Git anidada (git_metadata.author, git_metadata.commit_hash, etc.)
- Patterns detectados (is_test_code, has_error_handling, etc.)
- chunk_type en MAY√öSCULAS para compatibilidad BD

##### `_index_to_weaviate(data_object: Dict, vector: List[float]) ‚Üí None`

Indexaci√≥n directa en Weaviate con embeddings.

**Caracter√≠sticas:**

- Soporta EmbeddingVector y listas Python
- Manejo de errores con logging detallado
- Usa to_weaviate() cuando disponible

##### `_filter_files(files: List[str]) ‚Üí List[str]`

Respeta .acolyteignore, valida tama√±o y extensiones.

**Validaciones:**

- Tama√±o m√°ximo: 10MB por archivo
- 40+ extensiones soportadas
- Patterns de .acolyteignore

##### `_notify_progress(progress: IndexingProgress, task_id: Optional[str] = None, files_skipped: int = 0, chunks_created: int = 0, embeddings_generated: int = 0, errors_count: int = 0) ‚Üí None`

Publica ProgressEvent via EventBus con estad√≠sticas completas.

**Caracter√≠sticas:**

- Incluye task_id para filtrado en WebSocket
- Estad√≠sticas reales: files_skipped, chunks_created, etc.
- current_file del objeto progress
- WebSocket recibe estad√≠sticas reales
- Logging inteligente solo en intervalos del 10%

---

## git_service.py

### Clase GitService

#### M√©todos Principales

##### `detect_changes_from_others() ‚Üí List[Dict[str, Any]]`

Detecta cambios de otros desarrolladores DESPU√âS de pull/fetch.

**Retorna:**

- Lista de diccionarios con:
  - `type`: Tipo de cambio (add, modify, delete)
  - `files`: Archivos afectados
  - `author`: Autor del cambio
  - `date`: Fecha del cambio

**Caracter√≠sticas:**

- Solo detecta despu√©s de que el usuario hace pull
- Compara con √∫ltimo estado conocido
- Identifica cambios por otros desarrolladores

##### `analyze_potential_conflicts(files_to_modify: List[str]) ‚Üí Dict[str, Any]`

Analiza conflictos potenciales con severity 0-10 y sugerencias.

**Retorna:**

- Diccionario con:
  - `severity`: 0-10 basado en overlaps y autores
  - `conflicts`: Lista de conflictos detectados
  - `suggestions`: Sugerencias para resolver

##### `get_co_modification_patterns(file_path: str, days_back: int = 30) ‚Üí List[Tuple[str, float]]`

Encuentra archivos que cambian juntos para grafo neuronal.

**Retorna:**

- Lista de tuplas (archivo, frecuencia)

##### `notify_in_chat(notification_type: str, data: Dict[str, Any]) ‚Üí str`

Genera notificaci√≥n amigable para mostrar en chat.

**Tipos soportados:**

- `file_updated`: "Veo que actualizaste auth.py..."
- `potential_conflicts`: Conflictos con severity
- `branch_changed`: Cambio de rama
- `others_changes`: Cambios de otros devs

#### Sistema de Cache y Eventos

##### `@property repo ‚Üí Repo`

Cache con TTL de 5 minutos + lazy loading.

**Caracter√≠sticas:**

- Detecta cambios externos autom√°ticamente
- Se recarga cuando expira TTL
- Thread-safe con locks

##### `_publish_cache_invalidation(reason: str, files: List[str], target_services: List[str] = ["conversation", "indexing", "enrichment"]) ‚Üí None`

Integraci√≥n completa con EventBus.

**Publica CacheInvalidateEvent con:**

- `source`: "git_service"
- `target_service`: Servicios objetivo
- `key_pattern`: Patr√≥n de archivos
- `reason`: Raz√≥n de invalidaci√≥n

##### `invalidate_repo_cache() ‚Üí None`

Invalida cache del repo cuando se detectan cambios externos.

#### Notificaciones Espec√≠ficas

- `_notify_file_updated(data: Dict) ‚Üí str`: Archivos actualizados
- `_notify_conflicts(data: Dict) ‚Üí str`: Conflictos detectados
- `_notify_branch_change(data: Dict) ‚Üí str`: Cambios de rama
- `_notify_others_changes(data: Dict) ‚Üí str`: Cambios de otros

### Detecci√≥n de Identidad

Maneja m√∫ltiples identidades del desarrollador:

- Compara emails en min√∫sculas
- Soporta m√∫ltiples emails/nombres
- Funciona sin configuraci√≥n Git

## Observaciones

- **NO endpoints HTTP**: Solo l√≥gica interna, API los expone
- **Inyecci√≥n de dependencias**: ChatService acepta servicios externos
- **Fallback graceful**: Si falla Weaviate, contin√∫a con SQLite
- **Cache coordinado**: Sistema de invalidaci√≥n via EventBus funcional
- **Mono-usuario**: user_id siempre "default", sin rate limiting
- **Decisi√≥n #1 cumplida**: Solo guarda res√∫menes, ~90% reducci√≥n
- **Decisi√≥n #11 cumplida**: Git reactivo, NO fetch autom√°tico
- **Retry logic robusto**: ConversationService y ChatService con backoff
- **Modelos tipados**: ConversationSearch usa Pydantic
- **Sistema de errores consolidado**: Importan desde `core.exceptions`
- **M√©tricas extensivas**: Cada operaci√≥n importante se mide
- **L√≠mites configurables**: Via .acolyte para flexibilidad
- **18 ChunkTypes**: Detecci√≥n autom√°tica por regex patterns
- **Pipeline indexaci√≥n completo**: No es esqueleto
- **Sistema cache TTL**: GitService 5 minutos para cambios externos
- **Integraci√≥n EventBus**: GitService publica, otros invalidan cache
- **IDs centralizados**: Todos usan `generate_id()` formato hex32
- **Logging estrat√©gico**: En puntos cr√≠ticos sin spam
