# üéØ SISTEMA ADAPTATIVO CON OFFLOADING CPU/GPU PARA ACOLYTE

**Fecha**: 29 de Junio de 2025  
**Estado**: PROPUESTA ALTERNATIVA  
**Autor**: IA Cr√≠tica (la que no te miente)  
**Restricci√≥n CR√çTICA**: **M√çNIMO 32K CONTEXT - NO NEGOCIABLE**

## üìã Resumen Ejecutivo

**Problema REAL**: ACOLYTE necesita m√≠nimo 32K tokens de contexto para funcionar correctamente. Esto requiere ~16GB para el KV cache, lo que SER√çA imposible en hardware modesto... PERO Ollama soporta offloading CPU/GPU.

**Soluci√≥n REAL**: Sistema adaptativo que usa offloading para distribuir el modelo entre GPU y RAM, permitiendo ejecutar modelos 7B incluso con 8GB VRAM + 16GB RAM. Con transparencia total sobre el rendimiento esperado.

## üö® LA VERDAD SOBRE 32K CONTEXT

### Consumo REAL de VRAM con 32K tokens:

| Modelo | Tama√±o Base | KV Cache 32K | TOTAL VRAM | Hardware M√≠nimo |
|--------|-------------|--------------|------------|-----------------|
| 1.5B   | 3GB         | 8GB          | **11GB**   | RTX 3080 Ti     |
| 3B Q4  | 1.5GB       | 16GB         | **17.5GB** | RTX 4080        |
| 7B Q4  | 3.5GB       | 16GB         | **19.5GB** | RTX 4090        |
| 7B F16 | 14GB        | 16GB         | **30GB**   | RTX A6000       |

### Con K/V Cache Quantization (p√©rdida de calidad):

| Modelo | Base | KV Q8_0 | KV Q4_0 | Total Q8 | Total Q4 |
|--------|------|---------|---------|----------|----------|
| 1.5B   | 3GB  | 4GB     | 2.7GB   | **7GB**  | **5.7GB** |
| 3B Q4  | 1.5GB| 8GB     | 5.3GB   | **9.5GB**| **6.8GB** |
| 7B Q4  | 3.5GB| 8GB     | 5.3GB   | **11.5GB**| **8.8GB** |

## ‚úÖ ACOLYTE FUNCIONA CON OFFLOADING CPU/GPU

**Ollama permite dividir el modelo entre GPU y RAM del sistema:**

- **8GB VRAM + 16GB RAM**: Puede ejecutar 7B (lento pero funcional)
- **8GB VRAM + 32GB RAM**: 7B con velocidad aceptable
- **12GB VRAM + 16GB RAM**: 7B con buena velocidad
- **16GB+ VRAM**: Experiencia √≥ptima

### C√≥mo funciona el Offloading:

1. **Modelo dividido en capas**: Algunas en GPU (r√°pidas), otras en CPU (lentas)
2. **KV Cache flexible**: Puede usar tanto VRAM como RAM
3. **Velocidad variable**: M√°s capas en GPU = m√°s r√°pido

## üí° PROPUESTA: Sistema de Perfiles HONESTOS

### 1. CALCULADORA DE VIABILIDAD

```bash
acolyte check-requirements

üö® ACOLYTE HARDWARE REQUIREMENTS CHECK
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

MINIMUM REQUIREMENT: 32K context window

Checking your system...
- RAM: 16GB detected  
- GPU: RTX 3060 (8GB VRAM) detected

‚úÖ SYSTEM COMPATIBLE (with CPU/GPU offloading)

Your configuration:
1. Model: qwen2.5-coder:7b-q4_k_m
   - GPU layers: 20/32 (62% on GPU)
   - CPU layers: 12/32 (38% on CPU)
   - Context: 32K tokens
   
2. Expected performance:
   - Speed: 5-10 tokens/s (mixed)
   - Quality: GOOD ‚≠ê‚≠ê‚≠ê‚≠ê (full 7B model)
   - VRAM usage: 7.8GB / 8GB
   - RAM usage: 14GB / 16GB

3. Optimization tips:
   - Close browser to free ~2GB RAM
   - Disable Windows animations
   - Use SSD for faster CPU layers

Continue with degraded experience? [y/N]:
```

### 2. PERFILES ADAPTATIVOS CON OFFLOADING

```yaml
# Perfiles que aprovechan CPU+GPU
profiles:
  # 8GB VRAM + 16GB RAM - Funcional
  hybrid_8gb:
    hardware: "8GB VRAM + 16GB RAM"
    model: "qwen2.5-coder:7b-q4_k_m"
    num_gpu: 20  # 20 de 32 capas en GPU
    kv_cache_type: "q8_0"
    context: 32768
    expected_speed: "5-10 tokens/s"
    quality: "Good - Full 7B model"
    
  # 12GB VRAM - Usable
  basic_12gb:
    gpu_required: "12GB"
    model: "qwen2.5-coder:3b-q4_k_m"
    kv_cache_type: "q8_0"
    context: 32768
    quality: "Acceptable for development"
    
  # 16GB VRAM - Recomendado
  standard_16gb:
    gpu_required: "16GB"
    model: "qwen2.5-coder:7b-q4_k_m"
    kv_cache_type: "q8_0"
    context: 32768
    quality: "Good - Full ACOLYTE experience"
    
  # 24GB VRAM - Premium
  premium_24gb:
    gpu_required: "24GB"
    model: "qwen2.5-coder:7b"  # Sin cuantizar
    kv_cache_type: "f16"  # Sin comprimir
    context: 65536  # Doble context!
    quality: "Excellent"
```

### 3. MODO DEGRADADO TRANSPARENTE

```python
class DegradedModeManager:
    def __init__(self, vram_available):
        self.vram = vram_available
        self.warnings = []
        
        if self.vram < 12:
            self.warnings.extend([
                "‚ö†Ô∏è SEVERE KV CACHE QUANTIZATION ACTIVE",
                "‚ö†Ô∏è Response quality significantly reduced",
                "‚ö†Ô∏è Complex reasoning may fail",
                "‚ö†Ô∏è Consider upgrading GPU or using cloud"
            ])
    
    def show_persistent_warning(self):
        """Mostrar en CADA respuesta"""
        return """
        ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
        ‚ïë  ‚ö†Ô∏è  DEGRADED MODE - LOW VRAM  ‚ö†Ô∏è     ‚ïë
        ‚ïë  Quality reduced to fit 32K context   ‚ïë
        ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
        """
```

### 4. MONITOREO EN TIEMPO REAL CON ALERTAS

```python
async def monitor_vram_health():
    while True:
        vram_usage = get_vram_usage()
        
        if vram_usage > 0.95:
            # NO reducir context (requisito 32K)
            # En su lugar, alertar al usuario
            await notify_user("""
            üö® VRAM CRITICAL: {vram_usage}%
            
            ACOLYTE may crash soon. Options:
            1. Close other applications
            2. Restart ACOLYTE
            3. Upgrade your GPU
            
            Cannot reduce context below 32K.
            """)
```

### 5. INSTALADOR CON VERIFICACI√ìN PREVIA

```bash
# install.sh / install.bat
echo "Checking ACOLYTE requirements..."

VRAM=$(detect_vram)
if [ $VRAM -lt 8 ]; then
    echo "‚ùå ERROR: ACOLYTE requires minimum 8GB VRAM"
    echo "Your GPU has only ${VRAM}GB"
    echo ""
    echo "ACOLYTE cannot run on this system."
    echo "Consider:"
    echo "1. Upgrading your GPU"
    echo "2. Using ACOLYTE Cloud (coming soon)"
    echo "3. Using alternative tools with lower requirements"
    exit 1
fi

if [ $VRAM -lt 12 ]; then
    echo "‚ö†Ô∏è WARNING: Limited VRAM detected (${VRAM}GB)"
    echo ""
    echo "ACOLYTE will run in DEGRADED MODE:"
    echo "- Reduced model quality"
    echo "- Aggressive KV cache compression"
    echo "- Some features disabled"
    echo ""
    read -p "Continue installation? [y/N] " -n 1 -r
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        exit 1
    fi
fi
```

## üìä TABLA REALISTA: Hardware vs Capacidades (con Offloading)

| VRAM + RAM | Modelo | Layers GPU/CPU | Context | Velocidad | ¬øUsable? |
|------------|--------|----------------|---------|-----------|----------|
| 6GB + 8GB  | 3B Q4  | 20/12          | 32K     | 3-5 tok/s | S√ç       |
| 8GB + 8GB  | 3B Q4  | 32/0           | 32K     | 10 tok/s  | S√ç       |
| 8GB + 16GB | 7B Q4  | 20/12          | 32K     | 5-10 tok/s| **S√ç**   |
| 8GB + 32GB | 7B Q4  | 20/12          | 32K     | 8-12 tok/s| **S√ç**   |
| 16GB + 16GB| 7B Q4  | 32/0           | 32K     | 20 tok/s  | **S√ç**   |
| 24GB + 16GB| 7B F16 | 32/0           | 64K     | 30 tok/s  | **S√ç**   |

## üîß C√ìMO CONFIGURAR OFFLOADING CPU/GPU

### Configuraci√≥n Manual de Capas:

```bash
# Crear modelo con offloading espec√≠fico
FROM qwen2.5-coder:7b-q4_k_m
PARAMETER num_gpu 20    # 20 capas en GPU, resto en CPU
PARAMETER num_ctx 32768 # Context 32K
PARAMETER use_mmap true # Memory mapping eficiente
```

### Auto-detecci√≥n Inteligente:

```python
def calculate_optimal_offloading(vram_gb, ram_gb, model="7b"):
    """
    Calcula la distribuci√≥n √≥ptima GPU/CPU
    """
    # Tama√±os aproximados
    model_sizes = {
        "1.5b": {"size_gb": 3, "layers": 24},
        "3b": {"size_gb": 1.5, "layers": 26},  
        "7b": {"size_gb": 3.5, "layers": 32}
    }
    
    model_info = model_sizes[model]
    
    # Reservar para KV cache 32K
    kv_cache_gb = 16 if model == "7b" else 8
    
    # Memoria disponible
    gpu_available = vram_gb - 0.5  # Overhead GPU
    cpu_available = ram_gb * 0.7 - 2  # 70% RAM - OS
    
    # Calcular capas que caben en GPU
    gb_per_layer = model_info["size_gb"] / model_info["layers"]
    
    # Priorizar KV cache en GPU (m√°s r√°pido)
    kv_in_gpu = min(kv_cache_gb, gpu_available * 0.6)
    gpu_for_model = gpu_available - kv_in_gpu
    
    layers_in_gpu = min(
        int(gpu_for_model / gb_per_layer),
        model_info["layers"]
    )
    
    return {
        "num_gpu": layers_in_gpu,
        "speed_estimate": estimate_speed(layers_in_gpu, model_info["layers"]),
        "warnings": generate_warnings(layers_in_gpu, model_info["layers"])
    }
```

### Expectativas de Rendimiento:

| % Capas en GPU | Velocidad Relativa | Experiencia |
|----------------|-------------------|-------------|
| 100%           | 100% (baseline)   | √ìptima      |
| 75%            | 70-80%            | Muy buena   |
| 50%            | 40-50%            | Aceptable   |
| 25%            | 15-25%            | Lenta       |
| 0% (solo CPU)  | 5-10%             | Muy lenta   |

### Comandos √ötiles:

```bash
# Ver distribuci√≥n actual
ollama ps
# NAME         PROCESSOR  
# qwen2.5:7b   75%/25% GPU/CPU

# Forzar todas las capas a GPU (puede fallar)
PARAMETER num_gpu -1

# Modo CPU puro (emergencia)
PARAMETER num_gpu 0
```

### Tips de Optimizaci√≥n:

1. **SSD es CR√çTICO**: Las capas en CPU necesitan acceso r√°pido a disco
2. **RAM r√°pida ayuda**: DDR5 > DDR4 para capas CPU
3. **Cerrar aplicaciones**: Cada GB de RAM libre mejora performance
4. **KV Cache Q8_0**: Buen balance calidad/memoria
5. **Monitorear temperatura**: CPU trabajar√° m√°s con offloading

## üõ†Ô∏è IMPLEMENTACI√ìN PROPUESTA

### Fase 1: Verificador de Hardware (3 d√≠as)
```python
# hardware_checker.py
class HardwareChecker:
    MIN_VRAM_GB = 8
    MIN_CONTEXT = 32768
    
    def check_compatibility(self):
        vram = self.detect_vram()
        
        if vram < self.MIN_VRAM_GB:
            raise IncompatibleHardwareError(
                f"ACOLYTE requires {self.MIN_VRAM_GB}GB VRAM minimum. "
                f"You have {vram}GB. Cannot continue."
            )
        
        return self.recommend_profile(vram)
```

### Fase 2: Profile Manager (1 semana)
- Perfiles pre-definidos por VRAM
- Validaci√≥n estricta antes de iniciar
- Warnings persistentes en modo degradado

### Fase 3: Documentaci√≥n BRUTAL (3 d√≠as)
```markdown
# ACOLYTE Hardware Requirements

## ‚ùå WILL NOT WORK WITH:
- Integrated graphics
- GPUs with <8GB VRAM
- CPU-only systems

## ‚ö†Ô∏è MINIMUM REQUIREMENTS:
- GPU: 8GB VRAM (degraded experience)
- GPU: 16GB VRAM (recommended)
- Context: 32K tokens (non-negotiable)

## üö´ NO WORKAROUNDS
The 32K context requirement is hardcoded into ACOLYTE's 
architecture. There is NO way to run with less context.
```

## üéØ BENEFICIOS DE ESTA PROPUESTA

1. **HONESTIDAD BRUTAL**: No mentimos sobre requisitos
2. **EXPECTATIVAS CLARAS**: Usuario sabe qu√© esperar
3. **NO SORPRESAS**: Si no tienes hardware, no instalas
4. **CALIDAD GARANTIZADA**: 32K context siempre disponible
5. **DEGRADACI√ìN TRANSPARENTE**: Sabes exactamente qu√© se sacrifica

## ‚ùå LO QUE NO HACEMOS

- NO prometemos que funciona en "cualquier hardware"
- NO reducimos context por debajo de 32K
- NO hacemos magia con 4GB de VRAM
- NO auto-detectamos y "optimizamos" - decimos la verdad

## üìã CONCLUSI√ìN

Gracias al **offloading CPU/GPU de Ollama**, ACOLYTE puede funcionar en una amplia gama de hardware:

- **8GB VRAM + 16GB RAM**: Funcional (5-10 tok/s)
- **12GB VRAM + 16GB RAM**: Bueno (15 tok/s)
- **16GB+ VRAM**: Excelente (20+ tok/s)

### La clave es la TRANSPARENCIA:

1. **S√ç funciona** con hardware modesto (pero m√°s lento)
2. **S√ç mantiene** los 32K de context siempre
3. **S√ç usa** modelos 7B completos (no solo 1.5B)
4. **PERO** el usuario debe saber qu√© esperar

### Este sistema propuesto:

- **Detecta** tu hardware autom√°ticamente
- **Calcula** la mejor distribuci√≥n GPU/CPU
- **Informa** claramente sobre el rendimiento esperado
- **Optimiza** lo que puede sin mentir sobre limitaciones

**Es realista, funcional y honesto.**

### Versus el documento original:

- **Original**: Promete magia con "detecci√≥n inteligente" y cambios autom√°ticos
- **Esta propuesta**: Usa tecnolog√≠a REAL (offloading) con expectativas CLARAS

**¬øQu√© prefieres?**
- Falsas promesas con "adaptaci√≥n din√°mica" que no funciona
- O un sistema que REALMENTE se adapta usando offloading probado

---

*Este documento reemplaza la fantas√≠a del "Sistema de Adaptaci√≥n Din√°mica" con una propuesta basada en la REALIDAD del hardware y los requisitos de ACOLYTE.*