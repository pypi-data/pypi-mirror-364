# üîÑ Sistema de Reindexaci√≥n Autom√°tica de ACOLYTE

## üìã Tabla de Contenidos

- [Introducci√≥n](#introducci√≥n)
- [Arquitectura del Sistema](#arquitectura-del-sistema)
- [Flujo de Trabajo Completo](#flujo-de-trabajo-completo)
- [Implementaci√≥n T√©cnica](#implementaci√≥n-t√©cnica)
- [Configuraci√≥n](#configuraci√≥n)
- [API y M√©todos](#api-y-m√©todos)
- [Eventos y Mensajes](#eventos-y-mensajes)
- [M√©tricas y Monitoreo](#m√©tricas-y-monitoreo)
- [Tests](#tests)
- [Casos de Uso](#casos-de-uso)
- [Limitaciones Conocidas](#limitaciones-conocidas)
- [Mejoras Futuras](#mejoras-futuras)
- [Troubleshooting](#troubleshooting)
- [Decisiones de Dise√±o](#decisiones-de-dise√±o)

## üéØ Introducci√≥n

El Sistema de Reindexaci√≥n Autom√°tica de ACOLYTE mantiene el √≠ndice de b√∫squeda vectorial (Weaviate) sincronizado con los cambios en el c√≥digo del proyecto. Cuando GitService detecta cambios (pull, merge, checkout), autom√°ticamente reindex√° los archivos afectados sin intervenci√≥n del usuario.

### ¬øPor qu√© es necesario?

1. **B√∫squedas precisas**: El RAG necesita informaci√≥n actualizada
2. **Contexto correcto**: ChatService usa el √≠ndice para encontrar c√≥digo relevante
3. **Eficiencia**: Solo reindex√° lo que cambi√≥, no todo el proyecto
4. **Transparencia**: El usuario no necesita acordarse de reindexar manualmente

### Caracter√≠sticas Principales

- ‚úÖ **Autom√°tico**: Se activa con eventos Git (pull, merge, checkout)
- ‚úÖ **Inteligente**: Identifica archivos por patr√≥n
- ‚úÖ **Limitado**: Respeta l√≠mites configurables para evitar sobrecarga
- ‚úÖ **Observable**: M√©tricas detalladas y logging estructurado
- ‚úÖ **Resiliente**: No bloquea indexaci√≥n manual si falla
- ‚úÖ **As√≠ncrono**: No bloquea operaciones Git

## üèóÔ∏è Arquitectura del Sistema

### Componentes Involucrados

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   GitService    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   EventBus   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  ReindexService    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ IndexingService  ‚îÇ
‚îÇ                 ‚îÇ     ‚îÇ              ‚îÇ     ‚îÇ                    ‚îÇ     ‚îÇ                  ‚îÇ
‚îÇ Detecta cambios ‚îÇ     ‚îÇ  Pub/Sub     ‚îÇ     ‚îÇ Maneja eventos de  ‚îÇ     ‚îÇ Reindexa archivos‚îÇ
‚îÇ en archivos     ‚îÇ     ‚îÇ              ‚îÇ     ‚îÇ cache_invalidation ‚îÇ     ‚îÇ                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                                              ‚îÇ
         ‚îÇ                                              ‚ñº
         ‚ñº                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îÇ    Weaviate      ‚îÇ
‚îÇ Publica evento: ‚îÇ                           ‚îÇ                  ‚îÇ
‚îÇCacheInvalidate  ‚îÇ                           ‚îÇ Actualiza chunks ‚îÇ
‚îÇ - pattern       ‚îÇ                           ‚îÇ y embeddings     ‚îÇ
‚îÇ - reason        ‚îÇ                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ - source        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flujo de Datos

1. **GitService** detecta cambios (despu√©s de pull, merge, etc.)
2. Analiza qu√© archivos cambiaron
3. Publica **CacheInvalidateEvent** con patr√≥n de archivos
4. **EventBus** distribuye el evento a suscriptores
5. **ReindexService** recibe el evento (filtrado por `target_service="indexing"`)
6. Busca archivos que coinciden con el patr√≥n
7. Llama a **IndexingService** para reindexar los archivos encontrados
8. **IndexingService** actualiza **Weaviate** con nuevos chunks y embeddings

## üîÑ Flujo de Trabajo Completo

### 1. Detecci√≥n de Cambios (GitService)

```python
# En git_service.py - despu√©s de operaciones Git
async def _handle_post_pull(self):
    # Detecta archivos modificados
    changed_files = self._get_changed_files()

    # Para cada archivo cambiado
    for file in changed_files:
        # Crea patr√≥n para el archivo
        pattern = f"*{file.name}*"

        # Publica evento
        event = CacheInvalidateEvent(
            source="git_service",
            key_pattern=pattern,
            reason=f"File updated after pull: {file}",
            target_service="indexing"
        )
        await event_bus.publish(event)
```

### 2. Suscripci√≥n al EventBus (IndexingService)

```python
# En reindex_service.__init__()
self._unsubscribe = event_bus.subscribe(
    EventType.CACHE_INVALIDATE,
    self._handle_cache_invalidation,
    filter=lambda e: isinstance(e, CacheInvalidateEvent)
                     and e.target_service == "indexing"
)
```

### 3. Manejo del Evento

```python
async def _handle_cache_invalidation(self, event: Event):
    # Verificar si IndexingService ya est√° indexando
    if self.indexing_service._is_indexing:
        logger.warning("Skipping - already indexing")
        self.metrics.increment("reindexing.skipped_busy")
        return

    # Extraer patr√≥n
    file_hint = event.key_pattern.strip("*")

    # Buscar archivos
    matching_files = await self._find_files_matching_pattern(file_hint)

    # Aplicar l√≠mite
    if len(matching_files) > self.config.get("indexing.max_reindex_files", 50):
        matching_files = matching_files[:50]

    # Reindexar
    if matching_files:
        task_id = f"reinx_{int(time.time())}_{generate_id()[:8]}"

        result = await self.indexing_service.index_files(
            files=matching_files,
            trigger="cache_invalidation",
            task_id=task_id
        )
```

### 4. B√∫squeda de Archivos

```python
async def _find_files_matching_pattern(self, pattern: str) -> List[str]:
    project_root = Path(self.config.get("project.path", ".")).resolve()
    matching_files = []

    # Optimizaci√≥n: b√∫squeda espec√≠fica si parece nombre completo
    if "." in pattern and not pattern.startswith("."):
        # Buscar coincidencias exactas primero
        for file_path in project_root.rglob(f"*{pattern}"):
            if self._is_valid_file(file_path):
                matching_files.append(str(file_path))
    else:
        # B√∫squeda parcial m√°s amplia
        for file_path in project_root.rglob("*"):
            if pattern.lower() in file_path.name.lower():
                if self._is_valid_file(file_path):
                    matching_files.append(str(file_path))

    return matching_files

def _is_valid_file(self, path: Path) -> bool:
    return (path.is_file() and
            self.indexing_service.is_supported_file(path) and
            not self.indexing_service.should_ignore(str(path)))
```

## üîß Implementaci√≥n T√©cnica

### Estructura del CacheInvalidateEvent

```python
@dataclass
class CacheInvalidateEvent(Event):
    """Evento para invalidar cache y triggear reindexaci√≥n."""
    source: str           # Ej: "git_service"
    key_pattern: str      # Ej: "*auth.py*"
    reason: str           # Ej: "Files changed after pull"
    target_service: str   # Debe ser "indexing" para IndexingService

    event_type: EventType = EventType.CACHE_INVALIDATE
```

### Generaci√≥n de Task ID

```python
# Formato: reinx_<timestamp>_<short_id>
task_id = f"reinx_{int(time.time())}_{generate_id()[:8]}"

# Ejemplo: "reinx_1703123456_a1b2c3d4"
# - reinx: Prefijo para identificar reindexaci√≥n
# - timestamp: Para ordenar cronol√≥gicamente
# - short_id: Para unicidad (8 chars de hex32)
```

### Trigger Type

```python
# La reindexaci√≥n usa un trigger especial
trigger = "cache_invalidation"

# Otros triggers soportados:
# - "manual": Usuario solicita indexaci√≥n
# - "commit": Post-commit hook
# - "pull": Post-pull (ya no usado directamente)
# - "checkout": Branch change
# - "fetch": Preparation
```

## ‚öôÔ∏è Configuraci√≥n

### En `.acolyte`

```yaml
indexing:
  # L√≠mites de reindexaci√≥n
  max_reindex_files: 50 # M√°ximo de archivos por evento

  # Configuraci√≥n general que tambi√©n aplica
  batch_size: 20 # Archivos por batch
  max_file_size_mb: 10 # Tama√±o m√°ximo de archivo
  concurrent_workers: 4 # Workers paralelos

  # Patrones ignorados (se respetan en reindexaci√≥n)
ignore:
  patterns:
    - "*.pyc"
    - "__pycache__/"
    - ".git/"
    - "*.log"
    - "node_modules/"
    - ".venv/"
    - "*.egg-info/"
```

### Configuraci√≥n No Implementada (Futura)

```yaml
# Estas configuraciones est√°n documentadas pero NO implementadas a√∫n
indexing:
  # Reindexaci√≥n avanzada (FUTURO)
  reindex_queue_size: 100 # Cola de eventos pendientes
  reindex_cooldown_seconds: 5 # Evitar duplicados
  reindex_batch_size: 5 # Procesar en mini-batches
  pattern_cache_ttl_seconds: 60 # Cache de b√∫squedas
  verify_timestamps: true # Verificar si archivo cambi√≥
```

## üì° API y M√©todos

### M√©todos P√∫blicos

No hay m√©todos p√∫blicos espec√≠ficos para reindexaci√≥n. El sistema es completamente autom√°tico.

### M√©todos Internos

#### `_handle_cache_invalidation(event: Event)`

Maneja eventos de invalidaci√≥n de cache.

**Par√°metros**:

- `event`: CacheInvalidateEvent con patr√≥n y raz√≥n

**Comportamiento**:

1. Verifica si ya est√° indexando
2. Extrae patr√≥n del evento
3. Busca archivos coincidentes
4. Aplica l√≠mite de archivos
5. Genera task_id √∫nico
6. Llama a `index_files()` con trigger especial

**M√©tricas**:

- `indexing.cache_invalidations_received`
- `indexing.cache_invalidations_skipped`
- `indexing.reindex_triggered`
- `indexing.reindex_files_count`
- `indexing.reindex_success/failed`
- `indexing.cache_invalidation_errors`

#### `_find_files_matching_pattern(pattern: str) -> List[str]`

Busca archivos en el proyecto que coinciden con el patr√≥n.

**Par√°metros**:

- `pattern`: Patr√≥n de b√∫squeda (ej: "auth.py", "auth", "user\_")

**Comportamiento**:

1. Si contiene "." ‚Üí b√∫squeda exacta de nombre
2. Si no ‚Üí b√∫squeda parcial case-insensitive
3. Respeta archivos soportados
4. Respeta patrones ignorados
5. Devuelve paths absolutos

**Optimizaciones**:

- B√∫squeda espec√≠fica para nombres completos
- Early exit al alcanzar l√≠mite
- Deduplicaci√≥n de resultados

## üìä Eventos y Mensajes

### Eventos Publicados

IndexingService NO publica eventos de reindexaci√≥n espec√≠ficos, pero s√≠ publica `ProgressEvent` durante el proceso:

```python
ProgressEvent(
    source="indexing_service",
    operation="indexing_files",
    current=10,
    total=50,
    message="Processing: src/auth.py",
    task_id="reinx_1703123456_a1b2c3d4",
    files_skipped=5,
    chunks_created=100,
    embeddings_generated=100,
    errors=0
)
```

### Eventos Consumidos

```python
CacheInvalidateEvent(
    source="git_service",
    key_pattern="*auth.py*",
    reason="Files changed after pull",
    target_service="indexing"  # CR√çTICO: debe ser "indexing"
)
```

### Logs Importantes

```python
# Inicio de reindexaci√≥n
logger.info(
    "Re-indexing files after cache invalidation",
    pattern=file_hint,
    files_count=len(matching_files),
    task_id=task_id,
    reason=event.reason
)

# Finalizaci√≥n exitosa
logger.info(
    "Re-indexing completed successfully",
    task_id=task_id,
    files_processed=result["files_processed"],
    chunks_created=result["chunks_created"],
    duration_seconds=result["duration_seconds"]
)

# Warnings importantes
logger.warning(
    "Too many files match pattern, limiting re-indexing",
    pattern=file_hint,
    total_matches=len(matching_files),
    limit=max_reindex_files
)
```

## üìà M√©tricas y Monitoreo

### M√©tricas Implementadas

```python
# Contadores
indexing.cache_invalidations_received    # Total eventos recibidos
indexing.cache_invalidations_skipped     # Eventos saltados (ya indexando)
indexing.reindex_triggered               # Reindexaciones iniciadas
indexing.reindex_success                 # Reindexaciones exitosas
indexing.reindex_failed                  # Reindexaciones fallidas
indexing.cache_invalidation_errors       # Errores en el handler

# Gauges
indexing.reindex_files_count             # Archivos en √∫ltima reindexaci√≥n

# Timers (heredados de index_files)
indexing.index_files_total_ms            # Tiempo total de reindexaci√≥n
```

### Dashboard Conceptual

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Reindexaci√≥n Autom√°tica            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Eventos Recibidos:        1,234            ‚îÇ
‚îÇ Reindexaciones:             456            ‚îÇ
‚îÇ Archivos Promedio:           12            ‚îÇ
‚îÇ Tasa de √âxito:             98.5%           ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ √öltima Reindexaci√≥n:                        ‚îÇ
‚îÇ   Trigger: cache_invalidation               ‚îÇ
‚îÇ   Patr√≥n: *auth.py*                         ‚îÇ
‚îÇ   Archivos: 3                               ‚îÇ
‚îÇ   Duraci√≥n: 2.5s                            ‚îÇ
‚îÇ   Task ID: reinx_1703123456_a1b2c3d4       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üß™ Tests

### Tests Unitarios Implementados

En `tests/services/test_indexing_service_reindexing.py`:

1. **test_handle_cache_invalidation_success**

   - Verifica reindexaci√≥n exitosa
   - Valida archivos encontrados
   - Confirma task_id y trigger

2. **test_handle_cache_invalidation_already_indexing**

   - Verifica skip cuando ya est√° indexando
   - Confirma m√©trica de skip

3. **test_handle_cache_invalidation_no_files_found**

   - Maneja caso sin archivos coincidentes
   - No debe llamar index_files

4. **test_handle_cache_invalidation_max_files_limit**

   - Respeta l√≠mite de archivos
   - Trunca lista si excede l√≠mite

5. **test_handle_cache_invalidation_wildcard_pattern**

   - Ignora patrones "\*" (todo)
   - Evita reindexaci√≥n masiva

6. **test_find_files_matching_pattern_exact_filename**

   - B√∫squeda exacta de nombres
   - "auth.py" encuentra solo auth.py

7. **test_find_files_matching_pattern_partial**

   - B√∫squeda parcial
   - "auth" encuentra auth.py, user_auth.py, test_auth.py

8. **test_find_files_matching_pattern_case_insensitive**

   - Insensible a may√∫sculas
   - "auth" encuentra AUTH_CONFIG.py

9. **test_find_files_matching_pattern_respects_filters**

   - Respeta archivos ignorados
   - Respeta extensiones soportadas

10. **test_eventbus_integration**

    - Integraci√≥n con EventBus
    - Filtrado correcto por target_service

11. **test_handle_cache_invalidation_error_handling**

    - Manejo de errores sin crash
    - M√©trica de errores

12. **test_task_id_generation_uniqueness**

    - IDs √∫nicos para cada reindexaci√≥n
    - Formato correcto

13. **test_metrics_tracking**
    - Todas las m√©tricas se registran
    - Valores correctos

### Ejecutar Tests

```bash
# Todos los tests de reindexaci√≥n
poetry run pytest tests/services/test_indexing_service_reindexing.py -v

# Con coverage
poetry run pytest tests/services/test_indexing_service_reindexing.py --cov=acolyte.services.indexing_service --cov-report=html

# Test espec√≠fico
poetry run pytest tests/services/test_indexing_service_reindexing.py::TestIndexingServiceReindexing::test_handle_cache_invalidation_success -v
```

## üéØ Casos de Uso

### 1. Pull desde Repository Remoto

```
Usuario: git pull origin main
Git: Actualiza 5 archivos

GitService:
1. Detecta: auth.py, user.py, models.py modificados
2. Publica: CacheInvalidateEvent para cada archivo
3. Reason: "File updated after pull: auth.py"

IndexingService:
1. Recibe 3 eventos
2. Encuentra y reindex√° los 3 archivos
3. Actualiza Weaviate con nuevos chunks

ChatService:
- Pr√≥xima b√∫squeda encuentra c√≥digo actualizado
```

### 2. Merge de Feature Branch

```
Usuario: git merge feature/new-auth
Git: Merge con 10 archivos cambiados

GitService:
1. Detecta conflictos resueltos y archivos mergeados
2. Agrupa por directorio si son muchos
3. Publica eventos con patrones

IndexingService:
1. Procesa cada patr√≥n
2. L√≠mite de 50 archivos previene sobrecarga
3. Reindex√° en batches de 20
```

### 3. Checkout a Otra Branch

```
Usuario: git checkout develop
Git: Cambia a branch con diferente c√≥digo

GitService:
1. Detecta archivos diferentes entre branches
2. Publica eventos para archivos modificados

IndexingService:
1. Reindex√° archivos que cambiaron
2. Mantiene √≠ndice sincronizado con branch actual
```

### 4. Revert de Commits

```
Usuario: git revert HEAD~3
Git: Revierte √∫ltimos 3 commits

GitService:
1. Detecta archivos afectados por revert
2. Publica eventos para reindexaci√≥n

IndexingService:
1. Actualiza √≠ndice con versiones revertidas
2. ChatService usa c√≥digo correcto
```

## ‚ö†Ô∏è Limitaciones Conocidas

### 1. No hay Queue de Eventos

**Problema**: Si est√° indexando, eventos se pierden
**Impacto**: Archivos no se reindecan hasta pr√≥ximo cambio
**Workaround**: Usuario puede indexar manualmente

### 2. No Verifica Timestamps

**Problema**: Reindex√° aunque archivo no cambi√≥ realmente
**Impacto**: Trabajo innecesario, pero no da√±a
**Futuro**: Comparar file.mtime con indexed_at

### 3. B√∫squeda en Todo el Proyecto

**Problema**: Puede ser lento en proyectos grandes
**Impacto**: Delay en reindexaci√≥n
**Mitigaci√≥n**: L√≠mite de archivos previene worst case

### 4. Sin Deduplicaci√≥n de Eventos

**Problema**: M√∫ltiples eventos r√°pidos para mismo archivo
**Impacto**: Reindexaci√≥n duplicada
**Futuro**: Cooldown por patr√≥n

### 5. Patr√≥n Simple de Matching

**Problema**: No soporta glob avanzado o regex
**Impacto**: Matching menos preciso
**Actual**: Solo "\*" wildcards y b√∫squeda parcial

## üöÄ Mejoras Futuras

### 1. Queue de Reindexaci√≥n Pendiente (Alta Prioridad)

**Problema**: Si ya est√° indexando, el evento se pierde.

```python
class IndexingService:
    def __init__(self):
        # ...
        self._reindex_queue: asyncio.Queue[CacheInvalidateEvent] = asyncio.Queue()
        self._queue_processor_task = None

    async def _handle_cache_invalidation(self, event: Event):
        if self._is_indexing:
            # En lugar de solo loguear, agregar a la cola
            await self._reindex_queue.put(event)
            logger.info("Added to reindex queue", pattern=event.key_pattern)
            return

        # Procesar normalmente...

    async def _process_reindex_queue(self):
        """Process pending reindex requests after current indexing."""
        while not self._reindex_queue.empty():
            try:
                event = await self._reindex_queue.get()
                await self._handle_cache_invalidation(event)
            except Exception as e:
                logger.error("Failed to process queued reindex", error=str(e))
```

### 2. Verificaci√≥n de Timestamps (Alta Prioridad)

**Problema**: Re-indexa archivos que no han cambiado.

**Estado actual**: Implementado m√©todo `_filter_files_needing_reindex()` en ReindexService con TODO para completar la comparaci√≥n de timestamps con Weaviate.

```python
async def _should_reindex_file(self, file_path: str) -> bool:
    """Check if file needs reindexing based on timestamps."""
    try:
        # Get file modification time
        file_stat = Path(file_path).stat()
        file_modified = datetime.fromtimestamp(file_stat.st_mtime, tz=timezone.utc)

        # Query Weaviate for last indexed time
        where_filter = {
            "path": ["file_path"],
            "operator": "Equal",
            "valueText": file_path
        }

        result = await self.weaviate.query.get("CodeChunk", ["indexed_at"])
            .with_where(where_filter)
            .with_limit(1)
            .do()

        if result and result["data"]["Get"]["CodeChunk"]:
            indexed_at = parse_iso_datetime(result["data"]["Get"]["CodeChunk"][0]["indexed_at"])

            # Only reindex if file is newer
            return file_modified > indexed_at

        # Not indexed yet
        return True

    except Exception:
        # On error, reindex to be safe
        return True
```

### 3. Optimizaci√≥n de B√∫squeda (Media Prioridad)

**Problema**: B√∫squeda recursiva en todo el proyecto puede ser lenta.

```python
async def _find_files_matching_pattern(self, pattern: str) -> List[str]:
    """Optimized file search with caching and limits."""
    cache_key = f"file_pattern:{pattern}"

    # Check cache first
    if hasattr(self, '_pattern_cache'):
        cached = self._pattern_cache.get(cache_key)
        if cached and (time.time() - cached['time']) < 60:  # 1 minute cache
            return cached['files']

    # Use pathlib's match for efficiency
    matching_files = []
    max_depth = self.config.get("indexing.max_search_depth", 10)

    # If pattern looks like path, search more specifically
    if "/" in pattern or "\\" in pattern:
        # Direct path search
        base_path = Path(pattern).parent
        pattern_glob = Path(pattern).name
    else:
        base_path = self.project_root
        pattern_glob = f"**/*{pattern}*" if "." not in pattern else f"**/{pattern}"

    # Limited depth search
    for file_path in base_path.rglob(pattern_glob):
        if self._is_supported_file(file_path) and not self._should_ignore(str(file_path)):
            matching_files.append(str(file_path))

            # Early exit if we have enough
            if len(matching_files) >= self.config.get("indexing.max_reindex_files", 50):
                break

    # Cache results
    if not hasattr(self, '_pattern_cache'):
        self._pattern_cache = {}
    self._pattern_cache[cache_key] = {'files': matching_files, 'time': time.time()}

    return matching_files
```

### 4. Logging Mejorado (Media Prioridad)

**Problema**: No hay suficiente detalle sobre qu√© se reindex√≥ y por qu√©.

```python
async def _handle_cache_invalidation(self, event: Event):
    """Enhanced logging version."""
    start_time = time.time()

    logger.info(
        "Cache invalidation started",
        source=event.source,
        pattern=event.key_pattern,
        reason=event.reason,
        already_indexing=self._is_indexing
    )

    # ... find files ...

    logger.info(
        "Files found for reindexing",
        pattern=event.key_pattern,
        total_found=len(all_files),
        after_filtering=len(files_to_index),
        sample_files=files_to_index[:5]  # Show first 5
    )

    # ... reindex ...

    logger.info(
        "Reindexing completed",
        pattern=event.key_pattern,
        duration_seconds=time.time() - start_time,
        files_processed=result["files_processed"],
        chunks_created=result["chunks_created"],
        success_rate=f"{(1 - len(result.get('errors', [])) / max(result['files_processed'], 1)) * 100:.1f}%"
    )
```

### 5. Batch Processing Inteligente (Baja Prioridad)

**Problema**: Re-indexar muchos archivos puede bloquear indexaci√≥n normal.

```python
async def _handle_cache_invalidation(self, event: Event):
    """Process in smaller batches to allow interleaving."""
    # ... find files ...

    if len(matching_files) > 10:
        # Process in batches
        batch_size = 5
        for i in range(0, len(matching_files), batch_size):
            batch = matching_files[i:i + batch_size]

            # Allow other operations between batches
            await asyncio.sleep(0.1)

            await self.index_files(
                files=batch,
                trigger="cache_invalidation",
                task_id=f"{task_id}_batch_{i//batch_size}"
            )
    else:
        # Small number, process all at once
        await self.index_files(files=matching_files, trigger="cache_invalidation", task_id=task_id)
```

### 6. Deduplicaci√≥n de Eventos (Media Prioridad)

**Problema**: M√∫ltiples eventos r√°pidos para el mismo patr√≥n.

```python
class IndexingService:
    def __init__(self):
        # ...
        self._recent_patterns: Dict[str, float] = {}  # pattern -> timestamp
        self._pattern_lock = asyncio.Lock()

    async def _handle_cache_invalidation(self, event: Event):
        async with self._pattern_lock:
            # Check if we recently processed this pattern
            last_processed = self._recent_patterns.get(event.key_pattern, 0)
            if time.time() - last_processed < 5:  # 5 second cooldown
                logger.debug(
                    "Skipping duplicate pattern",
                    pattern=event.key_pattern,
                    seconds_since_last=time.time() - last_processed
                )
                return

            self._recent_patterns[event.key_pattern] = time.time()

        # Process normally...
```

### üìä M√©tricas Adicionales Sugeridas

```python
# Nuevas m√©tricas para mejor observabilidad
self.metrics.record("indexing.reindex_search_time_ms", search_duration * 1000)
self.metrics.gauge("indexing.reindex_queue_size", self._reindex_queue.qsize())
self.metrics.increment("indexing.reindex_cache_hits")
self.metrics.increment("indexing.reindex_files_skipped_uptodate")
self.metrics.histogram("indexing.reindex_batch_size", len(files))
```

### üß™ Tests Adicionales Sugeridos

1. **Test de concurrencia**: M√∫ltiples eventos simult√°neos
2. **Test de performance**: Con miles de archivos
3. **Test de resiliencia**: Weaviate no disponible durante reindexaci√≥n
4. **Test de deduplicaci√≥n**: Eventos duplicados r√°pidos
5. **Test de integraci√≥n E2E**: GitService ‚Üí IndexingService completo

### üîí Consideraciones de Seguridad

1. **Path traversal**: Validar que los archivos encontrados est√°n dentro del proyecto
2. **Resource exhaustion**: L√≠mites estrictos en b√∫squeda recursiva
3. **Event flooding**: Rate limiting de eventos por patr√≥n

### üìù Configuraci√≥n Sugerida

```yaml
# En .acolyte
indexing:
  # Reindexaci√≥n
  max_reindex_files: 50
  max_search_depth: 10
  reindex_batch_size: 5
  reindex_cooldown_seconds: 5
  pattern_cache_ttl_seconds: 60

  # Queue
  max_queue_size: 100
  queue_process_delay_seconds: 1
```

### üéØ Prioridad de Implementaci√≥n

1. **Alta**: Queue de reindexaci√≥n (evita p√©rdida de eventos)
2. **Alta**: Verificaci√≥n de timestamps (evita trabajo innecesario)
3. **Media**: Logging mejorado (debugging)
4. **Media**: Deduplicaci√≥n de eventos (eficiencia)
5. **Baja**: Optimizaci√≥n de b√∫squeda (performance)
6. **Baja**: Batch processing (UX)

## üîß Troubleshooting

### Problema: No se est√°n reindexando archivos

**Verificar**:

1. GitService est√° publicando eventos:

   ```python
   # Agregar log temporal en git_service.py
   logger.info("Publishing cache invalidation", pattern=pattern)
   ```

2. IndexingService est√° suscrito:

   ```python
   # Verificar en __init__
   assert self._unsubscribe is not None
   ```

3. Filtro de eventos es correcto:
   ```python
   # El evento DEBE tener target_service="indexing"
   ```

**Soluci√≥n**:

- Verificar logs en nivel DEBUG
- Confirmar que Weaviate est√° disponible
- Indexar manualmente como workaround

### Problema: Se reindexa demasiado

**S√≠ntomas**:

- Mismos archivos se reindecan repetidamente
- Alto uso de CPU/memoria

**Verificar**:

```yaml
# En .acolyte
indexing:
  max_reindex_files: 50 # Reducir si es necesario
```

**Soluci√≥n**:

- Reducir `max_reindex_files`
- Implementar deduplicaci√≥n (mejora futura)
- Revisar patrones de GitService

### Problema: Eventos perdidos

**S√≠ntomas**:

- Archivo cambi√≥ pero no se reindex√≥
- Logs muestran "already indexing"

**Verificar**:

```bash
# Buscar en logs
grep "Skipping - already indexing" acolyte.log
```

**Soluci√≥n temporal**:

- Esperar que termine indexaci√≥n actual
- Indexar manualmente archivo espec√≠fico
- Implementar queue (mejora futura)

### Problema: B√∫squeda lenta de archivos

**S√≠ntomas**:

- Reindexaci√≥n tarda mucho en empezar
- CPU alta durante b√∫squeda

**Verificar**:

- Tama√±o del proyecto
- Patrones muy gen√©ricos ("_._")

**Soluci√≥n**:

- Patrones m√°s espec√≠ficos en GitService
- Excluir directorios grandes en .acolyteignore
- Implementar cache de b√∫squeda (mejora futura)

## üìê Decisiones de Dise√±o

### 1. ¬øPor qu√© no reindexar todo siempre?

**Decisi√≥n**: Solo reindexar archivos espec√≠ficos
**Raz√≥n**:

- Eficiencia: Proyecto grande = mucho tiempo
- UX: Usuario no espera delays despu√©s de git pull
- Recursos: Menos CPU/memoria/embeddings API calls

### 2. ¬øPor qu√© usar EventBus?

**Decisi√≥n**: Comunicaci√≥n as√≠ncrona v√≠a eventos
**Raz√≥n**:

- Desacoplamiento: GitService no conoce IndexingService
- Extensibilidad: Otros servicios pueden escuchar
- As√≠ncrono: No bloquea operaciones Git

### 3. ¬øPor qu√© l√≠mite de archivos?

**Decisi√≥n**: max_reindex_files = 50
**Raz√≥n**:

- Prevenir DoS accidental
- Merge grande no bloquea sistema
- Balance entre completitud y performance

### 4. ¬øPor qu√© no verificar timestamps?

**Decisi√≥n**: Reindexar sin verificar si cambi√≥
**Raz√≥n**:

- Simplicidad inicial
- Git dice que cambi√≥ = probablemente cambi√≥
- Verificaci√≥n requiere query a Weaviate (latencia)
- Futuro: Implementar cuando sea problema real

### 5. ¬øPor qu√© task_id con timestamp?

**Decisi√≥n**: `reinx_{timestamp}_{id}`
**Raz√≥n**:

- Debugging: F√°cil ver cu√°ndo ocurri√≥
- Ordenable: Sort cronol√≥gico natural
- √önico: Timestamp + ID previene colisiones
- Identificable: Prefijo "reinx" claro

### 6. ¬øPor qu√© no usar git hooks directamente?

**Decisi√≥n**: GitService con GitPython
**Raz√≥n**:

- Portabilidad: Funciona en Windows/Mac/Linux
- Control: Manejo de errores en Python
- Integraci√≥n: Mismo proceso, no scripts externos
- Testing: M√°s f√°cil mockear que hooks reales

## üìö Referencias

### Archivos Clave

- `services/indexing_service.py`: Implementaci√≥n principal
- `services/git_service.py`: Detecci√≥n de cambios
- `core/events.py`: Definici√≥n de eventos
- `tests/services/test_indexing_service_reindexing.py`: Tests completos

### Documentaci√≥n Relacionada

- Esta secci√≥n de "Mejoras Futuras": Contiene todas las mejoras sugeridas
- `services/README.md`: Contexto del m√≥dulo services
- `PROMPT.md`: Sistema de eventos y arquitectura general

### Configuraci√≥n

- `.acolyte`: Configuraci√≥n del proyecto
- `.acolyteignore`: Patrones a ignorar

---

_Documento creado para ACOLYTE - Sistema de reindexaci√≥n autom√°tica v1.0_
