# üîß Centralizaci√≥n de Utilidades Comunes

## üìã ¬øQu√© es?

La centralizaci√≥n de utilidades se refiere a extraer patrones de c√≥digo que se repiten en m√∫ltiples lugares del proyecto y consolidarlos en funciones/clases reutilizables. El TODO espec√≠ficamente menciona 2 patrones:

### 1. **Progress Reporting**
- Notificar progreso de operaciones largas
- Formato consistente de eventos de progreso
- Publicaci√≥n a EventBus

### 2. **Token Estimation Utilities**
- Estimar tokens sin llamar a APIs externas
- C√°lculos aproximados para planificaci√≥n
- Diferentes ratios por tipo de contenido

## üéØ ¬øPara qu√© vale?

### Beneficios de centralizaci√≥n:

1. **Elimina duplicaci√≥n de c√≥digo**
   - Menos l√≠neas totales = menos bugs potenciales
   - Un solo lugar para corregir errores
   - Cambios consistentes en todo el proyecto

2. **Mejora mantenibilidad**
   - L√≥gica compleja en un solo lugar
   - Tests unitarios centralizados
   - Documentaci√≥n √∫nica

3. **Consistencia garantizada**
   - Mismo comportamiento en todos los usos
   - Mismos par√°metros y configuraci√≥n
   - Misma gesti√≥n de errores

4. **Facilita evoluci√≥n**
   - Mejorar algoritmo beneficia a todos
   - A√±adir features en un solo lugar
   - Optimizaci√≥n centralizada

### Problemas actuales por la duplicaci√≥n:

- **Progress events** con diferentes formatos
- **Token counting** con diferentes aproximaciones

## üí° ¬øPor qu√© es √≥ptimo?

### 1. **Principio DRY (Don't Repeat Yourself)**
- Una sola implementaci√≥n en lugar de c√≥digo duplicado
- Cambios en un solo lugar benefician a todos los usos

### 2. **Reduce superficie de bugs**
- Bug en utilidad = corregir en m√∫ltiples lugares actualmente
- Con centralizaci√≥n = corregir en 1 lugar
- Tests m√°s completos posibles

### 3. **Mejora la legibilidad**
- Reemplaza bloques de 20+ l√≠neas con una sola llamada clara
- C√≥digo m√°s expresivo y f√°cil de entender

### 4. **Optimizaci√≥n de performance**
- Cach√© compartido para estimaciones de tokens
- Reutilizaci√≥n de c√°lculos frecuentes
- Evita recalcular m√©tricas id√©nticas

## üèóÔ∏è ¬øC√≥mo deber√≠a ser?

### Estructura propuesta:

```
src/acolyte/core/utils/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ progress.py       # Progress reporting helpers
‚îî‚îÄ‚îÄ tokens.py         # Token estimation utilities
```

### 1. **Progress Reporting** (`progress.py`)

```python
from typing import Optional, Dict, Any
from dataclasses import dataclass, field
from datetime import datetime

from acolyte.core.events import event_bus, ProgressEvent
from acolyte.core.utils.datetime_utils import utc_now

@dataclass
class ProgressTracker:
    """Helper for consistent progress reporting."""
    
    operation: str
    total: int
    source: str = "unknown"
    task_id: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    _current: int = 0
    _start_time: datetime = field(default_factory=utc_now)
    
    async def update(self, current: int, message: str = ""):
        """Update progress and emit event."""
        self._current = current
        
        # Calculate percentage
        percentage = (current / max(self.total, 1)) * 100
        
        # Calculate ETA if possible
        elapsed = (utc_now() - self._start_time).total_seconds()
        if current > 0 and elapsed > 0:
            rate = current / elapsed
            remaining = self.total - current
            eta_seconds = remaining / rate if rate > 0 else None
        else:
            eta_seconds = None
        
        # Create progress event
        event = ProgressEvent(
            source=self.source,
            operation=self.operation,
            current=current,
            total=self.total,
            message=message or f"Processing: {percentage:.1f}%",
            task_id=self.task_id,
            percentage=percentage,
            eta_seconds=eta_seconds,
            **self.metadata
        )
        
        # Publish event
        await event_bus.publish(event)
    
    async def increment(self, message: str = ""):
        """Increment current by 1 and emit event."""
        await self.update(self._current + 1, message)
    
    async def complete(self, message: str = "Complete"):
        """Mark as complete."""
        await self.update(self.total, message)
```

### 2. **Token Estimation** (`tokens.py`)

```python
import re
from typing import Dict, Optional
from functools import lru_cache

class TokenEstimator:
    """
    Estimate token counts without external API calls.
    
    Based on empirical observations:
    - Average English word ‚âà 1.3 tokens
    - Code tends to have more tokens per "word"
    - Different languages have different ratios
    """
    
    # Empirical ratios (tokens per word)
    LANGUAGE_RATIOS: Dict[str, float] = {
        "english": 1.3,
        "python": 1.5,      # snake_case, special chars
        "javascript": 1.4,  # camelCase
        "java": 1.6,        # verboseLongNames
        "cpp": 1.7,         # namespace::class::method
        "markdown": 1.2,    # mostly natural language
        "json": 2.0,        # lots of delimiters
        "xml": 2.5,         # tags everywhere
    }
    
    # Simple word splitter (good enough for estimation)
    WORD_PATTERN = re.compile(r'\b\w+\b|[^\w\s]')
    
    @classmethod
    @lru_cache(maxsize=1000)
    def estimate_tokens(
        cls, 
        text: str, 
        language: str = "english",
        multiplier: float = 1.0
    ) -> int:
        """
        Estimate token count for text.
        
        Args:
            text: Text to estimate
            language: Language/format of text
            multiplier: Safety multiplier (default 1.0)
            
        Returns:
            Estimated token count
        """
        # Find all words and symbols
        words = cls.WORD_PATTERN.findall(text)
        word_count = len(words)
        
        # Get ratio for language
        ratio = cls.LANGUAGE_RATIOS.get(language, 1.3)
        
        # Calculate estimate
        estimate = int(word_count * ratio * multiplier)
        
        # Minimum of 1 token per 4 characters (safety)
        char_estimate = len(text) // 4
        
        return max(estimate, char_estimate)
    
    @classmethod
    def estimate_messages_tokens(
        cls,
        messages: list[Dict[str, str]],
        overhead_per_message: int = 4
    ) -> int:
        """
        Estimate tokens for a list of messages.
        
        Each message has overhead for role markers.
        """
        total = 0
        
        for message in messages:
            content = message.get("content", "")
            role = message.get("role", "")
            
            # Estimate content tokens
            content_tokens = cls.estimate_tokens(content)
            
            # Add overhead for message structure
            total += content_tokens + overhead_per_message
            
            # Add role tokens
            total += len(role.split())
        
        return total
```

### Integraci√≥n con el c√≥digo existente:

```python
# Progress reporting
from acolyte.core.utils.progress import ProgressTracker

tracker = ProgressTracker("indexing", total=100)
await tracker.update(50, "Halfway done")

# Token estimation
from acolyte.core.utils.tokens import TokenEstimator

tokens = TokenEstimator.estimate_tokens(text, language="python")
```

### Plan de migraci√≥n:

1. **Fase 1**: Crear m√≥dulos de utilidades con tests
2. **Fase 2**: Identificar todos los lugares con c√≥digo duplicado
3. **Fase 3**: Migrar gradualmente, servicio por servicio
4. **Fase 4**: Eliminar c√≥digo duplicado
5. **Fase 5**: Documentar patrones de uso

### Beneficios medibles:

- **Reducci√≥n de c√≥digo**: ~200-400 l√≠neas menos
- **Consistencia**: 100% de eventos de progreso con mismo formato
- **Mantenibilidad**: 1 lugar para actualizar estimaciones de tokens
- **Tiempo de desarrollo**: 30% menos para nuevos servicios

## üöÄ Prioridad y Esfuerzo

**Prioridad**: Media
- Mejora consistencia del c√≥digo
- Facilita mantenimiento futuro
- Reduce duplicaci√≥n

**Esfuerzo estimado**:
- Crear utilidades: 0.5 d√≠as
- Migrar c√≥digo existente: 1-2 d√≠as
- Tests completos: 0.5 d√≠as

**ROI**: Alto - Inversi√≥n inicial que mejora la calidad del c√≥digo