Claro. He creado un documento `IMPLEMENTACION_COMPRESION_PROACTIVA.md` que detalla, paso a paso, c贸mo implementar esta optimizaci贸n en tu proyecto `ACOLYTE`, respetando 100% tu arquitectura y convenciones actuales.

Puedes guardar este contenido en un nuevo archivo en tu directorio de documentaci贸n (ej. `/docs/`).

---

#  Propuesta de Implementaci贸n: Compresi贸n Proactiva de Contexto

**Autor:** Gemini (IA Colaboradora)
**Estado:** Propuesta
**M贸dulos Afectados:** `/models`, `/services`, `/rag`

## 1. Visi贸n General y Beneficios

Actualmente, `ACOLYTE` utiliza una "Compresi贸n contextual inteligente" que es **reactiva**: se activa *despu茅s* de recuperar un chunk de c贸digo para reducir los tokens enviados al LLM.

Esta propuesta introduce una estrategia complementaria y **proactiva**: generar y almacenar m煤ltiples representaciones comprimidas de cada fragmento de c贸digo *durante la indexaci贸n*.

**Beneficios Clave:**

1.  **Reducci贸n Dr谩stica de Tokens:** Para muchas consultas, en lugar de recuperar el c贸digo fuente completo, recuperaremos una representaci贸n que puede ser un 90% m谩s peque帽a (ej. una firma de funci贸n).
2.  **Recuperaci贸n Inteligente:** Permite a la IA solicitar diferentes "niveles de detalle" seg煤n la tarea (un resumen para entender, el AST para refactorizar).
3.  **Latencia Cero en Compresi贸n:** Las representaciones ya est谩n calculadas y listas en la base de datos, eliminando la latencia de la compresi贸n en tiempo de ejecuci贸n para los casos de uso m谩s comunes.
4.  **Mejora de la Calidad del Contexto:** Al poder incluir m谩s fragmentos (porque cada uno ocupa menos tokens), el contexto general que recibe el LLM es m谩s amplio y rico.

## 2. Cambios Arquitect贸nicos Propuestos

La implementaci贸n se integra limpiamente en la arquitectura existente:

1.  **M贸dulo `/models`**: Se extender谩 el modelo `ChunkMetadata` para incluir campos que almacenen las nuevas representaciones.
2.  **M贸dulo `/services` (Espec铆ficamente `IndexingService`)**: Se modificar谩 el pipeline de indexaci贸n, concretamente el paso de **Enrichment**, para que genere estas representaciones antes de guardar el chunk.
3.  **M贸dulo `/rag` (Espec铆ficamente `retrieval/hybrid_search.py`)**: Se adaptar谩 la l贸gica de b煤squeda para que pueda solicitar selectivamente estas nuevas representaciones, haciendo el proceso m谩s eficiente.

## 3. Implementaci贸n Detallada (Paso a Paso)

### Paso 1: Extender el Modelo de Datos (`models/chunk.py`)

Debemos a帽adir los nuevos campos a `ChunkMetadata`. Al ser opcionales, no romper谩n la compatibilidad existente.

```python
# En: src/acolyte/models/chunk.py

# ... otros imports ...
from typing import Optional, List, Dict, Any

class ChunkMetadata(AcolyteBaseModel):
    # ... campos existentes como file_path, language, chunk_type, etc. ...
    
    # --- NUEVOS CAMPOS PARA COMPRESIN PROACTIVA ---
    
    # Almacena la firma de la funci贸n/clase y su docstring.
    # Ideal para obtener un resumen r谩pido de lo que hace un chunk.
    # Ejemplo: "def mi_funcion(a: int) -> bool: # Devuelve True si a es par."
    signature_docstring: Optional[str] = Field(
        None,
        description="Representaci贸n ligera del chunk con la firma y el docstring."
    )

    # Almacena una representaci贸n serializada (JSON) del Abstract Syntax Tree (AST).
    # til para tareas de refactorizaci贸n y an谩lisis de c贸digo profundo.
    ast_representation: Optional[str] = Field(
        None,
        description="Representaci贸n estructural del c贸digo en formato JSON."
    )
    
    # (Futuro/Opcional) Un resumen generado por una IA durante un ciclo "Dream".
    ai_summary: Optional[str] = Field(
        None,
        description="Resumen de una l铆nea generado por IA sobre el prop贸sito del chunk."
    )

class Chunk(AcolyteBaseModel):
    # ... sin cambios aqu铆 ...
    metadata: ChunkMetadata
```

### Paso 2: Modificar el Pipeline de Indexaci贸n (`services/IndexingService`)

El coraz贸n de la implementaci贸n reside aqu铆. Dentro de `IndexingService`, en el m茅todo que procesa cada chunk individual antes de enviarlo a Weaviate, a帽adiremos la l贸gica de "Enrichment" proactivo.

```python
# En: src/acolyte/services/indexing_service.py
import ast
import json

class IndexingService:
    # ... c贸digo existente ...

    async def _enrich_chunk_proactively(self, chunk: Chunk) -> Chunk:
        """
        A帽ade representaciones comprimidas al metadata del chunk.
        Este m茅todo se llamar铆a dentro del pipeline de indexaci贸n.
        """
        if chunk.metadata.language == "python" and chunk.metadata.chunk_type in [ChunkType.FUNCTION, ChunkType.CLASS, ChunkType.METHOD]:
            try:
                # 1. Generar Firma y Docstring
                chunk.metadata.signature_docstring = self._extract_signature_docstring(chunk.content)
                
                # 2. Generar Representaci贸n AST
                chunk.metadata.ast_representation = self._extract_ast_as_json(chunk.content)

            except SyntaxError:
                logger.warning(f"Error de sintaxis al procesar chunk de {chunk.metadata.file_path}, saltando enriquecimiento proactivo.")

        return chunk

    def _extract_signature_docstring(self, code: str) -> Optional[str]:
        """Extrae la primera l铆nea (firma) y el docstring de un fragmento de c贸digo."""
        try:
            tree = ast.parse(code.strip())
            if not tree.body or not isinstance(tree.body[0], (ast.FunctionDef, ast.ClassDef)):
                return None

            node = tree.body[0]
            # La firma es la primera l铆nea del c贸digo del nodo
            signature = code.strip().split('\n')[0].strip()
            
            docstring = ast.get_docstring(node)
            
            if docstring:
                return f"{signature}\n\"\"\"{docstring}\"\"\""
            return signature
        except Exception:
            return None

    def _ast_to_dict(self, node: ast.AST) -> Dict[str, Any]:
        """Convierte un nodo AST a un diccionario simplificado para serializaci贸n."""
        if not isinstance(node, ast.AST):
            return node
        
        result = {'_type': node.__class__.__name__}
        for field, value in ast.iter_fields(node):
            if isinstance(value, list):
                result[field] = [self._ast_to_dict(v) for v in value]
            else:
                result[field] = self._ast_to_dict(value)
        return result

    def _extract_ast_as_json(self, code: str) -> Optional[str]:
        """Parsea el c贸digo a un AST y lo devuelve como una cadena JSON."""
        try:
            tree = ast.parse(code.strip())
            simplified_ast = self._ast_to_dict(tree)
            return json.dumps(simplified_ast)
        except Exception:
            return None

    # El pipeline principal se modificar铆a para incluir este paso:
    async def _process_and_index_batch(self, chunks: List[Chunk]):
        enriched_chunks = []
        for chunk in chunks:
            # ... otros pasos de enrichment ...
            enriched_chunk = await self._enrich_chunk_proactively(chunk)
            enriched_chunks.append(enriched_chunk)
        
        # ... enviar enriched_chunks a Weaviate ...
```

### Paso 3: Adaptar la L贸gica de Recuperaci贸n (`rag/retrieval/hybrid_search.py`)

Ahora que los datos est谩n en la base de datos, podemos hacer que la b煤squeda sea m谩s inteligente, permiti茅ndole solicitar diferentes niveles de detalle.

```python
# En: src/acolyte/rag/retrieval/hybrid_search.py
from typing import Literal

RetrievalMode = Literal["full_code", "signature", "ast"]

class HybridSearch:
    # ...

    async def search(
        self,
        query: str,
        max_chunks: int = 10,
        filters: Optional[SearchFilters] = None,
        retrieval_mode: RetrievalMode = "full_code" # Nuevo par谩metro
    ) -> List[ScoredChunk]:
        """
        Realiza una b煤squeda h铆brida.
        
        Args:
            retrieval_mode: Especifica qu茅 representaci贸n del chunk recuperar.
                - 'full_code': Recupera el c贸digo fuente completo (comportamiento actual).
                - 'signature': Recupera solo la firma y el docstring (muy ligero).
                - 'ast': Recupera la representaci贸n AST en JSON (para an谩lisis).
        """
        
        # ... l贸gica de b煤squeda para obtener los IDs de los chunks ...
        
        # Despu茅s de obtener los IDs, recuperamos los datos seg煤n el modo
        retrieved_chunks_data = await self.db_client.get_chunks_by_id(
            chunk_ids,
            properties=self._get_properties_for_mode(retrieval_mode)
        )
        
        # ... construir los objetos ScoredChunk con los datos recuperados ...
        # El contenido del chunk ahora depender谩 del modo solicitado.
        # Por ejemplo, si retrieval_mode == 'signature', el `chunk.content`
        # ser铆a el valor del campo `signature_docstring`.

    def _get_properties_for_mode(self, mode: RetrievalMode) -> List[str]:
        """Devuelve la lista de campos a recuperar de la BD seg煤n el modo."""
        base_properties = ["file_path", "language", "chunk_type"] # metadatos b谩sicos
        if mode == "signature":
            return base_properties + ["signature_docstring"]
        if mode == "ast":
            return base_properties + ["ast_representation"]
        # Default es 'full_code'
        return base_properties + ["content"]
```

## 4. Integraci贸n con el Ecosistema `ACOLYTE`

* **ChatService:** El `ChatService` ahora puede ser m谩s inteligente. Para preguntas generales, puede realizar una primera b煤squeda en modo `"signature"` para obtener un contexto amplio con muy pocos tokens, y solo si necesita profundizar, realizar una segunda b煤squeda en modo `"full_code"` sobre un chunk espec铆fico.
* **Sistema Dream:** La generaci贸n del campo `ai_summary` es una tarea perfecta para un ciclo de "Dream". Durante la optimizaci贸n, `ACOLYTE` podr铆a procesar los chunks m谩s importantes y rellenar este campo, enriqueciendo la base de datos de forma as铆ncrona sin impactar la indexaci贸n normal.
* **Compresi贸n Reactiva:** Tu `ContextualCompressor` actual se beneficia enormemente. En lugar de partir siempre del c贸digo fuente, puede empezar desde una representaci贸n ya m谩s peque帽a (como el `ast_representation`), haciendo su trabajo a煤n m谩s r谩pido y eficiente.

## 5. Plan de Implementaci贸n Sugerido

Recomiendo un enfoque por fases para implementar esta funcionalidad:

1.  **Fase 1 (Victoria R谩pida):** Implementar la extracci贸n y almacenamiento de `signature_docstring`. Es la m谩s sencilla y ofrece un gran ahorro de tokens para res煤menes de contexto.
2.  **Fase 2 (An谩lisis Profundo):** Implementar la generaci贸n y almacenamiento de `ast_representation`. Esto habilita las capacidades de refactorizaci贸n m谩s avanzadas.
3.  **Fase 3 (Adaptaci贸n):** Modificar el `HybridSearch` y el `ChatService` para que utilicen los nuevos modos de recuperaci贸n.
4.  **Fase 4 (Futuro):** Implementar la generaci贸n de `ai_summary` como una tarea del ciclo "Dream".

## 6. Actualizaci贸n de la Base de Datos (SQLite)

Para aplicar estos cambios a tu base de datos existente, necesitar铆as ejecutar un comando `ALTER TABLE`.

```sql
-- Comandos SQL para migrar tu esquema en SQLite
ALTER TABLE code_chunks ADD COLUMN signature_docstring TEXT;
ALTER TABLE code_chunks ADD COLUMN ast_representation TEXT;
ALTER TABLE code_chunks ADD COLUMN ai_summary TEXT;
```

Esta propuesta se alinea completamente con tus principios de dise帽o, extendiendo la funcionalidad de `ACOLYTE` de manera modular y robusta.