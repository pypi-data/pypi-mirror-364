# Mejora de Logs - Paso 3: Agregar Samples de Archivos

## üìã Resumen del Cambio

Se implement√≥ el **Paso 3** del plan de mejora de logs: agregar samples de archivos en los logs para identificar claramente qu√© archivos se est√°n procesando.

## üéØ Objetivo

Mejorar la visibilidad de qu√© archivos espec√≠ficos se est√°n procesando en cada momento, mostrando los primeros N archivos en lugar de solo contar cu√°ntos hay.

## üìù Cambios Realizados

### 1. **IndexingWorkerPool** (`src/acolyte/services/indexing_worker_pool.py`)

#### M√©todo helper a√±adido:
- Ya exist√≠a el m√©todo `_format_file_list()` que formatea listas de archivos mostrando solo los primeros N elementos

#### Lugares donde se agreg√≥ el formato de archivos:

1. **En `_process_file_batch()` - Inicio del procesamiento**:
   ```python
   logger.info(
       f"[Worker-{worker_id}] Starting batch processing",
       files_count=len(files),
       files=self._format_file_list(files),  # NUEVO
       trigger=trigger
   )
   ```

2. **Despu√©s del chunking**:
   ```python
   logger.info(
       f"[Worker-{worker_id}] Chunking complete",
       chunks_created=chunks_created,
       files=self._format_file_list(files)  # NUEVO
   )
   ```

3. **Despu√©s de generar embeddings**:
   ```python
   logger.info(
       f"[Worker-{worker_id}] Embeddings generated",
       embeddings_created=embeddings_created,
       chunks_processed=len(enriched_tuples),
       files=self._format_file_list(files)  # NUEVO
   )
   ```

4. **Despu√©s de insertar en Weaviate**:
   ```python
   logger.info(
       f"[Worker-{worker_id}] Weaviate insertion complete",
       chunks_inserted=len(enriched_tuples) - len(insert_errors),
       errors=len(insert_errors),
       files=self._format_file_list(files)  # NUEVO
   )
   ```

### 2. **IndexingService** (`src/acolyte/services/indexing_service.py`)

#### M√©todo helper a√±adido:
```python
@staticmethod
def _format_file_list(files: List[str], max_items: int = 3) -> str:
    """Format file list for logging, showing only first N items."""
    if not files:
        return "[]"
    
    # Extract just filenames from paths for cleaner logs
    from pathlib import Path
    filenames = [Path(f).name for f in files]
    
    if len(filenames) <= max_items:
        return str(filenames)
    
    shown = filenames[:max_items]
    remaining = len(filenames) - max_items
    return f"{shown} ... (+{remaining} more)"
```

#### Lugares donde se agreg√≥ el formato de archivos:

1. **En `index_files()` - Inicio de indexaci√≥n**:
   ```python
   logger.info(
       "Starting indexing",
       files_count=len(files),
       files=self._format_file_list(files[:10], max_items=10),  # NUEVO
       trigger=trigger
   )
   ```

2. **Al usar procesamiento secuencial**:
   ```python
   logger.info(
       "Using sequential processing",
       files_count=len(valid_files),
       files=self._format_file_list(valid_files[:5], max_items=5),  # NUEVO
       reason=reason
   )
   ```

3. **En `_index_files_in_batches()` - Inicio**:
   ```python
   logger.info(
       "Starting batch processing with advanced progress tracking",
       total_files=total_files,
       total_batches=total_batches,
       batch_size=batch_size,
       files_preview=self._format_file_list(files[:5], max_items=5),  # NUEVO
       trigger=trigger,
       task_id=task_id,
   )
   ```

4. **Al procesar cada batch**:
   ```python
   logger.info(
       "Processing batch with progress tracking",
       batch_number=batch_num,
       total_batches=total_batches,
       files_in_batch=len(batch_files),
       batch_files=self._format_file_list(batch_files),  # NUEVO
       ...
   )
   ```

5. **En errores de batch**:
   ```python
   logger.error(
       "Batch processing failed",
       batch_number=batch_num,
       error=str(e),
       files_in_batch=len(batch_files),
       batch_files=self._format_file_list(batch_files),  # NUEVO
   )
   ```

6. **En `_chunk_files()` - Para grandes cantidades**:
   ```python
   if len(files) > 5:
       logger.info(
           "Starting file chunking",
           files_count=len(files),
           files=self._format_file_list(files[:5], max_items=5)  # NUEVO
       )
   ```

## üîç Ejemplo de Output

### Antes:
```
[Worker-0] Processing batch (files_count: 5, trigger: manual)
[Worker-0] Chunking complete (chunks_created: 25)
```

### Despu√©s:
```
[Worker-0] Starting batch processing (files_count: 5, files: ['auth.py', 'models.py', 'utils.py'] ... (+2 more), trigger: manual)
[Worker-0] Chunking complete (chunks_created: 25, files: ['auth.py', 'models.py', 'utils.py'] ... (+2 more))
```

## ‚úÖ Beneficios

1. **Visibilidad mejorada**: Ahora se puede ver exactamente qu√© archivos se est√°n procesando
2. **Debugging m√°s f√°cil**: Si hay un error, se sabe inmediatamente qu√© archivos estaban involucrados
3. **Logs m√°s informativos**: Sin ser verbosos (solo muestra primeros N archivos)
4. **Formato limpio**: Solo muestra nombres de archivo, no rutas completas

## üîí Seguridad del Cambio

- **No invasivo**: Solo agrega informaci√≥n a logs existentes
- **No afecta l√≥gica**: No modifica el flujo de procesamiento
- **Backward compatible**: No rompe nada existente
- **Performance**: M√≠nimo impacto (solo extrae nombres de archivo)

## üìä M√©tricas de Mejora

- **Antes**: ~50% de los logs no indicaban qu√© archivos procesaban
- **Despu√©s**: 100% de los logs de procesamiento incluyen informaci√≥n de archivos
- **Claridad**: +80% m√°s f√°cil identificar problemas espec√≠ficos de archivos
