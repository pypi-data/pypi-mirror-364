#!/usr/bin/env python3
"""
RefinireAgent Streaming Example
RefinireAgentã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä½¿ç”¨ä¾‹

This example demonstrates how to use RefinireAgent with streaming output
for real-time response display.
ã“ã®ã‚µãƒ³ãƒ—ãƒ«ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¿œç­”è¡¨ç¤ºã®ãŸã‚ã®RefinireAgentã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ã®ä½¿ç”¨æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚
"""

import asyncio
import sys
import os

# Add the src directory to the Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from refinire import RefinireAgent, Context

async def basic_streaming_example():
    """
    Basic streaming example with real-time output
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡ºåŠ›ã®åŸºæœ¬ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¾‹
    """
    print("ğŸ”„ Basic Streaming Example")
    print("=" * 40)
    
    # Create agent with longer response instruction for better streaming demonstration
    # ã‚ˆã‚Šè‰¯ã„ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢ã®ãŸã‚ã€é•·ã„å¿œç­”æŒ‡ç¤ºã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
    agent = RefinireAgent(
        name="StreamingAgent",
        generation_instructions="""
        Provide a detailed, thoughtful response about the topic. 
        Explain concepts clearly and give examples. 
        Write in a conversational tone with multiple paragraphs.
        """,
        model="gpt-4o-mini",
        temperature=0.7
    )
    
    user_input = "Explain how artificial intelligence is changing the world"
    
    print(f"User: {user_input}")
    print("Assistant: ", end="", flush=True)
    
    # Stream the response
    async for chunk in agent.run_streamed(user_input):
        print(chunk, end="", flush=True)
    
    print("\n")

async def streaming_with_callback_example():
    """
    Streaming with callback function for custom processing
    ã‚«ã‚¹ã‚¿ãƒ å‡¦ç†ç”¨ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ä»˜ãã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
    """
    print("ğŸ”„ Streaming with Callback Example")
    print("=" * 40)
    
    agent = RefinireAgent(
        name="CallbackAgent",
        generation_instructions="Provide a helpful response with examples.",
        model="gpt-4o-mini"
    )
    
    # Callback function to process each chunk
    # å„ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
    chunks_received = []
    def chunk_processor(chunk: str):
        chunks_received.append(chunk)
        # You could add custom processing here, like:
        # ã“ã“ã«ã‚«ã‚¹ã‚¿ãƒ å‡¦ç†ã‚’è¿½åŠ ã§ãã¾ã™ã€‚ä¾‹ï¼š
        # - Save to file / ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        # - Send to websocket / WebSocketã«é€ä¿¡
        # - Update UI / UIã‚’æ›´æ–°
        # - Log to database / ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ­ã‚°
    
    user_input = "What are the benefits of renewable energy?"
    
    print(f"User: {user_input}")
    print("Assistant: ", end="", flush=True)
    
    # Stream with callback
    async for chunk in agent.run_streamed(user_input, callback=chunk_processor):
        print(chunk, end="", flush=True)
    
    print(f"\n\nğŸ“Š Received {len(chunks_received)} chunks")
    print(f"ğŸ“ Total characters: {sum(len(chunk) for chunk in chunks_received)}")

async def streaming_with_context_example():
    """
    Streaming with shared context for conversation continuity
    ä¼šè©±ç¶™ç¶šã®ãŸã‚ã®å…±æœ‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
    """
    print("ğŸ”„ Streaming with Context Example")
    print("=" * 40)
    
    agent = RefinireAgent(
        name="ContextAgent",
        generation_instructions="Continue the conversation naturally, referencing previous messages.",
        model="gpt-4o-mini"
    )
    
    # Create shared context for conversation
    # ä¼šè©±ç”¨ã®å…±æœ‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
    ctx = Context()
    
    messages = [
        "Hello, can you help me understand Python?",
        "What about async/await in Python?",
        "Can you give me a practical example?"
    ]
    
    for i, user_input in enumerate(messages):
        print(f"\n--- Message {i + 1} ---")
        print(f"User: {user_input}")
        print("Assistant: ", end="", flush=True)
        
        # Add user message to context
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
        ctx.add_user_message(user_input)
        
        # Stream response with shared context
        # å…±æœ‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§å¿œç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
        async for chunk in agent.run_streamed(user_input, ctx=ctx):
            print(chunk, end="", flush=True)
        
        print()  # New line after each response

async def error_handling_streaming_example():
    """
    Demonstrate error handling in streaming
    ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å®Ÿè¨¼
    """
    print("ğŸ”„ Error Handling Streaming Example")
    print("=" * 40)
    
    agent = RefinireAgent(
        name="ErrorTestAgent",
        generation_instructions="Respond helpfully to user input.",
        model="gpt-4o-mini"
    )
    
    try:
        # Test with empty input
        print("Testing with empty input...")
        async for chunk in agent.run_streamed(""):
            print(chunk, end="", flush=True)
        
        print("\n\nTesting with normal input...")
        async for chunk in agent.run_streamed("Tell me about Python"):
            print(chunk, end="", flush=True)
        
    except Exception as e:
        print(f"Error occurred: {e}")

async def main():
    """Run all streaming examples"""
    try:
        await basic_streaming_example()
        await streaming_with_callback_example()
        await streaming_with_context_example()
        await error_handling_streaming_example()
        
        print("\nâœ… All streaming examples completed successfully!")
        
    except Exception as e:
        print(f"âŒ Example failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # Run the examples
    asyncio.run(main())